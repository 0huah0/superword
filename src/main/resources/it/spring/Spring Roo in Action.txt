For online information and ordering of this and other Manning books, please visit www.manning.com.
The publisher offers discounts on this book when ordered in quantity.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the publisher.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in the book, and Manning Publications was aware of a trademark claim, the designations have been printed in initial caps or all caps.
Recognizing the importance of preserving what has been written, it is Manning’s policy to have the books we publish printed on acid-free paper, and we exert our best efforts to that end.
How to install the Roo add-on for Spring Integration 343
Java has been the world’s most popular programming language for well over a decade.
You can find it running everywhere: on super computers, servers, set top boxes, PCs, phones, tablets, routers, and robots.
There are millions of expert engineers fluent in it, libraries for every conceivable purpose, and unparalleled tooling and management capabilities.
Despite Java’s success, few people consider it highly productive for quickly develop­ ing enterprise applications.
It promoted patterns that are unthink­ able in the modern era, including vast deployment descriptors, code that was virtually impossible to unit test, confusing lifecycle methods, meaningless layers, excessive redeployment delays, and so on.
It also significantly popularized the use of open source within traditionally conservative organizations that had previously only allowed vendor-endorsed prod­
Today, most developers enjoy considerable latitude in their ability to use liberally licensed open source software.
Ruby on Rails in particular exploited a range of dynamic language capabili­ ties to further raise the bar of enterprise application development productivity.
Grails delivered similar benefits on the JVM by combining Spring’s solid enterprise founda­ tions with Groovy’s dynamic language capabilities.
Implementing a convention-over-configuration web framework for Java was chal­ lenging because of its static typing model, so I designed an incremental active code.
This allowed multiple compilation units to be woven into a single class file.
The approach had not been attempted before, but it worked out nicely, and today other code generators also emit mixins (for example, Apache Magma)
One unique benefit of Spring Roo’s convention-over-configuration model is the absence of any runtime component.
It operates only at development time, just like Maven or Eclipse.
This makes Roo completely free of lock-in or runtime expense, such as memory or CPU time.
Many people use Roo to start a project and then stop using it, while others keep using it indefinitely for the same project.
Since 2008, there have been tens of thousands of projects built using Spring Roo.
It brings you the proven productivity benefits of convention over configuration, but with the substan­ tial advantages of Java.
Spring Roo in Action is an insightful and comprehensive treatment of Spring Roo.
Ken Rimple and Srini Penchikala have worked closely with the Roo community and engineering team for over two years, with countless emails, tickets, and forum posts that dig deep into the Roo internals.
They have carefully tracked Roo’s development and inspired multiple improvements.
The result is a detailed book that is extensively researched, up-to-date, authoritative, and pragmatic.
I hope that you enjoy Spring Roo in Action and the significant productivity enhancements it will bring to your applica­ tion development journey.
In the summer of 2009, I learned from Ben Alex about a new technology called Spring Roo.
This project, based on a command-line shell, promised to bring the agil­ ity of other rapid development frameworks, such as Grails and Ruby on Rails, to the native Java and Spring platform.
Using a shell instead of writing code seemed like a loss of control, but after downloading and experimenting with the tool, I started to realize the potential of this project.
Roo appeared to crack that problem and provide an elegant solution.
With Spring Roo, you issue simple commands, such as jpa setup, web mvc setup, entity jpa, field, service, and repository.
Configuration tasks that normally take hours or days are performed instantly.
I could see that this was going to be a useful tool for the everyday Spring developer.
Unlike so many other times in my life, I was able to posi­ tion myself at just the right time to make the pitch.
In the beginning of 2011, Srini Penchikala, InfoQ author and editor who had been using Roo on various projects, accepted the coauthor slot.
Srini was a huge help, hav­ ing penned chapters on Spring Integration, cloud computing, email and JMS, and Spring Security.
During the spring and summer of 2011 we wrote the majority of these chapters.
So this book has undergone at least three major revisions since the time we started writing it.
Our pain is your gain, and that includes all of our hard work with code that was written the night before, identifying bugs for the Roo team to fix, and working with the fantastic community of readers we have in Manning’s MEAP program, aligned as well with completing the manuscript around the time of the Roo 1.2.1 release.
Our hope is that you glean from this book a sense of how Roo development oper­ ates, regardless of which version of Roo you’ll be using.
We also hope to spur on more developers to start using Roo as a key tool in their arsenal.
The Roo community could really use some good add-ons, and though this book goes into some detail, we hope people take up the cause and contribute.
The book has been a long time in development and production, but I think the timing is good.
There are many people we want to thank for their help in making this book, starting with the Manning team: Michael Stephens, who first discussed the project with us; Christina Rudloff; the inimitable Marjan Bace; marketing genius Candace Gillhoolley; and our wonderful editors, in order of appearance: Emily Macel, Sara Onstine, and Sebastian Stirling.
They were absolutely invaluable in providing advice and critiques, and in revving us up when we were out of juice.
We wish to thank our production team of Mary Piergies; maestro Troy Mott and his band of merry editors: Ben Berg, Tara McGoldrick, and Bob Herbstman; our talented proofreaders: Katie Tennant and Alyson Brener; and others behind the scenes whom we are not able to name.
The reader community also deserves a huge amount of credit.
Brown, varevadal, Terry Jeske, and Jeff Hall, among others, helped us find bugs, from the stupid to the super-complex, and gave us honest feedback when we needed it most.
Finally, we’d like to thank the Roo development team for being there and fixing bugs almost before we thought them up: Dr.
Thank you for accepting our JIRA reports and working up fixes so.
Special thanks to Ben for agreeing to write the foreword to our book, and to Alan and Andrew for a final technical proofread of the manuscript just before it went into production.
I dedicate the book to my wife, Kris, because without seeing her complete more than nine books while raising our boys, I never thought I could finish this project.
Quattrone, who got me started in obsess­ ing over my writing as a literary magazine editor.
And I absolutely must thank my mother, who always told me that I could do anything.
I would also like to acknowledge my employer, Chariot Solutions, for their support of the book by giving me a forum for training courses (http://chariotsolutions.com/ education) and podcasts (http://techcast.chariotsolutions.com), and allowing me to participate in other endeavors, such as the Emerging Technologies for the Enterprise conference (http://phillyemergingtech.com) that also inform my writing.
A huge expression of gratitude to Srini Penchikala, who came in at the right time and helped me get this project done.
His contributions in areas such as Spring Inte­ gration, JMS, email, cloud computing, and much more make this book extremely comprehensive.
I would be remiss if I didn’t thank Gordon Dickens for his research and writing contributions during the beginning of this book project.
He and I are close friends, and without our crazy plan, hatched one day after the interview with Ben Alex, I might not have reached out to Manning.
Finally, I’d like to single out one contributor who must have a special mention: Mete Senocak contributed key early suggestions, edits, and frank advice.
You’re a good man, Mete, and I’m sure we’ll see each other in a coffee support group soon.
It’s been a rewarding experience to contribute to the book as well as learn from others about authorship.
I also want to thank Ken Rimple for his guidance and mentoring in my transition from writing articles to writing a book.
Special thanks to our MEAP readers who provided excellent feedback and sugges­ tions in improving the content as well as the sample application discussed in the book.
I would like to also thank my wife Kavitha and my seven year-old daughter Srihasa for their continued support and patience during the writing of this book.
Welcome to Spring Roo in Action! If you’re reading this book, you’re looking for ways to improve your Spring development productivity.
When we started writing this book, nobody had even considered a book on Roo.
The tool had been out in the public sphere for only a few months, and, after all, writ­ ing a book on any emerging technology is a crazy thing to do.
But crazy things are usu­ ally tried by crazy people, and once we got started there was no turning back.
This book is your guide to juicing your Spring development productivity, using a tiny, 8-megabyte project known as Spring Roo.
The writers of this book are Spring developers, trainers, mentors, and hobbyists.
We develop, train, mentor, and tinker with Spring every day, so when we saw what Roo brought to the table we realized the power it represented to the everyday developer.
Craig Walls’s Spring in Action, also published by Manning, is an excellent compan­
It’s our hope that you can read this book and get a taste of how to build a Roo applica­ tion, even without running a single sample.
That said, the concepts are relatively easy to grasp—using Roo’s TAB completion you can test the various commands and.
Then you can use your editor to review the code and test it.
Soon you’ll find it easy to try out new frame­ works, because the feedback loop is so short.
Combine it with Git for version control, and you can create a branch for your new idea, try it out, and merge it back in if you like it.
Of course, because branches are cheap, you can remove the branch and forget it ever happened.
We encourage you to create a lot of throw-away projects with Roo.
We begin by making the case for Roo and RAD on Java—how Spring makes things better, but how Roo really knocks it out of the park.
We create a sample project, the Roo Pizza Shop, as a way to get you to kick the tires early, and you’ll see how little you need to do to build a full-featured database-backed web application.
We then dig into the code behind the application, inter-type declara­ tions (ITDs), the various ways to structure your projects, and using an IDE such as SpringSource Tool Suite.
We then discuss how to use refactoring to push-in or pull-out code, and how to remove Roo entirely if you need to.
Chapter 3 is an introduction to database persistence in Roo.
We detail the options for setting up persistence using JPA, setting up a JPA entity, using the Bean Validation framework to provide annotation-driven validations, how to use finders to write simple JPA queries, and how to create repositories using the repository command and the Spring Data API.
We show you how to install the web framework and how to use scaffolding to automatically generate a simple CRUD application with only two commands.
We also discuss accessing other Spring beans, and how to scaffold in a multimodule project.
Chapter 6 digs deeply into the scaffolding engine and Roo’s tag libraries.
We show you how you can customize the scaffolded web views, and how to modify the way fields are displayed.
We outline how to display reference data in drop-down lists, customize date fields, deal with localization and theming, and we show you how Roo uses Apache Tiles to lay out your user interfaces.
We start by showing you how to use Spring MVC and Dojo to provide Ajax support for your forms.
We then show you how to install two other web frameworks, Google Web Toolkit and JavaServer Faces.
We end by listing a few other web frameworks and the support that Roo had for them at the time we wrote the book.
We cover unit testing and Mockito, mocking the persistence tier, integration testing in-container against entities, repositories and services, and how to write functional, black box tests with Selenium, both using Roo’s support for HTML table-based tests as well as using the JUnit API.
Chapter 10 discusses email and JMS, two external integration points that most developers have to work with at some point in their careers.
We begin by outlining a course management system, and then lay down the JMS and email features required to support that system.
We cover JMS installation, the JMS template, building a POJO listener, and testing the listener.
Then we cover building email messages with an email sender, configuring SMTP support, building an email template, and hosting it behind a Spring service.
We start by showing you how to search for publicly available add-ons and how to install and remove them.
Because add-ons are OSGi components, we spend time detailing enough of OSGi to be dangerous, and then we dive right in and create three add-ons: a Norwegian language addon, a Roo wrapper add-on to expose a non-OSGi JAR to the Roo system, and a “Simple” add-on to provide jQuery support.
Chapter 12 continues our add-on discussion and provides support for CoffeeScript by creating an advanced add-on.
We install the Maven plug-in for CoffeeScript compilation, build and test it, and show you how to detect the availability of both adding and removing the feature from your project.
We then wrap up the discussion by detailing how to publish and submit your add-on to the add-on community.
Chapter 13 shows you how to use cloud computing to host your Roo applications.
We discuss some of the platforms, including CloudBees and Heroku, and then focus on using Cloud Foundry, a VMware hosting offering.
We deploy the Course Manager application to the cloud and show how to fetch application statistics, as well as how to bind cloud resources to the application.
Chapter 14 details how to use Spring Integration from a Roo project.
We discuss event-driven application architectures, how to add a workflow to handle course registration, and how to build and install the Roo integration add-on from source, because it’s not yet released for Roo 1.2
To follow along with the book, you’ll need to download and install Spring Roo, version 1.2.1, from http://springsource.org/spring-roo.
You’ll also need an IDE; for the new Spring developer, we suggest using SpringSource Tool Suite.
Gordon Dickens has written an STS RefCard that can be downloaded free (note: registration required) from http://refcardz.dzone.com/refcardz/ eclipse-tools-spring.
This special version of Eclipse is fully configured to develop Spring-based applications, and can be configured to use your Roo shell.
IntelliJ is an excellent alternative IDE, and provides support for many of the same features as SpringSource Tool Suite, the key omission being an integrated copy of the Spring tc Server web application server, which comes bundled with STS.
You’ll also need to install Maven 3.0.3 or higher, because Roo projects are Maven projects.
If you’re going to write your own add-ons, you’ll need to install GPG, an open source encryption provider.
To make these add-ons available to the public, you’ll want to install Git and/or Subversion (SVN) to deliver your add-ons to public repositories hosted by Google Code, GitHub, or other places where the Roo team can access and index your add-on.
Users of earlier versions of Roo will need to make some adjustments in their shell commands, and the classes will look notably different.
In earlier versions of Roo, the only persistence mechanism is via the Roo Active Record pattern.
Also, earlier versions of the persistence framework configuration use a persistence setup command, which has changed to the newer jpa setup in light of support for configuring non-SQL databases.
Expect additional changes for the better in future ver­ sions.
Concept-wise, the chapters hold up—the concept behind simple and advanced add-ons is the same; but the individual beans, interfaces, and techniques will vary.
We’ve found the best course of action is to perform the upgrade, but then create a brand new scratch Roo project with the features you’re using, and diff the pom.xml file to make sure that you’ve been properly upgraded to the most recent version.
Refer to the Roo documentation for details for each official release.
We use specially formatted code in non-proportional type to convey symbols, com­ mands, and fragments of source code.
Roo (and Spring) make it hard to fit code on single lines, due to the fact that Spring developers are long-name happy (consider one of the longer class names, ClassPathXmlApplicationContext, to see what gave us many headaches when formatting our listings)
We occasionally use the continuation character to show a long line in a generated artifact as well.
We use Courier to highlight various commands, such as web mvc setup.
We skip long lists of Java import statements and nonessential source code fragments to illustrate key features.
We use bold code font to emphasize some areas of code examples to show.
We use italic font for emphasis and to detail new terms.
Code annotations are used instead of comments in code samples.
Where comments are used, they appear in the code sample as a numbered bullet, and may have corresponding discussion points in the manuscript below the sample.
The source code for Roo in Action is available at http://github.com/krimple/springroo-in-action-examples.
You can also find links to the source code repository and a post-publication errata list on the Manning page for this book, http://manning.com/ SpringRooinAction.
As the Roo project progresses rapidly, we’ve constantly been reworking our examples and upgrading them before publication of the book.
If you find a problem with the samples, please log a bug with the project by creating a GitHub account and clicking on the Issues tab.
We’ll also be taking contributions of example code to share with our readers— contact us via GitHub with pull requests to the user-contrib directory and we’ll review them.
Assume that your samples will be available for use by the public Roo user community, and that the code should be freely contributed without additional restrictive source licenses.
Any contributions are welcomed by the reader community, so feel free to lend your expertise.
If it contains a readme.txt file, please review it before running the sample.
This file may contain instructions on how to build, run, or review the individual sample.
The purchase of Spring Roo in Action includes free access to a private forum run by Manning Publications where you can make comments about the book, ask technical questions, and receive help from the authors and other users.
This page provides information on how to get on the forum after you’re registered, what kind of help is available, and the rules of conduct in the forum.
Manning’s commitment to our readers is to provide a venue where a meaningful dialogue among individual readers and between readers and authors can take place.
It’s not a commitment to any specific amount of participation on the part of the authors, whose contribution to the book’s forum remains voluntary (and unpaid)
We suggest you try asking the authors some challenging questions, lest their interest stray!
The Author Online forum and the archives of previous discussions will be accessible from the publisher’s website as long as the book is in print.
He has had an obsession with creativity in music and computers his whole life.
At the same time he began his lifelong love affair with the drums.
Today he’s a jazz drummer who plays whenever he can.
Ken has been active in emerging technologies since he entered the IT sector in 1989, at the dawn of the client/server movement.
He’s worked on technologies from fat clients to databases to servers, ranging from WebLogic to Tomcat.
He is currently immersed in Spring technologies, including Roo and Grails.
Ken runs Chariot’s education services (http://chariotsolutions.com/education) where he teaches Spring-related VMWare courses, including Maven and Hibernate, among others.
He also hosts the Chariot TechCast (http://techcast.chariotsolutions .com) podcast, and blogs at http://rimple.com.
He has over 16 years of experience in software architecture, security, and.
Srini has published several articles on risk management, security architecture, and agile security methodologies on websites like InfoQ, The ServerSide, OReilly Network (ONJava), DevX Java, java.net, and JavaWorld.
The book includes finely colored illus­ trations of figures from different regions of Croatia, accompanied by descriptions of the costumes and of everyday life.
Sinj is a small town in Dalmatia, about 25 miles north of Split.
The figure on the cover wears black woolen trousers and a white linen shirt, over which he dons a black vest and black jacket, richly trimmed with the blue and red embroidery typical for this region.
The man is also hold­ ing a pipe and has a short sword tucked under his belt.
Dress codes and lifestyles have changed over the last 200 years, and the diversity by.
It’s now hard to tell apart the inhabitants of different continents, let alone of different hamlets or towns separated by only a few miles.
Perhaps we have traded cultural diversity for a more varied personal life— certainly for a more varied and fast-paced technological life.
Manning celebrates the inventiveness and initiative of the computer business with book covers based on the rich diversity of regional life of two centuries ago, brought back to life by illustrations from old books and collections like this one.
Spring Roo is an excellent framework for the rapid development of Springbased Java applications.
With a simple command-line shell, it can create and manage Spring applications, adding and configuring components in all of the application architecture layers from SQL to URL, so to say.
You’ll also learn how to install and launch the Roo shell.
We’ll look at a simple application by running one of the sample scripts provided in the Roo installation package.
You’ll also learn the details of Roo project layout and architecture.
We discuss one of the new concepts Roo introduces, called AspectJ ITDs‚ that plays an important role in the overall Roo architecture.
As developers, you need tools to take advantage of new technologies and frame­ works.
Roo comes with integration in the form of the SpringSource Tool Suite (STS) IDE tool, which is also discussed in this chapter.
We wrap up the chapter with a discussion on refactoring Roo code and leaving Roo behind if, for some reason, you want to remove Roo from your project.
With a simple command-line shell, Roo can create and manage Spring-based appli­ cations, adding and configuring features such as the Java Persistence API (JPA), the Java Message Service (JMS), email, and Spring Security.
These allow you to manage and edit your database data, config­ ure tests using frameworks such as JUnit and Selenium, and choose from a variety of ORM APIs and databases.
At the same time, Roo reduces the amount of code writ­ ten by you and rolls out efficient, customizable generated code.
In this chapter, we discuss the challenges of working with Enterprise Java appli­ cations, create a sample application with the Roo shell, and take a quick tour of Roo’s features.
We then review the Roo sample script file and discuss the architec­ tural models available to you when crafting your application.
You’re about to be introduced to a powerful new tool that makes your life as a Java.
You’ll see that you can gain much of the productivity available in dynamic-language, convention-over-configuration plat­ forms such as Ruby on Rails and Grails.
This all comes without sacrificing the benefits of Java compile-time type safety, compiled code, and debuggability.
Let’s begin our journey by discussing one of the major reasons why Java-based devel­ opment projects sputter: the complexity of configuring an application architecture.
Putting together a Java-based application can be a difficult task these days.
In traditional Enterprise Java development efforts, architects pull together a hodgepodge of open source technologies and standards-driven platforms such as JDBC, the Servlet and JavaServer Pages (JSP) APIs, and Enterprise JavaBeans (EJB) using a build tool such as Ant or Maven.
If they’re more advanced, they’ll use an appli­ cation framework such as Struts and EJB, Seam, or Spring.
Contrast this with your friends programming in dynamic language platforms, such as Ruby on Rails or Grails, who take about 15 minutes to get a basic application shell up and running.
That shell usually includes a web application, database data and vali­ dation, and some basic business and navigation logic.
Unlike a lot of Java application prototypes, theirs is usually the beginning of the final project, whereas Java developers have to try and throw away a fair number of APIs and platforms manually until they get to a point where they’re comfortable assigning a team to the project.
The bottom line is that it just takes a long time to write a Java-based application.
The Spring Framework, a development platform that uses interface-driven develop­ ment, dependency injection, aspect-oriented programming, and a number of helper APIs and services, significantly reduces the complexity of your Enterprise Java code.
If you haven’t heard of Spring by now, we strongly suggest you put this book down and read up on the framework before you dig deeply into Roo.
Craig Walls’ excellent Spring in Action is a great companion to this book.
Spring operates on the principle of making your development less about busy work and more about writing business logic.
Spring application developers define interface-driven beans that are then implemented as Plain Old Java Objects (POJOs) and mounted in a Spring container using XML, annotations, or Java-based configuration directives.
Configuration is a burden 5 Here’s an example business interface:
One way you can use this bean is to autowire it as shown next:
We’re leaving out the configuration here, but the basic idea is a simple one: let Spring find and mount your component, deal with it at the interface level, and just write a POJO both to expose and use your component.
You can use any Java API you can think of inside a Spring application, but you’re still required to add dependent JAR files and configuration to simplify the program­ ming tasks later.
Even Spring can’t save you from all of the tedium involved in building an application.
There are many decisions that you need to make, as shown in figure 1.1
Spring makes those tasks easier and shifts some of them to configuration, rather than coding, such as these:
Configuring a persistence tier  Building web components such as forms, menus, templates, localization, and.
Since Spring is so configurable, it almost provides you with too many choices of how to implement your solution.
It’s an extremely flexible platform for development, but it can be difficult to make a good decision on how to move forward.
The more choices developers are faced with when attempting to make a decision, the more difficult that decision becomes.
Some developers may just begin to select a configuration option at random, or start experimenting with several, comparing the results.
All of this takes time and can really hold up a project.
Spring can wrap or enable access to other APIs, even though you’re still working with those APIs and platforms to some degree.
A crucial tenet of Spring is providing tem­ plate beans for complex APIs in order to help simplify them.
For example, the Spring JDBC API component, JdbcTemplate, provides method calls to query, insert, update, and delete data, which can be as short as a single line.
Here’s the Spring JDBC template method to fetch a single value from a SQL statement:
Simple, isn’t it? The JDBC template does all of that boilerplate work for you and throws a translated Spring runtime exception if the query fails so that you don’t have to write tedious try ...
Spring eliminates the layers of exception hierarchies such as your application datalayer exception, service-layer exception, and web-layer exception.
Sound familiar? If not, it’s likely because you’ve been working with Spring, which pioneered using runtime exceptions over declarative ones.
Another way Spring helps is by providing factory beans to easily configure enterprise APIs.
Those of you who’ve configured Hibernate applications by hand will appreciate Spring’s ability to set up Hibernate this way:
We may abbreviate those names because we know that most developers can use an IDE or even Google to look up the packages of well-known classes such as the one above.
By the way, it’s LocalContainerEntityManagerFactoryBean, which is located in the org .springframework.orm.jpa package.
You can use this entityManagerFactory bean to fetch a JPA entity manager, which is the API used to interact with a JPA-supported database:
Note that you use a Java EE annotation here; @PersistenceContext communicates with the entity manager factory and requests that it fetch or create an entity.
Spring can use Java EE annotations to expose and consume resources.
Somebody still has to configure JPA for the project, come up with a persistence strategy, and show the other developers how to use it.
Let’s see how much work you would still have to do by hand in a Spring-based application:
Include dependent JAR files in the project for the JPA API, as well as a number of ORM vendor JAR files.
Install a JDBC data source, and include the JAR files for the data source and the database driver.
Configure a transaction management strategy in Spring to associate with the database data source and JPA.
Configure META-INF/persistence.xml with settings relating JPA to the database using Hibernate configuration settings.
Configure a Spring LocalContainerEntityManagerFactoryBean to install a JPA container, and configure the transaction management to honor the JPA entity manager.
To actually use the JPA API in your project, you’d have to do the following:
Create an entity class that represents the table, annotating it with JPA  annotations.
Create a repository class, and inject it with an EntityManager instance from the configuration above.
Write methods to retrieve, save, update, delete‚ and search for entities.
Develop a Spring Service class to provide transactional services that coordinate.
You can see why it takes an average Java, or even Spring‚ development project a fair amount of time to set up a framework such as JPA.
Because the Enterprise Java uni­ verse is a decentralized, highly compartmentalized set of libraries, it has to be wrestled with just to get a basic application in place.
Rapid application development frameworks, such as Ruby on Rails or Grails, narrow choices and implement programming patterns in a simple yet predictable way.
Configuration is a burden also focus on removing repetitious configuration and coding from your application.
You’ve probably met the Java developer who says, “I’m never coming back to Java.
Now, we’re not here to bash any frameworks or approaches.
Most of these platforms use runtime type checking and are based on interpreted languages.
The languages lack a compilation step, and problems usually occur at run­ time, putting more of a burden on testing.
In our opinion, Spring is certainly the biggest leap forward for Java developers in the past five years.
Coupled with tools like Maven, which helps manage project configura­ tion and dependencies, and strong ORM frameworks like Hibernate or JPA, it can really improve code quality and developer productivity.
They’re only as good as the template maintainer’s diligence provides.
Once you create your project from the template, there generally is no easy way to upgrade it.
Plus, you still end up spending time manually configuring Spring for additional features needed by your application.
And unlike RAD tools such as Rails or Grails, where adding a new feature is as sim­ ple as installing a plug-in and following the conventions to use it, this is all done by hand in Spring.
This is a key reason people are moving to these rapid application development platforms.
What Spring and Java need is the ability to make it easier to configure and add fea­ tures to a project, and to remove or hide any generated or mechanical code so you can easily focus on your actual business logic.
Roo configures and manages the infrastructure of a Spring project, hides repeti­ tive code, manages your build process, and generally helps you focus on solving your business problems.
In short, Roo gives Java developers the same productivity that other RAD platforms have.
Roo makes life easier for the average Spring programmer by managing the busy work and implementing the code with sound architectural patterns.
When you ask Roo to set up your persistence tier, it responds by adding JPA, Hibernate, validations, transaction management‚ and a pooled data source.
When you ask Roo to install the MVC web framework, it implements Spring MVC and pre-creates a web framework complete with layout templates, localiza­ tion, themes, menu navigation, and client-side validation.
When you need to send or receive JMS messages, a single command in Roo sets up your JMS listener or templates, and you can immediately get to work coding your sending or receiving bean.
The Roo tool provides an add-on system that enables developers to add new features, such as web application frameworks, databases, enterprise APIs, and more.
You can write your own add-ons and use them for your own projects, or even contribute them to the public directory.
If you don’t like a feature provided by Roo, customize it or remove it.
Roo will do as much or as little as you want.
From a developer’s perspective, Roo pulls the tedious code out of your classes and into files that it manages for you.
For example, your JPA entities will contain only the code that defines the fields, validation rules, and specific logic you require.
Behind the scenes, Roo will implement the setters, getters, persistence management, and even but the advantage of doing so is eliminated for the majority of your code.
To show you just how powerful Roo is, you’ll create and review one of the sample applications provided by the Roo team—the Pizza Shop.
To install the Roo shell, first visit the SpringSource project site at http:// springsource.org/spring-roo and download the latest released version.
All version 1.2 releases should be compatible with the code samples within the book, but if not, please visit the author forum at http:// manning.com/rimple and let us know your issue in the reader forum.
You can verify that both are properly installed by typing.
For Windows users, set your operating system path to include the unpacked Roo dis­ tribution’s bin folder.
On Unix and Mac systems, you can just make a symbolic link to the file roo_directory/bin/roo.sh as /usr/bin/roo, breaking it and replacing it with one from a new distribution whenever you upgrade:
After installing the Spring Roo path into your environment, open an operating system command line in an empty directory.
Roo will respond with a banner and a roo> prompt:
The Roo shell does the heavy lifting of configuring and maintaining your project.
Once launched, you interact with the shell by entering configuration commands, and Roo responds by modifying or creating the necessary files in your project.
The advantage is that an IDE will instantly see changes made by the Roo shell.
In the next chapter, we discuss how to create your own project from scratch.
But for now, we’ll use the Roo script command, which executes a script provided to it by the user.
Let’s use this command to set up a sample application.
To illustrate how much Roo can help you boost your productivity on the Spring plat­ form, let’s take a quick dive into Spring Roo by running one of the sample scripts, pizzashop.roo, provided by the Roo project team.
This file is located in the Roo installation folder called samples, along with a number of other example scripts.
Other Roo scripts To experiment with a more complex model, create additional empty directories and experiment with the following prebuilt scripts:
You can find these scripts in the /samples folder of the Roo software installation directory.
Anything placed in this directory is available for execution using the script command.
The pizzashop.roo sample is a simple demonstration application that simulates a basic pizza shop.
It allows the user to define bases, toppings, pizzas‚ and orders.
Create an empty directory somewhere called pizzashop, and open your OS command-line shell in that directory.
You’ll see Roo go to work, executing commands and building your project.
If you’re watching the directory from a file manager, you’ll see it quickly expand into a fullfledged project structure.
A JPA container, using EclipseLink as the backing object-relational mapping (ORM) API.
Four JPA entities, which are classes that map to tables in databases, namely Pizza.java, Base.java, Topping.java, and PizzaOrder.java.
Four JPA repositories that persist data to the database (commonly known as data access objects—DAOs—outside of the JPA world)
A Spring MVC web application to input and display data, interacting with the four JPA entities via the repositories.
Now that we’ve let Roo do its magic, let’s build the application, launch it, and kick the tires on your new application.
Believe it or not, you’re ready to run the application.
Roo configures a complete Maven-based build, even preconfiguring both the Tomcat and Jetty web servers for you to experiment with.
Let’s use the Jetty web server to launch the application:
Maven replies by building the application, and then runs the Jetty web server on port 8080
Roo configures both Jetty and Tomcat web servers for your testing.
You can also deploy a Roo application on any application server that accepts a WAR deployment.
Just use the mvn package command to generate your WAR, which will be located in the target folder.
Executing the Maven package goal guarantees that you run against the latest changes to your application.
This looks like a typical CRUD-based application, but looks can be deceiving.
Let’s create a new topping by clicking on the Create New Topping menu item on the left-hand menu system.
You’ll see a prompt to enter the name because it’s a required field.
We’ve omitted the full-page view on these images to focus on the important elements.
All pages show a full menu, title bar‚ and footer.)
Spring should have turned the input field yellow and marked it with a triangle warning, as depicted in figure 1.4
Each time you save a choice, you’ll see something like figure 1.5, a confirmation of the saved results as a separate page.
Clicking the edit icon (the page with the pencil) will take you to a page similar to the creation form, except that it’s working with an already persisted entity.
Finally, if you click the List all Toppings menu item, you’ll see a list of the toppings you’ve already entered, as shown in figure 1.6
As you see in figure 1.6, Roo provides paging support.
It also enables viewing, editing, and removing of entities using icons on each row, as well as creating a new one using the new page icon to the left of the list results paging control at the bottom.
Let’s look at a slightly more complicated form—the pizza form.
Each pizza is com­ prised of a base and one or more toppings.
You need to be able to create your pizza and choose your toppings and base from the ones entered before.
The shell has the ability to watch your entities, detect relationships, and automatically update your web forms and controllers with widgets to pick from your related entities.
Start with bases and toppings; create your perfect pizza components.
Create some pizzas based on those bases and toppings, and finally, experiment with placing an order.
You’ll see the Roo client-side validations for invalid data, drop-down lists of related data, and if you take enough time to enter a lot of data, paging support.
Spring Roo even configures your controllers to support JSON-based web service calls.
If you’re on a Unix/Mac machine, and have installed the Unix curl command-line tool, the script even documents several curl commands you can use to test the web ser­ vice side of this application.
For example, to create a Thin Crust base, you’d issue a POST call to the pizzashop/bases URL, passing it JSON data, as shown next:
Whenever you see the line arrow icon don’t hit Return; just keep typing.
This is in contrast to the Unix OS line continuation character, \, which can be typed.
Note the data sent in JSON format to create a new pizza base named Thin Crust; it was JSON data.
Curl will respond with the result of the web service call, which is an HTTP 201 response code:
If you open the web application and review the listing of pizza bases, you’ll now see the Thin Crust base appear.
To fetch a list of pizza bases, you’d just issue a GET call to the pizzashop/bases URL:
Remove something and see how Roo asks for a confirmation.
You get these features for free, all by asking Roo to configure Spring MVC and scaffolding your entities.
These are all enabled by various Roo add-ons, some of which are installed with Roo itself.
But if you wish to install your web framework into a number of Roo-managed applications, you may wish to write your own Roo add-on and share it with your developers or the world.
Go to your command window and shut down Jetty by hitting [CTRL]-[C]
This is because Roo’s default behavior is to re-create the database on startup.
We discuss how to customize this behavior in chapter 3
Not bad for just a few lines of Roo script code.
Let’s take a few minutes and review the script that created your application.
The Pizza Shop script file, samples/pizzashop.roo in the Roo installation directory, is approximately 48 lines of scripting text, including comments, but the script does a lot of configuration.
Let’s walk through some of the commands in this script and touch on what they do.
First, the script creates a Roo project, defining the Java package structure that Roo will use to store objects that it generates:
At this point in time, Roo just defines the project as a JAR file—nothing yet tells it that you need a web application configuration.
Roo is flexible and won’t configure more than it needs to.
We describe the work Roo does in depth in chapter 3
The script then sets up the four JPA entity classes—Base, Topping, Pizza, and PizzaOrder.
The entity jpa and field commands comprise the content of most of this script.
We talk about those in chapter 3, as well as the field reference and field set commands, which establish relationships between entities:
These are the objects that talk to the database in the service-based Spring architecture we discussed earlier:
Roo can optionally expose JSON to the web tier if needed.
These commands provide JSON support for the web services we reviewed earlier:
This code literally installs Spring MVC, configures the website layout, builds controllers for each entity automatically, and places the controllers in the web subpackage of the root package:
This setting allows you to use the previously mentioned ~
With only a few lines of Roo commands, you've already generated a complete Spring MVC web application.
Spring Roo will help you configure and manage the bulk of your project, regardless of whether it’s a web applica­ tion or a standalone program, saving valuable time you would otherwise spend wiring together your infrastructure.
Now that you’ve created your application, kicked the tires, and explored the script, let’s dig deeper into the project’s application architecture.
Every application should be designed with a particular architectural pattern in mind so that developers know where to place their components.
A typical Spring web application can be broken down into at least three layers:
Services —Business components that expose services for the user interface layer.
When an application architecture is defined in layers, developers are able to switch each layer’s implementation.
It becomes straightforward to switch persistence strategies or user interface implementations.
Spring, being a component-driven development framework, fits well with layered architectures.
Developers are encouraged to build beans using interface-driven development techniques, defining business method signatures in the interface, and implementing them in a realizing bean.
Spring uses the interface as the contract to the client, so that the implementation can be swapped later.
Defining interfaces also helps developers test their components in isolation, using unit testing tools such as JUnit, which can use various APIs to mock or stub other beans.
It uses annotationdriven controllers, and can integrate with traditional Spring business services or with Active Record–based entities, as you’ll see later.
Spring MVC is an MVC platform, and as such contains all of the views as well.
These views are written in a variant of JavaServer Pages that is fully XML-compliant, and all JSP files are well formed.
These files are known as JSPX files, and are written and saved with the .jspx extension.
Roo also deploys several major Spring MVC features, which we discuss in chapter 5:
Theming—Spring themes provide a way to present the website in several ways.
Localization—Roo installs Spring MVC’s localization support so that you can support multiple languages, allowing you to translate elements of your website so that various native language speakers can use your application.
Roo uses a set of generated tag libraries to handle operations such as displaying result lists, providing smart form elements such as drop-down pick lists, date and time pickers, and rich text editing.
It can generate, or scaffold, web application controllers, views‚ and logic automatically to manage your data objects.
As you're about to see, it can adapt to two major forms of application architecture: services-and-repositories and Active Record.
Roo can provide all of the traditional features of a typical web-based layered application.
Views—Components that display information or provide ways to edit data.
Controllers —Accept incoming HTTP web requests and return responses, generally using views to present the data.
Web service layer—Some applications expose web services, using a convention such as SOAP or REST.
These are analogous to web controllers and views and exist in the same layer as those in this diagram.
Services—Provide an abstraction of business functionality, and are usually coarsegrained, performing a task that may interact with a number of objects in the repository layer.
Messaging integration code using APIs such as JMS may also be defined at this level.
Models/Entity classes—These components represent data that is transferred from the data access layer or service layer upward to the user interface components.
You can even roll your own Spring Beans to represent each of these component types, and wire them together using Spring’s @Autowired annotation, or even drop down to using XML or even JavaConfig to configure them.
It enables a more lightweight, rapid application development approach to Spring development that may provide for even more rapid productivity.
Roo was created to allow developers of Spring applications to become even more productive, and attempt to match the rapidity of development frameworks such as Ruby on Rails or Grails, while not leaving the Java platform.
Though developers can still introduce services and repositories, by default Roo takes the approach of slimming down the required components, as shown in figure 1.9
At first glance, this may seem like a loss of structure.
One of the reasons applications in enterprise Java take so long to deliver is the sheer number of artifacts required.
This might seem counter-intuitive to a typical service-and-repository Spring developer.
But consider that this pattern, the Active Record, has been used by frameworks such as Ruby on Rails and Grails with great success.
In Roo, you can define your persistence objects as Spring Roo entities, and Roo automatically wires up the code to properly validate and persist the entities for you.
You’ll see the advantages of this in the next three chapters, but for now, consider that you’re able to use this feature to reduce the amount of code you type.
Who needs to write boilerplate methods to load and persist data if a tool can do it for you?
Actually, the original Roo platform envisioned that Active Record would take over, just as it has for those Ruby on Rails and Grails application tools.
But a large subset of Spring developers desire service-and-repository layers in their applications.
You may find less code overall for the Active Record pattern, and if you have a large number of model objects that you’re manipulating, the extra work of building repositories and services for each one may be a bit tedious, especially when you aren’t doing anything special in those objects.
But if you truly have cross-entity transactions and you have significant business logic, you may wish to roll out services, and if you don’t want to see your persistence logic held within your entities, you can ask Roo to create repositories.
Roo is flexible about application architecture, and, in fact, it can dynamically re-fit your project using the shell.
Often, you’ll be adding fields to your entities, or adding annotations, and the Roo shell will generate code and keep up with you.
There are so many frameworks to choose from! Luckily, we’ve decided to discuss Spring, a powerful and flexible application development platform that can host a wide variety of applications and make configuring and accessing other frameworks better than doing so by hand.
Then we discussed how Spring itself can even become a chore to configure as you begin to add configuration elements for your web applica­ tion, persistence APIs, messaging, email, and other services.
We introduced Spring Roo, and using a built-in sample script, configured the Pizza Shop Spring-based web application in a handful of lines of configuration code.
We used the built-in pizzashop.roo demonstration script to build a simple application, complete with validation, persistence‚ and a Spring MVC web framework, using only a page of Roo commands.
By running the application, you saw just how much Spring Roo can help greatly simplify the configuration and setup process.
You saw how Roo even exposes JSON-based RESTful web services against the object you’ve created.
That can certainly come in handy when wiring your application to nonweb applications or rich browser clients.
We’ll define a sample project, the Task Manager application, and we’ll dig deeper into the Roo shell.
Visit and get familiar with the information on the Spring Roo project home page, available at www.springsource.org/spring-roo.
You’ll find a link to forums, documentation, the JIRA bug tracking system, the GitHub repository, and a whole lot more.
And by now you’re probably itching to get started on your own Roo-based application.
In this chapter, we use the Roo shell to create and manipulate an application.
You’ll learn where key artifacts are located and define some of the key con­ figuration files and directory structures.
Roo encourages experimentation, so let’s get started by firing up the shell and building a basic Roo application.
You saw in chapter 1 that Spring Roo, with only a few commands, can really make.
As we mentioned in chapter 1, Roo is controlled through a command-line shell.
Let’s use the shell to create a simple training task management application, and introduce some of the major topics we cover in the book along the way.
Using your operating system shell, create an empty directory, taskmanager.
Switch to the directory and fire up the Roo shell, using the roo command.
We do the same thing if you’re at the operating system prompt.
We use the $ symbol to show that we’re on an OS prompt line, rather than executing commands in the Roo shell.
The Roo shell supports code completion, a help command, and hints.
Try it now: hit your TAB key and see how Roo automatically prompts you with a list of commands you can type.1
Let’s try the hint command to ask Roo what the next logical steps are for managing your application.
When you’re finished experimenting with tab completion and hint, type quit to exit the Roo shell.
You can ask Roo to guide you through the project con­ figuration process by typing the hint command:
To do this, type 'project' (without the quotes) and then hit TAB.
Your new project will then be created in the current working directory.
Note that Roo frequently allows the use of TAB, so press TAB regularly.
Roo provides the hint command as a way of guiding beginners in configuring a proj­ ect.
As you progress through the configuration process, you’ll see the hints change— from creating the project, to configuring the database, to creating entities, and more.
Before we go any further, we need to show you how to get a list of all commands in your Roo shell.
Make sure you’re on an empty Roo command prompt, and hit the [TAB] key.
You’ll see the valid commands for your project at this stage:
The web gwt command configures the Google Web Toolkit web user interface.
Finally, web flow config­ ures Spring Web Flow, a directed navigation web technology that rides on top of Spring MVC.
These two commands, which configure JMS messaging and email, are covered in detail in chapter 10
The reason it’s not shown is because we haven’t configured Spring MVC yet, so the Roo shell is hiding the command.
If the entity is backed with ActiveRecord, it will write calls to the CRUD methods on the entity.
Otherwise, it will detect the repository and call methods on the repository instead.
There are several other commands that perform housekeeping for you, including backup, monitoring‚ and scripting.
Roo wants you to specify the root package name for your Java artifacts.
Roo will config­ ure various frameworks to scan for any annotation-driven components (JPA entities, Spring beans, repositories, and controllers, for example) using this top-level package.
Go ahead and type the package name, type a space, and then type a double-hyphen (--)
Roo will prompt you with a series of allowable options:
You want the --projectName option, so start typing the beginning of the option name, pro, and hit [TAB] again.
In the preceding output, the uppercased names represent file paths; SRC_MAIN_RESOURCES equates to src/main/resources.
If you’ve worked on any Maven-based projects in the past, you’ll recognize the path structures, and especially the Maven project object model file, pom.xml.
Table 2.1 outlines the key Maven folders, Roo Shell uppercase labels, and purpose for each one.
Generally, this source code starts in the package named in the project command’s --topLevelPackage argument.
The tests are generally stored within the same packages  as the classes under test.
This includes Spring MVC configuration, views in JSPX for­ mat, style sheets, JavaScript files, and other web tier assets.
You’ll also notice the log4j.properties file installed in the root resource directory.
Now let’s adjust your project configuration, specifically the logging level of your appli­ cation.
First, you’ll ask Roo to tell you about the logging command.
As you can see, the Roo shell contains a help system, which can fetch information about the various commands that can be executed from the command line.
The log­ ging system can be configured by executing the logging setup command.
The uppercased name refers to the path src/main/resources, where the log4j.proper­ ties file resides.
Roo changed the logging level in the beginning of this file:
If you want to be more specific, you can change a particular component’s logging level.
Use the tab key to see what options are available to you.
Let’s say you want to increase the logging for your project files (the nonframework ones) to the level of TRACE.
You could use the --level attribute of TRACE; then‚ using tab completion again, type --package.
Now Roo defines another log configuration entry, just for your project top-level 
Use the logging system to your advantage Spring errs on the side of detail when outputting log messages in trace or debug mode.
Although that’s a lot of potentially useful information, it can prove extremely difficult to dig through the noise to find the one thing you’re interested in.
For example, if you set ALL_SPRING to DEBUG, and want to back off to just the JPA container class, simply change that entry from.
Add as many of these to your log4j.properties file as needed while troubleshooting or debugging.
Roo requires the installation of a persistence configuration, for example, JPA or MongoDB.
For JPA, type 'jpa setup' and then hit TAB three times.
We suggest you type 'H' then TAB to complete "HIBERNATE"
If you press TAB again, you'll see there are no more options.
As such, you're ready to press ENTER to execute the command.
Once JPA is installed, type 'hint' and ENTER for the next suggestion.
According to the hint command, Roo requires that you configure your database.
Type in these commands, each time waiting until the configuration operations complete before continuing:
Believe it or not, you now have a complete working application.
Now, try it out by pointing your browser to http://localhost:8080/taskmanager.
See? You’re pretty RAD yourself, and in only five commands.
Figure 2.1 shows the listing page of your task manager.
Convinced about the productivity you can get with Spring Roo? Wait, there’s more...
Before a major change, you may want to back up your application.
Although you could argue that version control is a much better plan (especially using Git or Mercurial, where the developer keeps a copy of the entire repository on their hard drive) that’s a pretty handy command for quick and dirty prototyping.
Now let’s see how Roo tracks changes it has made to your project.
If you were to look around in your file explorer, you might also find a file named log.roo.
This file is a log of all shell commands typed into the Roo shell.
At the start of each session, Roo date-stamps the time the shell is launched so that you can find out when a particular command was requested.
A snippet from the log file for the application you’re working with would look like this:
If you’re using Git A Roo add-on exists for managing your application in Git.
You’ll then get commands to manage your project from Git, including.
Once you install this add-on, it’s available for all Roo projects.
Working with the Roo shell help logging logging setup --level WARN logging setup --level TRACE --package PROJECT quit.
What if you wanted to run that script to create a new project with the same configuration? Just create another directory, copy the file into that directory (name it something other than log.roo, so it doesn’t get overwritten), and edit the file to taste.
You can execute the script command to create your application:
For assistance press TAB or type "hint" then hit ENTER.
You can imagine how easy it would be to define starter project frameworks with just a handful of Roo commands.
Remember, Roo stores those commands you’ve entered in log files, and you can distribute scripts to other developers to reproduce your application template from scratch.
Of course, those scripts won’t write any business logic, or style a web page, but they at least can get things started for you.
The two ways of invoking scripting are using the script command inside of the Roo shell, and from the operating system, invoking the script command on the command line.
From within the Roo shell, you call the script command, passing it the file to execute:
You can use this technique when doing rapid prototyping; perhaps somebody has created a set of domain object models, and you want to try using them from various front ends such as Spring MVC, JSF, or GWT.
The other way, as you saw in chapter 1, is to invoke the script as you load the Roo shell:
Either way, the Roo shell commands can be stored and shared across multiple proj­ ects.
You can even use setup scripts to configure developers’ Roo add-on environ­ ments and other settings.
Now let’s take a look at some of the rules for developing Roo-based applications.
Now we’ll review the project structure for the taskmanager project, discussing the files generated by Roo.
We’ll also switch the architecture from the default Active Record model to a service-and-repository model and see what additional files have been created.
But before we begin discussing specific project structure, we should cover some basic tenets of how you should manipulate files in the Roo system.
Don’t touch the AspectJ (.aj) files —These files, generated by Roo, are meant to be managed by Roo itself, and may be upgraded when you install newer versions of Roo.
We discuss the ways you can extract methods from the aspects and customize them, write your own aspects, and even remove Roo entirely from your application.
Roo may add methods or settings to these files, so don’t delete anything you think may be used by the Roo system, such as the transaction man­ agement or JPA persistence setup.
Take care manipulating scaffolded objects —Scaffolding is the act of dynamically generating code for a particular object, such as the web pages and controller that expose a JPA persistent entity.
If Roo scaffolds a given object, such as a con­ troller or view, please take care to learn how Roo manipulates the object so you don’t break the bidirectional synchronization between the Roo shell and the source code.
The Roo shell will then generate the same Roo-managed files, such as AspectJ ITDs or even JSPX web pages, being created on behalf of the user as those created by Roo commands themselves.
For Java classes, make sure they live within the top-level package defined when the project is created.
You can use any annotation, as long as you know what it does.
This can be quite handy and save you a lot of time when you are heads down in your IDE.
As we move through the book, we’ll note the artifacts you can modify or should leave alone.
Once you get the feel for what you can change, you’ll be able to move quickly and easily throughout your Roo-managed application without fear of breaking it with simple modifications.
The application you just created, taskmanager, is a fairly typical Spring Roo project, created using Roo’s default Active Record–based entities.
Let’s review each of the major directories under src/main/java/org/rooinaction/ taskmanager.
This aspect contains all of the required Spring MVC controller methods to handle creation, listing, editing, and removing tasks.
Roo also generates views for each of the main create, read, update‚ and list actions of the controller in src/main/webapp/WEB-INF/views:
You also see the ApplicationConversionServiceFactoryBean.java class, which is mounted as a Spring bean on startup and converts entity instances to Strings for the default display of drop-down option lists.
Let’s convert this application to a traditional Spring service-and-repository applica­ tion and see Roo adjust your source listing.
Want to build a traditional layered application instead? You’re actually almost there.
Just open up the Roo shell in the taskmanager project and type these two commands:
Roo automatically creates the service and repository beans, and their respective ITDs:
It injected the task service into the TaskController_RooController.aj class and delegated all code originally written against the Task entity’s Active Record methods to the service.
It also updated all generated entity test files to test the entity via the service and repository instances.
Oh, speaking of tests, we didn’t review the test file directory for entities, org/roo­ inaction/taskmanager/model, located in src/test/java.
Looking at the project files before and after the service-and-repository layer should convince you that you can rapidly refit projects to different APIs with Spring Roo, at a much more rapid rate than it would take to do the same tasks by hand.
Roo generates these files in src/test/java under the org/rooinaction/taskmanager directory:
It contains two major components within the ~.model2 package, the TaskIntegrationTest and a helper class to generate test data, TaskDataOnDemand.
If you run the Maven command mvn test, it will execute the JUnit test, using the TaskDataOnDemand class to generate instances of valid tasks.
The web layer is where Roo configures your web application.
As you can see, Roo generates an organized Spring MVC web application, another task that takes a lot of time to do by hand.
We need to look at the key configuration files Roo uses to manage your application.
Any home page named index.jsp will be served from here by default as the home page of the application.
As with all web applica­ tions, this directory is not visible for browsing.
The web.xml web application descriptor file, generated by Roo, lives here and manages the Spring Web application context.
Remember, ~.model is shorthand for org.rooinaction.taskmanager.model, a helpful shorthand both for Roo itself and for conversations about the project structure.
Spring Roo manages a number of APIs for you when it creates your applications.
They’re managed by mounting them as APIs and services from within the Spring Framework.
Knowing where these files live and what they do is key to the success of any Spring-based project, including one generated by Spring Roo.
Spring configuration files are generally stored in two locations in a Roo project— the business-tier application context directory, META-INF/spring in src/main/ resources and the web-tier application context in WEB-INF/spring, located in the src/ main/webapp directory.
As Roo adds features, such as JMS, email, or Spring Security, it may add files to this directory.
When Roo creates an initial project, this directory contains a single Spring context file, applicationContext.xml.
If you add, for example, Spring Security, it will add an additional context file, applicationContext-security.xml.
Roo config­ ures Spring to look for any files starting with applicationContext and ending in xml in this directory, so you may add your own Spring configuration files as needed here.
META-INF/persistence.xml (in src/main/resources)—The JPA deployment descriptor, which is configured when you configure your database settings.
META-INF/spring/database.properties (in src/main/resources) —The JDBC connection settings for establishing access to a database in Roo, if you’re using a standard JDBC data source.
Review this file to see how the Spring MVC and Spring Security frameworks are mounted using filters and servlets.
Spring Roo configured all of these files for you, without any work on your part, beyond stating preferences in the shell commands.
Better still, if a feature is upgraded, such as a newer version of Spring, a newer version of Roo may upgrade generated files, or change the version property in the Maven pom.xml file.
When you issue a Roo entity command, Roo builds not only the entity class, but a series of AspectJ inter-type declaration files, abbreviated ITDs.
Roo responds by generating the Roo entity as shown next.
This class, which is seen as a JPA entity, is managed by Roo via the @RooJpaActiveRecord annotation D.
It’s defined as a JavaBean due to the @RooJavaBean annotation, annotation.
It contains two fields, description C, which is required and must not exceed 40 characters, and an optional Boolean completed C field.
You were able to quickly surmise this because all of the boilerplate code has been extracted elsewhere, and you’re only looking at the code that makes this class unique.
The files Roo created when you defined your entity mix behavior into the entity class at compile time, and are generated by the Roo shell in response to the annotations that Roo added to the class definition.
To see how these ITDs work, we’ll take a look at one from the Task class.
We’ve mentioned ITDs and other likely unfamiliar terms a lot so far.
The following listing shows the definition of an ITD, Task_Roo_JavaBean.aj.
You may push code into the target .java compilation unit if you wish.
ITDs are not Java classes per se; they’re defined by the keywords privileged aspect rather than class.
You’ll notice that each method or variable is prefixed with the name of the class into which they are being woven—for.
Roo uses the Maven aspectj-maven-plugin tool to compile these ITDs during the compile phase of your build process.
When the compiler sees a definition starting with the class name of a Java class, it weaves the code into that type; hence the name inter-type declaration.
The aspect type Task_Roo_JavaBean mixes code into the Java type Task.java.
In this way, the byte code for all of the methods, variables‚ and annotations defined in these ITDs are folded into the class file of your original Java object.
What do all of these ITDs do for your Task entity? Anything repetitive or boilerplate.
But you’re using Spring Roo; it generated all of that code behind the scenes so that you don't have to.
When you issued the entity command to build your Task, the Roo shell emitted the entity class.
You may even find more AspectJ ITD files than the preceding ones, as Roo evolves to add additional features to the entities you create.
Roo expects you to mostly ignore these generated files and focus on writing your business logic.
But if you open up the ITDs in a text editor, you’ll see it’s the dirty work you’re used to coding yourself.
As you saw, all of these files are created by the Roo shell, which takes direction from special annotations contained within the source file, Task.java.
At compile time, the Maven aspectj compiler plug-in weaves them into the actual Task class file.
Any Roo ITD can be mixed into the class definition so that it appears exactly as if you wrote that code in Task.java yourself.
Roo will create the TaskIntegrationTest, TaskDataOnDemand, and the related ITDs only if you specify the --testAutomatically flag on the entity command, or use the test integration command after the entity is created.
The generated test class and ITD actually spins up the Spring container and runs integration tests against the entity, helping you identify problems with the database design and mapping process early in the project lifecycle.
You can execute the Roo-generated tests within an IDE or by executing the Maven command mvn test.
Roo can even build a multimodule project comprised of multiple Maven projects called modules.
These modules are created to separate your application into horizontal tiers, such as web and business layers, or vertical slices, such as functional business lay­ ers.
A single Roo project can potentially contain several web applications, JAR projects that provide business or infrastructure logic, or other components.
To create a multimodule project, you begin by defining the outer project using the --packaging tag, setting the value to POM:
Roo uses Maven’s pom project type as an aggregator; it allows you to add subprojects below but doesn’t actually create a new deliverable artifact.
For example, to create a JAR-based project to hold Spring beans, you’d issue a module command:
This symbol can be post-fixed with your module’s specific subpackage.
This allows you to define your services within your outer project, separated in their own jar: --topLevelPackage ~.infrastructure.
When you create a module, the roo> prompt will switch to that module, focusing to it, prefixing the module name before the word roo:
You can switch to another module using the module focus command.
For example, to switch to another module use the following:
You can also move to the top-level Maven project by focusing on ~ (available via tab completion, as for all module names):
Mind the currently focused module when working on Roo projects.
Working with modules adds an additional level of complexity to your project, so when beginning just focus on nonmodular web applications.
You’ll do much better adding modules later, when you can appreciate the component models you’re building and how they relate each other.
Now that you’ve configured your project files using the Roo shell, let’s look at how you can open these Roo projects in your favorite Java IDE.
It would be inconvenient if you had to flip back and forth between the command line and an IDE when building applications.
Let’s take a look at the support for Roo projects in both applications.
SpringSource has a version of the Eclipse IDE known as the SpringSource Tool Suite, which we’ll call STS.
Geared toward developing Spring-based applications, STS is chock full of features supporting the Spring Framework, such as.
Spring context editing support—STS provides automatic code fill-in features and namespace support for Spring context files.
Open one of these files in the editor and see the tabs along the bottom, which provide graphical editing features.
But this isn’t a sales call, so let’s discuss the features specific to Roo:
AspectJ ITD support— Part of STS’s support for AspectJ, it will let you show or hide the generated ITDs and provides navigational access to the code written in those ITDs when editing source code or debugging your application.
Refactoring support—STS supports refactoring of code written in Roo ITDs; you can push-in refactor methods out of ITDs and into Java code for customization purposes.
Loading your project into STS can be done with the Eclipse’s import function.
To import the project from within STS, select File > Import...
Then navigate to the directory where the project was created.
Roo projects have a special nature to them, and STS adds special right-click menu options within the Spring Tools section as seen in figure 2.3
There are a number of features directly available to you in a Roo project, over and above the typical Spring application:
Figure 2.3 The right-click menu is enabled when a Roo project is imported into the STS workspace.
You can turn on this feature and then use [CTRL]-[SPACE] to use methods from these ITDs in your Java source code.
The Refactor menu (not shown) —A menu item in the Refactor ...
Let’s take a look in detail at the Roo shell support provided by STS.
The Roo shell is opened automatically when opening a Roo-based project in STS, as shown in figure 2.4
This provides you with a concise view of the objects that you work with day to day.
But to see the generated code, you need to bring up the Filters dialog.
From the Package Explorer, click on the drop-down triangle and select the Filters ...
From the Project Explorer, click on the drop-down triangle and select the Cus­ tomize View ...
Figure 2.5 The drop-down triangle menu, shown in the Project Explorer view.
If you’ve done this before, it appears as a selectable shortcut.
This feature will toggle display of the gener­ ated AspectJ ITD files.
You can see all of the ITDs generated for each arti­ fact.
Viewing the aspects isn’t just a convenience; as you get more used to Roo, you may find your­ self customizing the behavior of a given Roo entity or controller to handle an atypical problem.
That is where push-in refactoring comes in, which is the ability to push code out of the ITDs and into the.
Figure 2.7 The project pane with ITDs Java classes themselves.
Now take a look at another STS feature—the ability to navigate to the woven ITD methods right from the Java source editor.
If you see a special icon to the left of your editor pane, that means that the class has been woven with ITD methods.
You can right-click on that icon and select from several menu options, including the Aspect Declarations pane shown in figure 2.8
In short, support for Roo in STS is first-rate, and it’s improving with each release.
Being a free option, STS is a good choice for developers who are beginning to experi­ ment with Spring Roo, and who want to work with frameworks such as Spring and AspectJ.
Of the two other popular Java IDEs (NetBeans and IntelliJ IDEA), NetBeans doesn’t support AspectID ITD files, so it won’t launch the AspectJ weaver.
It won’t make meth­ ods in the ITDs available in code fill-in features, and will only show the AspectJ files as pure text files.
Any code that references ITD methods directly, such as integration tests, will fail to compile.
This makes it another excellent choice for developing Roo-based applica­ tions.
You can choose to run the Roo shell in the IDE, or you can keep the shell run­ ning in the background in an operating system window.
You will want to turn on the Maven auto-import feature so that you get con­ figuration changes as soon as Roo reconfigures your project.
Unfortunately, AspectJ support, the key enabling technology for Spring Roo, is dormant in the NetBeans IDE to date.
Until a solution arrives that allows devel­ opers to edit code built on AspectJ ITDs on that platform, developers who use NetBeans will have to use command-line Maven or another IDE to work with Spring Roo.
Now we’ll discuss how you can work with your ITDs.
There are three techniques you need to learn to make the most out of the Roo development platform: push-in refac­ toring, pull-out refactoring, and removing Roo from your project.
Each of these techniques is supported from the SpringSource Tool Suite.
IntelliJ also allows you to perform these operations, but we will focus on STS in this discussion.
Push-in refactoring is used to customize and replace the default behavior of Roo’s aspects.
The technique moves a method or attribute from a Roo project to the Java source file.
From there, the developer can modify the method code directly.
Sorting the data to be retrieved to feed a list from the Roo JPA ITD  Adding custom server-side validations to your Spring MVC controllers.
To perform push-in refactoring using the SpringSource Tool Suite, make sure STS is showing the Roo-generated ITDs (see section 2.3.4)
You’ll implement a new business requirement for your task manager.
Every time you mark a task complete, you’ll prepend the task text with (completed) so that it is obvious you’ve done your work.
Open up the Java source folder org.rooinaction.taskmanager.service, and expand the TaskServiceImpl_Roo_Service.aj aspect.
Right-click on the updateTask(Task): void method, as shown in figure 2.10
You’ll then see the Push In Intertype Declaration dialog, as shown in figure 2.11
If you selected the method correctly, only the Task.setCompleted method will be pushed in.
If, on the other hand, you clicked on the ITD itself and not a method or member variable, the entire ITD will be pushed in.
This dialog is a chance to review your pending changes.
Click OK to perform the operation, as shown in figure 2.12
Once the refactoring is complete, you’ll see the method vanish from the ITD, and appear in TaskServiceImpl.java.
This will only happen if your Roo shell is running.
Now you can customize it to prepend your mes­ sage to the task text:
Let’s run the application now, this time on tc Server within STS.
You can then right-click on the server and select Start.
Once the server is started, you can right-click on the application name in the server pane, and select Open Home Page.
If you execute your taskmanager web application again and complete a few tasks, you’ll see the completed message appear when you click on the checkbox and update your task.
Although Eclipse can be clunky at times, STS installs several plug-ins that make developing Roo applications a snap, including AspectJ refactoring techniques, the Spring MVC namespace editor, and Maven editing support.
But if you don’t use STS, you can just cut and paste the code from your AspectJ ITDs, and use your editor’s search/replace feature to remove the Classname.
Fire up the Roo shell and allow it to remove the methods from the ITD.
Roo can then remove the ITD completely if you remove the annotation that created it, such as @RooWebScaffold.
You can actually create your own ITDs and pull code out of your class file into them.
This works as long as the code you’re pulling out isn’t supposed to exist because of the presence of another Roo annotation.
The ITDs you generate need to be marked as privileged aspect ITDs—you can just swap the public keyword with privileged.
Once finished, the method will be extracted into the AspectJ ITD you selected.
As much fun as you might have with Spring Roo, there may come a time when you want to remove it from your project.
Perhaps you aren’t comfortable with supporting an AspectJ-based application platform, or you’re using Roo to prototype your project, but then will switch over to a traditional Spring application architecture.
Leaving Roo, because it’s a compile-time platform, is as simple as several steps:
As outlined in the Roo installation guide, you can leave the Roo annotations in the source code.
That way, if you decide to re-install Roo and continue coding, you don’t have to redefine the annotations.
If you do so, you can actually remove all of the Roo configuration, including AspectJ support, from the Maven pom.xml file by removing the aspectj-maven-plugin plugin configuration entry from the build/plugins stanza.
Other configuration settings are no longer relevant either, such as the AspectJ Maven Plugin, and skipping the scan of AspectJ ITDs, because they’ll no longer exist in the project.
Remove what you wish, unless you think at some point you may want to resume using Roo on your project.
Resources 53 Now let’s review what you’ve learned about working with the Roo shell, aspects, and the Eclipse IDE.
In this chapter, you’ve seen how you can work with the Roo shell to manipulate proj­ ects.
We introduced some of the Roo configuration commands, and explained how they create artifacts or configure project settings.
We reviewed how Roo organizes project structure, including where it stores various configuration files.
If you’re already a Maven or Spring developer, much of this looks familiar, since Roo follows common architectural patterns.
We also discussed the tiers in a typical application, and how Roo provides a more entity-driven model of develop­ ing a data-driven application, using either the Active Record pattern or the service/ repository pattern.
You also worked with the SpringSource Tool Suite to import a project, and enabled the Roo shell.
You experimented with pushing in code from an ITD, and pulling code out to your own ITDs.
We also discussed how to leave Roo if the time comes.
Finally, chapter 5 explains how Roo helps you develop web-based applications, and how you can use those entities you learned about in the prior chapters.
For more internals on Roo from the founder of the Roo project, Dr.
Although out of date, this is a great read to see what they were thinking when they originally architected Roo.
Ken’s interview with Ben Alex provides an audio history of the project.
In part 1, you learned how Roo aids in rapid Java application development.
Most real-world enterprise software applications use some type of database to store and retrieve business data to display on user interface screens.
Data persistence and data access are the main topics of part 2
You’ll also learn how you can create entities and add fields to those entities‚ and you’ll write a JUnit test to test the Roo entity you created.
Validation is another important aspect of keeping data in the database clean.
We’ll discuss how to enable data validation using the Bean Validation Framework to configure automatic data validation in your entities.
We’ll finish chapter 3 by discussing how to create repositories in Roo, including the features of Spring Data JPA.
Entities stored in the database typically have relationships with other entities.
Not all types of data are good candidates to store in a relational database.
This is where NoSQL databases come into the picture; these nonrelational databases have been getting a lot of attention lately.
You’ll learn how to persist data into a NoSQL database like MongoDB.
In the last chapter, we discussed Spring Roo from a developer’s perspective.
In this chapter, you’ll learn how to store and load data from relational data­ bases.
You’ll start by defining object-relational mapping (ORM) APIs and the stan­ dard Java Persistence API, and then learn how to configure persistence in a project using the Roo shell.
Next, you’ll define Roo entities, which are an enhanced version of the standard JPA Entity class.
Next, you’ll use the Bean Validation Framework to configure automatic data vali­ dation in your entities.
We’ll discuss both built-in and custom validations, and how to provide validation messages.
We’ll discuss finders—methods that allow for searching for properties within a Roo entity.
No matter how cool your application architecture is, it often boils down to loading data from a database, editing it, and then saving it back again with changes from the user or external system.
The challenge is to get the data to flow between your objectdriven Java application server and the relationally mapped database server.
The Java Persistence API, or JPA for short, was created to provide a standard program­ ming interface for object-oriented database mapping.
The persistence context—A storage area assigned to an individual session or thread, this is the workspace that keeps track of changes to relational data.
The JPA configuration file —JPA-compliant ORMs are configured using the special.
Spring provides a factory to configure the JPA API, whether or not the Spring application is running as a standalone application or within a Java EE application server like WebSphere or JBoss.
There are a number of books available on the subject of JPA 2.0
Now let’s use the Roo shell to set up JPA.
Then you can get started coding against rela­ tional databases, Roo-style.
Configuring JPA in a traditional Spring project involves setting up various configura­ tion elements and programming directly to the JPA API.
Spring Roo configures all of these features for you using the jpa setup command.
You don’t even have to manually wire up a configuration at all!
In this chapter, you’ll begin to configure your application, the Course Manager, which manages a set of courses for a fictitious training company.
If you’re following along, you can start by creating your own project with the project command, naming the project coursemanager.
Let’s use the jpa setup command to set up your database.
We’ll assume you don’t have a database engine installed on your machine; for simplicity, let’s use the Hyper­ sonic SQL standalone database.
We’ll assume you’ve already set up the project itself with the name of coursemanager and a base.
As we described in the quick-start in chapter 2, the jpa setup command performs a number of configuration steps.
Include the dependent JAR files in your Maven pom.xml configuration file for the selected JDBC driver, the JPA API, and a number of Hibernate JARs (and their dependencies)
Configure a JDBC data source, Spring transaction manager, and a Spring JPA configuration in META-INF/spring/applicationContext.xml.
Configure META-INF/persistence.xml with settings relating JPA to the database using Hibernate configuration settings.
Let’s look at the jpa setup command in a little more depth.
Using [TAB] completion, you’ll be prompted for the appropriate parameters.
The most useful options of course are --provider and --database.
Of particular note, when running Spring Roo on an application server such as WebSphere, WebLogic, or JBoss, you can take direct advantage of a JNDI data source; just put the proper data source name in the --jndiDataSource option.
Please note: Oracle and some other proprietary database drivers aren’t provided by the Maven public repository.
If using JNDI, the data source to reference in your Java EE application server.
You can use several data sources,  each linked to individual transaction managers.
For  each one, a separate JPA environment is set up.
The --persistenceUnit parameter names the JPA envi­ ronment, and the --transactionManager specifies which Spring transaction manager to use.
Rerun jpa setup to change your database configuration You can run the jpa setup command over and over again.
Each time it will replace the configuration entry and reconfigure JPA to support whatever settings you’d like to change.
This makes the ORM implementation changeable without affecting your code, and lets you mix and match combinations of the various persistence providers and JDBC drivers to find the best fit for your application.
Note that this will rewrite your database.properties file, so be prepared to reenter your connection information.
One way this makes your life easier as a developer is that you can quickly get going using HIBERNATE against a HYPERSONIC_PERSISTENT database to provide a simple relational database.
Later, you can modify your persistence provider by running again and selecting another JPA vendor such as ECLIPSELINK or OPENJPA.
When using Google’s cloud database, you would use DATANUCLEUS to support run­ ning Roo on Google App Engine.
Your database properties are configured and stored in database.properties, located in src/main/resources/META-INF/spring.
Colons (:) may be escaped in the file with a preceding backslash (\)
To view, change‚ or set properties, either edit the file yourself, or use the Roo properties shell commands.
The properties shell command can manipulate any properties file, and takes a symbolic --path attribute for the various paths in a Roo application.
Explore it with tab completion to view various files in your application.
Another file Roo creates for you is the standard JPA configuration file, META-INF/persistence.xml.
In the current example, this file passes along configuration parameters to your selected ORM API, Hibernate.
You can use this file to send configuration information to the ORM layer, controlling settings such as schema generation.
When using Hibernate, the hibernate.hbm2ddl.auto property controls whether the tables are re-created on startup.
The settings available include create, create-drop, update, validate‚ and none.
If any table or field is incorrectly named, typed, or configured, throws an excep­ tion and reports the problem.
This is good if you’re using Hibernate against a preconfigured database.
Can speed startup against a known database but often developers choose validate to spot changes in the database that may cause problems against the defined schema.
The default setting, create, drops and re-creates tables on startup.
Change this value to update to allow restarting your application and preserving existing data, since Hibernate won’t delete the data from the tables for you automatically.
Note that this option won’t delete columns you remove from your mappings; it will only add or alter existing columns.
For example, when configuring EclipseLink, Roo defines this property to determine whether to drop or create tables:
As you switch JPA drivers, Roo will define the appropriate DDL generation configura­ tion syntax for you automatically.
Now you’re ready to start creating some entities and writing some code.
You’ll start by defining the courses for your Course Manager application.
The Course Manager application primarily focuses on delivering courses to students.
In this section, you’ll define the Course class as a persistent entity and configure it with the appropriate fields.
We’ll then discuss how to use and test the Course in a Roo application.
Let’s define the Course entity, which will hold your course definitions.
But here’s some good news! The Roo shell has a command for that, jpa entity.
You can open up the Roo shell and execute this:
Roo just created your Course entity, a suite of AspectJ ITDs to manage it, and a set of files for testing purposes.
This includes the integration test and a strangely named series of files labeled DataOnDemand—we'll get to those later.
For now, we'll focus on adding fields to the generated Course entity.
We'll cover the Roo annotations and what they mean shortly, but for now, you need to define the fields in order for this class to be useful to anybody.
Any modifications you make, such as adding additional fields, will take place with that entity by default.
You can set the focus on a particular entity by using the focus command, or use the --class option when creating a field element.
Even though you don't know how Roo does it, you probably figured out from the annotations that Roo provides several automatic services for this entity: something Each of these resides in a separate ITD:
We'll talk about all of those things in a little bit.
But for now, let's go ahead and add some fields to this entity.
To add database fields to the Course entity, you use the field shell command.
This command adds the appropriate variables to your Course.java class, and also main­ tains the various generated methods in your Course ITD files.
With these five commands, you’ve just added five fields to the Course class: name, description, listPrice, maximumCapacity, and runDate.
Let’s take a bird’s-eye view of the Course.java entity Roo just updated.
Let’s walk through each of the key features of the Roo entity defined in the listing.
For each feature, we’ll show the code snippet that corresponds to the feature itself.
For example, the fields you’ve defined via your command are implemented as private member variables:
Roo built this file when it detected at least one private member variable in your class definition, which was annotated with @RooJavaBean.
The @Temporal annotation tells JPA that this is a date field.
Roo did this for you when you defined the field with field date.
Roo also added the TemporalType.DATE parameter when you used the field option --persistenceType JPA_DATE.
Finally, the option, which will help Spring MVC and other user interfaces parse and format the date.
Course_Roo_Configurable.aj, which provides basic Spring bean support when creating new instances of the Course automatically.
You’ll see later in the chapter how Roo can also generate true JPA repositories, in a more traditional tiered approach to application software development.
In that case, a different combination of ITDs are generated.
A common task in programming involves printing the string representation of data within a given object.
This a typical informational method, useful for log­ ging or diagnostic information.
Let’s take a bird’s-eye view of the ITDs as they relate to the Course entity.
Figure 3.1 shows how the generated ITD files relate to the Course class.
All of these files are viewable, and with Roo’s support for push-in refactoring, you can migrate any generated method to the Course Java source file itself and override the implementation.
This approach gives the developer visibility of the key details, such as the course fields themselves, and relegates the boilerplate code to the ITDs; an elegant, but acces­ sible approach.
You can enter fragments of your class name to look up the entries (even using the capital letters only) to locate a class.
And you can use this shortcut (or CTRL/CMD clicking on a class name) to browse the open source frameworks (JPA, Bean Validation, Spring) the entity is based on.
Let’s add one more field: an enumerated data type, courseType.
You’ll support seminars, courses for college credit, and continuing education seminars:
When you create the CourseTypeEnum field, you’ll see Roo change the shell’s focused type to ~.model.CourseTypeEnum, so that your next command, enum constant, operates on that type.
You can just build your Java classes normally, even adding Roo annotations, and the Roo shell will keep up, manipulating ITDs as needed.
Now you’ll add the field to your entity, using that enum type.
Now you can use CourseTypeEnum to define values for your courseType field.
While not always practical, this is handy for values that don’t often expand, such as Boolean selections and static discrete values (active/inactive, normal, warning, error)
In com­ ing chapters you’ll see how to establish relationships between Course and other tables, and how to use the user interface to expose lists of values to select from.
Remember, all of these ITD files are woven into the class at compile time using the Maven AspectJ compiler.
As such, the code is compiled into the Course directly.
Roo projects have the same run­ time dependencies as normal JPA projects, with no Roo runtime libraries.
Now let’s actually write some code to use our Course.
As you’ve seen above, the @RooJpaActiveRecord annotation generated all of the JPA code we need.
In fact, technically it is already built into the class itself.
But rather than make you wait, and in the spirit of testing early and often, let’s use the power of Roo’s Active Record persistence API to interact with your model.
Let’s write some code in the automatically generated JUnit test class, Course­ IntegrationTest.java, to exercise the API.
The Roo shell created this class when you specified --testAutomatically on the entity jpa command.
Here’s a small fragment of generated test ITD code for one of the methods,
This method woven into CourseIntegrationTest, checks to see that the test data is make sure that courses are returned.
We’ll get to how this all works in a moment.
Maven users —Issue an mvn test OS shell command from the root of the Roo project, or issue the Roo shell command, perform tests.
The more adventurous among you may want to use Debug As...
You’ll see a number of tests execute (and hopefully pass)
To review the test output, Maven users can browse the project’s target/surefire-reports directory and review files for each test, ending in .txt, and STS users can review the JUnit Runner output in STS, illustrated in figure 3.2 in the STS JUnit test results view.
We’ll discuss the Roo integration test framework in greater detail in chapter 9
For now, you’ll use it to form a base for running your own integration tests, so that you can exercise your newly created Course entity.
Roo shell and the perform command Not only can you run your tests without leaving the shell with perform tests, but Roo provides some other very useful perform commands:
In this stage, being only a JAR file, the application will merely be a JAR of all classes and resources, but when deploying to the web, this command will create a WAR file.
You might be thinking that this is all smoke and mirrors.
You may also be concerned that the code isn’t optimally written.
To allay your fears, we’ll dig a bit deeper and review the JPA code that Roo generates.
For example, the testPersist(Course) and testFindCourse(Long id) methods in the CourseIntegrationTest ITD exercise the methods persist(Course) and findCourse(Long id)
But if you look inside Course.java you don’t see anything but your attributes.
As we mentioned before, this code is hidden within AspectJ ITD files.
Look at Course_Roo_Jpa_ActiveRecord.aj, located in the org.rooinaction.coursemanager.model package of the src/main/java lowing code:
This means each instance of a Course can persist itself.
Although this method looks simple, the key benefit of Roo’s entity ITD code is that you’re not directly writing JPA code yourself.
In this pattern the entities are treated as first-class objects that contain their own data, and know how to load and persist themselves.
You’ll see later how they can even implement their own validation rules.
If Spring Roo needs to modify the code for persisting the data in a future version, your calling code doesn’t have to change.
And although this is code you’d normally have to write yourself, why should you? It is purely mechanical.
This static method fetches a Course by the primary key value.
Roo works a little harder here; JPA stipulates that if the row isn’t found, it returns null, but Roo also returns null if the primary key passed in is null as well.
And it does it the same way for all Roo entities‚ by default.
Table 3.2 Some Spring Roo entity methods (example uses  as the entity)
Counts the number of rows in the table that backs the Course entity.
Returns a range of courses, starting with the row position (not primary key value) of firstResult, for maxResults rows.
Forces the persistence provider to issue any SQL statements to update data changed within the persistence context.
Resets the persistence context and clears any cached entity rows.
Updates the data in the persistence context using data provided in the entity.
Marks an entity as ready to persist in the persistence context.
Issues a select count(o) from Course o query and returns the result.
Be careful not to use this method against tables with many rows.
Used to paginate results in Roo web applications by default.
May throw validation exceptions if any modi­ fied entities have not yet been flushed.
Also useful in conditions where you want to cancel any potential changes that may have been made in the cache before it is flushed.
The merge operation loads data from the database matching the primary key of the detached entity.
It then replaces any data  in the loaded entity with data from the detached class.
Keep in mind that it over­ writes data from the data in the database that may have changed since the detached instance was loaded.
May throw validation exceptions if the data scheduled is persisted at the time of this call (see section 3.3)
This may not happen when calling this method, as JPA may remove at flush time.
You may use this API to provide your own  JPA methods in the Course.java source code file.
Working with entities 73 The Roo product developers may add more methods in the future.
You’ll get them automatically when you upgrade to the newest version of Roo by running the new Roo shell against your existing project.
You should review all Roo ITDs and become familiar with their APIs, since you can use them directly in code that accesses these classes.
More advanced users can take advantage of Roo 1.2’s repository and service features.
Now let’s write some code against the entity API, using Roo’s support for JUnit testing.
Writing code against the Roo entity API is a cinch.
For example, to get a list of all Course objects in a method, you’d simply have to write.
To load a Course by ID, modify the class capacity, and update it, you could do this:
Roo provides a useful API for the CRUDbased work you usually end up doing in most data-driven applications.
Let’s try adding a course and retrieving it from the database using your pregenerated JUnit test.
In the preceding sample, you create a new Course, set the fields to valid values, and persist it to the database.
You flush and clear your persistence context B‚which executes the SQL INSERT statement to persist the data to the database and clears the cached entity.
This detaches the Course instance, c, but at the same time fills in the primary key value in the id field.
Finally, you query for the same data using the Course.findCourse(Long id) method, and make sure that it was saved appropriately using assertions to check the field values.
Not too shabby for just a few lines of code.
Roo marks the test class as @Transactional (which you can find in the Test ITD), so that the unit tests automatically roll back any changes.
You can test this code again and again without worrying about adding duplicate data rows.
This is a Spring Framework test best practice, automatically implemented by Roo.
Now that you’ve seen some of the power of Roo for creating entities, and some of the code generated by the tool, let’s discuss how to add validation logic to your entity using the Bean Validation Framework.
You may ask yourself a bevy of questions, such as these:
Spring MVC has it’s own validation API, but it’s MVC-based, and doesn’t necessarily suit itself to embedding rules within the entities.
You want to do this, as it helps you to encapsulate the behav­ ior of validation within the entity tier.
Created by the Java EE Expert Group, it was developed to address the lack of a standard validation API on the Java EE platform.
This API uses Java annotations to define specific rules, which are attached to attributes of a Java bean.
Spring Roo supports automatic validation of Roo entities, if annotated with Bean Vali­ dation annotations.
Roo entities are automatically validated when a persist or merge method call is executed.
Any errors will result in the throw of a ConstraintViolationException, which contains all ConstraintViolation instances for errors encountered during the validation process.
With the Roo shell already fired up, open up a source code editor and delete all of the field definitions in the Course entity.
Then add them back in, this time with Bean Validations:
Note: an empty or all-spaces string is still a value.
Note this is a numeric range‚ whereas sizeMin/sizeMax are text-based.
Values are defined by the enum and can only be set as Enum values.
And now the entity contains Bean Validation annotations, as shown next.
Each option in the Roo shell turns into a similar annotation in the Java source code.
If you forget to set them during creation, you can edit the source file and add them later.
To test failure cases, you can write some tests in your CourseIntegrationTest class.
First, you’ll build a simple test to prove that you’re running validations.
You’ll just create a test that defines a Course, and not set any field values, which should trigger the.
If you’re following along, use STS and choose to automatically fix/optimize imports with CTRL-SHIFT-O.
When resolving the exception class, choose the one from the javax.validation package over the Hibernate one.
The test should throw a ConstraintViolationException, which will contain a series of ConstraintViolation instances, one for each error.
In the preceding test, the fact that the test threw this exception causes the test to pass.
For a more detailed look at the errors returned by Bean Validation, look at the more detailed test in the following listing.
In the example, you trigger the validation exception by passing nulls to the name and description fields B and attempting to persist the data.
The Bean Validation throws a ConstraintViolationException, and the framework loads each violation into that exception as an implementation of the ConstraintViolation interface, held in the constraintViolations property.
You create an iterator C and fetch each ConstraintViolation, which contains a constraintDescriptor member detailing the error.
You then test the annotation property of the descriptor, checking the annotation type name.
If the name of the annotation isn’t the class name of your annotation type, in this case javax .validation.NotNull D‚ then the test fails.
A list of the available attributes of the ConstraintViolation is defined in table 3.4
In the case of a hierar­ chy of JPA entities, such as a department and all employees within, this will be the top-level class, Department.
As you’ll see in chapter 5, Roo can configure and generate a web application that includes CRUD operations for your entities automatically.
It generates automatic error handling for form elements, populating the page with messages when these Bean Val­ idation errors occur.
Further, Roo generates client-side validations based on these annotations, which will appear whenever a user attempts to enter an invalid value.
There are a number of validation annotations available in the javax.validation several of its own in the org.hibernate.constraints package.
The validations in table 3.5 are built into the Bean Validation API.
BigDecimal, BigInteger,  String, byte, short, int, long, and wrappers.
BigDecimal, BigInteger,  String, byte, short, int, long, and wrappers.
Define a lower and upper boundary for the range of a number.
Support datatypes such as BigDecimal, BigInteger, String, byte, short, int, long, and the wrapper types.
Defines the integer and fractional digits of a given fixed-point decimal or scalar number.
For Array, Map‚ and Collections, validates against number of elements.
In the current release of Roo, the only validation group supported is Default, so unless Roo entities begin to support validations with multiple groups, this particular valida­ tion won’t really be easily used.
So far we’ve looked at implementing validations, and we’ve seen how Spring Roo automatically executes validation checks before saving an entity.
Now let’s take a look at how you can create your own validator annotations.
Instead of that three-step process we discussed earlier, you can just build a Boolean method and annotate it with the validation.
Here’s the same validation logic, expressed with an @AssertTrue annotated method within the Course entity:
This is the easiest way to build multifield and one-off validations.
The method must have no arguments and return a Boolean value.
The method must have a standard JavaBeans name compatible with a Boolean.
Push in the setPrice method in the CourseDataOnDemand_Roo_DataOnDemand.aj file and set a valid, nonfractional price.
The rest of the samples assume this has been done.
You can test this method with the same test suite; it has the same effect.
Run your CourseIntegrationTest suite to make sure you’re validating appropriately.
As you can see, this mechanism is much easier to deal with than defining your own Bean Val­ idation annotations and validators.
But it may cause other tests to fail, because the Roo test framework can’t introspect the valid values of any method marked with.
Other validation options There are still other ways to trigger validation in any Spring project.
For example, you could either implement your own custom bean validators, or use Spring’s program­ matic Validator framework.
We’ll briefly discuss the Spring MVC validation framework in chapter 5
As you’ve just seen, if you need to validate your beans before persisting them, you can use the Bean Validation Framework.
To fix this, push-in refactor the getNewTransientCourse(int index) method of CourseDataOnDemand _RooDataOnDemand.aj, and return a valid value for the fields you’re using for the assertion.
If you’d like to compose your own grouped validation, just build a validation annotation that’s comprised of the validators you need.
You can get a lot done by using a combination of @NotNull,
Be sparing in your processing power—Just because you can call a stored procedure behind a service to validate an entry in that list, doesn’t mean that you should.
Realize that if you’re saving a collection of objects, this validation will be called on each item within the list, thus causing many calls to the same procedure.
Within this method you have access to other fields in the entity.
Use this technique sparingly because these are more complex to build, and spread out your validation away from the entities themselves.
Now that you’ve seen how to define well-validated entities with the Bean Validation framework, let’s switch gears a bit and discuss how to enable users of your entities to locate entities that they’ve created, using the finder Roo shell command.
Searching for data in a database-centric application generally involves writing a lot of queries: fetching a list of items, pulling back a single item by a particular key, joining data together from various tables.
In pre-ORM days, people wrote a lot of SQL to do this task.
But JPA aims to simplify the query process by providing the JPA-QL  (JPA Query Language) API.
This API treats the database as an object graph, but still allows you to express que­ ries in a SQL-like language.
Here’s an example query, which fetches all Courses within a range of priorities:
There are some key differences in the way regular SQL and JPA-QL operate:
Use the name of the entity in the query and the mapped table will be substituted at query time.
For example, query patterns collections, developers can define JOIN statements to query between associa­ tions.
JPA-QL will actually write out the proper SQL joins or queries to pull the data from the related tables.
Since JPA-QL runs on top of JPA, it manages all connection information for the developer through the persistence context.
Developers need not concern them­ selves with setting up and tearing down connections.
Now you can write your own JPA-QL queries and place them in methods on an entity or service bean object.
Let’s look at how easy it is to have Roo write them for you.
Roo finders provide methods to search your entities, which are attached to the entities automatically like the JPA methods defined in the beginning of this chapter.
You cre­ ate them with the Roo shell using the finder command.
There are generally two steps involved in generating a finder: First‚ you get a list of all of the methods that Roo can generate for your entity.
Let’s take a look at an example that implements the search we just discussed, one that searches the name field in your Course object.
First you’ll ask Roo for a list of finders that you can generate:
This is simply a mechanical list of all finders Roo can generate for you, filtering on the fields that contain the search term name.
Let’s use finder add to create a method that uses the SQL LIKE keyword, comparing the value passed to the name field, findCoursesByNameLike:
Spring Roo adds a parameter to the @RooJpaActiveRecord annotation, finders, that.
The shell then generates the finder and places it in Course_Roo_Finder.aj, where it’s.
Let’s take a look at the code that the Roo finder add method set up.
This makes the like command search anywhere in the name field.
Instead of writing the JPA-QL queries yourself, Roo can generate them for you, saving you a significant amount of activity.
Here’s the test that exercises the finder, which we’ve added to CourseIntegrationTests:
Most of that test method involved test setup, but in the end it resulted in a one-line call to your pregenerated finder.
Note the fact that after you call the finder, you chain want a single result or a list, so it lets you choose.
The finder command includes the --depth option, which lets you ask for combinations of finders for several fields at the same time.
Keep in mind that the output begins to get a bit voluminous after a depth of two, or with entities that have a large number of attributes.
You can use the --filter method to list the attributes you wish to see, separated by commas, to limit the output.
Let’s see the finders Roo can generate for a combination of both the courseType and runDate fields:
The one you’re interested in is findCoursesByCourseTypeAndRunDateBetween, which finds any course of a particular CourseTypeEnum within an offer date range.
This command results in the following additional finder method in Course_Roo_Finder.aj:
Now finding all courses of a particular type, within a particular date range, is as simple as calling the static Course method findCoursesByCourseTypeAndRunDateBetween, passing three parameters, the CourseType enum value, and a minimum and maxi­ mum date to establish the search range.
The finder list command is simply there to make your job easier by showing you potential combinations.
You can even tie three or four fields together, if you know the pattern.
In this way, you can save yourself from having to write boilerplate JPA query code.
Since finders are added to the entity along with the persistence code and validation rules, they help you to contain your complex data query logic within the entities themselves.
But using the finder to generate the bulk of your code, you can always use pushin refactoring to bring the code into the entity itself, and then modify it to suit your needs.
You could also use more advanced features of JPA, such as querying by exam­ ple, which are beyond the scope of this book.
Roo repositories are built using the relatively new Spring Data API.
Spring Data provides support for dynamically generated proxy classes for a given entity, and those classes handle all of the methods you’re used to coding by hand (or using in the Active Record entities)
There are no methods defined in this interface; it exists merely as a holding place for the @RooJpaRepository annotation.
These two files may be a bit baffling to you if you’re used to coding your own reposito­ ries.
Roo uses the typical Spring pattern of annotating the repository with it also extends it with two additional interfaces—JpaRepository and JpaSpecificationExecutor.
Let’s take a look at each one, starting with JpaRepository.
These are all methods to search, save, and remove data from the entity.
This interface provides access to the Spring Data features for providing criteria-based query and paging support.
The methods accept a Specification class, which is used to define the search criteria to pass to the repository to find, sort, and page through a list of entities, or fetch a single entity.
For example, to provide a predicate that expects a non-null run date:
To use the specification, you just need to call the static CourseSpecifications.
This approach is similar to writing criteria-based JPA queries, but is in marked contrast to Roo finders, which are attached normally to Active Record entities annotated with.
One of the most powerful features of the Spring Data JPA API is providing annotationdriven queries.
Since Spring Data builds the implementation class at runtime, you can define methods in your interface that Roo can use to implement custom queries and even updates.
You can define a query method in your CourseRepository interface to find all student registrations for a given student and date range (we define the Registration entity in chapter 4, but this code shows you more complex queries):
Roo implements the code for this method at runtime, based on the Spring Data annotation, and the type returned is defined as the return type of the method, List<Registration>
Note that you’ve also passed the @Transactional annotation, and marked the query as a read-only transaction.
In this example, you’ve marked your interface method with @Modifying to signify that you’re expecting a data manipulation statement, not just a simple SELECT statement.
You also define your method with @Transactional, so that it’s wrapped with a read/ write transaction.
Spring Roo builds the implementation classes automatically, based on a Spring configuration file in META-INF/spring named applicationContext-jpa.xml.
This file contains the Spring Data XML configuration element, <repositories/>, which scans for and mounts interface-driven repositories:
The package defined in this Spring XML configuration element is your root project.
For more about the Spring Data JPA API, visit the project website at http:// mng.bz/63xp.
As you’ve seen, you can use repositories in a more traditional Spring layered applica­ tion instead of applying the Active Record pattern.
Roo even rewrites your automated entity integration tests automatically, when it detects that you’ve added a repository for a given entity.
You can always fall back to the typical interface-and-implementation JPA repository where necessary.
As an added bonus, you can skip the Active Record generation for Roo entities by issuing the --activeRecord false attribute when defining an entity:
Fire up the Roo shell and watch it remove all of those Active Record ITDs.
Follow up by creating a JPA repository and you’re all set.
If you take advantage of Roo’s web interface scaffolding, Roo will even reroute calls in the controller to the repository after you create one.
In the next chapter, we’ll show you how to use Roo’s service support to automatically provide a wrapper service around your repositories.
The examples we used around the Active Record Course object are contained in the github samples repository under the directory /chapter-03-jpa/coursemanager.
This includes the Course ITD, the Course finder, the integration tests for Course, and the finder.
All of these examples work against the Hypersonic SQL database by default, but feel free to re-execute the jpa setup command and switch to your favorite database.
Now let’s review the topics we covered in this chapter.
In this chapter, we discussed the two major ways that Roo provides access to database entities—the Active Record pattern and via repositories.
With this container, you saw that you can define queries using annotations and Java interfaces.
You can also extend other interfaces, such as JpaRepository, which provide automatically generated CRUD methods.
Just think of all the things Roo does for you as a Spring developer:
Roo also uses AspectJ ITD files to wrap entities with JPA persistence code, adding.
Roo gives you the ability to use your own JPA code, or to harness the power of.
Roo has a comprehensive system testing facility, enabled by the Spring JUnit.
You can either execute the standard Spring JUnit Test Runner, or allow Roo to scaffold tests automatically by using the @RooIntegrationTest annotation.
Roo supports adding finders to your entities, which provide results for various searches enabled as simple Java methods.
In the next chapter, we’ll take a look at how to relate entities to each other.
You’ll also see some of the more advanced features of the JPA persistence framework and how you can make them work in Roo.
The online reference for the Spring Data JPA project: http://mng.bz/Q9X4 The Spring Data JPA project home page, which includes references to blog entries by Oliver.
In chapter 3, we discussed how to install Roo’s JPA-based persistence engine, create entities, and manipulate them using Roo’s domain-driven entity ITD methods such Validation API and how to generate search queries using the finder facility.
You also saw how to build Spring-based repositories so that developers who want a separation of application layers can still provide a data layer for their applications.
In this chapter, you’ll learn how to relate entities to each other, building JPA rela­ tionships via the Roo shell.
You’ll use the field reference and field set commands, which establish JPA relationships via various annotations, collections, and references.
You’ll explore several mapping strategies, including one-to-many, many-to-many, many-to-one, and inheritance hierarchies.
You’ll see how to use the reverse engineer­ ing facility to automatically create entities from an existing database.
You’ll then see how to build Spring-based services to expose the repositories and to create a tradi­ tional, layered, service-based architecture.
Let’s begin by reviewing how JPA manages relationships between database entities.
Courses can’t just live in the world all by themselves; they need students, rooms, teach­ ers, offerings, and registrations.
In a relational database, you relate data from one table to another table via special columns called primary and foreign keys.
But in the object-oriented world, you relate entities via references to each other through object references, composition, and aggregation.
To make the process of mapping easier for the developer, Spring Roo provides variants of the field shell command that define refer­ ences between entities.
These commands can map either a single object reference or a collection of elements of a particular type.
Let’s use the Roo shell commands to create and relate other entities to your Course.
You’ll use several relationship types and let the Roo shell configure the JPA annotations for you.
One-to-many Relates a row in a parent table to zero or more rows in a child table.
The relationship can either be defined as bidirectional or unidirectional.
One-to-one A single row in one table is related to a single row in another table.
Many-to-many Rows from each table are related to rows in another table.
For example, tracking the authors for a series of books, where books can be authored by more than one author, and an author can write any number of books.
Many-to-one A reference from a child entity back to its parent.
Inheritance hierarchies JPA supports object-based inheritance and provides several physical mod­ els to map this onto a database.
A sample Course Manager database 95 In your Course Manager application there are more than just courses.
You need to track training programs, tags to describe your courses, students, instructors, and course offerings.
You need to be able to per­ form the following activities:
Although you may not implement all of these entities in the book, this gives you a model to practice with when creating your own sample applications.
We don’t have enough space to teach all of the JPA in this chapter, but we focus on some of the major relationship types that you’ll use on a regular basis.
We refer you to a number of books at the end of this chapter to help you continue your JPA learning journey.
Let’s dive right in and create some entities and relationships.
You’ll start by adding a TrainingProgram entity so that you can group courses together.
Your Course Management application is comprised of a number of JPA entities, related together via a combination of relationship types, such as one-to-many, manyto-one, and many-to-many.
You’ll use this model to put Roo’s entity command through its paces.
The training company wants to offer collections of courses, which they call training pro­ grams.
To support this requirement, you need to add another entity, TrainingProgram, and relate it to your Course entity.
Next let’s create the relationship between TrainingProgram and the Course entity.
You’ll make a bidirectional, one-to-many relationship, meaning that you can navigate from training programs to courses, and from courses to their training program.
First you establish the one-to-many side of the relationship, using the field set command.
This command creates a Course-typed Java set in the TrainingProgram entity:
The @OneToMany annotation tells JPA that a relationship is established between Course and TrainingProgram, so that when queries are issued, JPA can write the proper SQL statements.
You’ve used the mappedBy attribute, which describes the name of the attribute in the Course object that represents the related TrainingProgram.
This is done so that JPA manages the relationship at the many end, which you’ll configure next.
In order to complete this relationship, you need to define the reverse side: the many-to-one relationship between the Course and the TrainingProgram, which you’ll do by defining a trainingProgram attribute using Roo’s field reference command:
Training programs contain sets of courses in a collection named courses.
Courses reference their training program in the reference variable trainingProgram.
Any change to the training program, including adding a course, cascade.
If you use a JPA query to load a training program, JPA will fetch courses for you.
But, in the database, you relate these objects using primary and foreign keys, as in figure 4.3
REMEMBER: STAY FOCUSED! If you restart Roo, or want to switch to adding fields to another entity, you can use the focus Roo shell command to switch the entity you’re working on.
Forgetting to switch back to the Course entity when adding the reference to TrainingProgram will add the reference to the TrainingProgram entity.
You won’t receive a warning because Roo doesn’t know you made a modeling mistake!
Alternatively, use the --class parameter to apply the field or reference to another entity and ignore the currently focused class.
You’ll add the code in listing 4.1 to the TrainingProgramIntegrationTest class, which Roo added when you defined your TrainingProgram with the --testAutomatically option of Roo’s entity jpa command.
In this test you assert that you can store and retrieve a one-to-many relationship between a training program and a related course.
You create an instance of CourseListing 4.1 Testing the TrainingProgram-to-Course relationship.
Course Manager relationships	 99 DataOnDemand, which is used to create an unsaved transient instance of an entity B, saving you the work of creating a course by hand.
Next you create an instance of your TrainingProgram C, and set the reference to your Course instance.
You still need to add the course to the collection, so ask the TrainingProgram for the Now, both sides of the relationship are satisfied, from both Java and JPA perspectives.
Next you make sure the data is persisted, and the JPA context is cleared for the ver­ the database, and so that the foreign key can be properly populated.
At this time, JPA needs to create the course that you’ve added to the training program too, so that will generate an insert.
Finally you attempt to reload the training program from scratch and verify that the name that you loaded matches the name that you created, and that you have one course attached to the training program F.
Databases relate these same entities using a primary and foreign key.
To see this in action in Hibernate, you can add the following entry to your log4j.properties file:
The log setting above causes the actual DDL to be emitted in the STS console, and.
Here’s sample output from a configuration using the MySQL database, which includes both primary and foreign key definitions:
As you can see, you can focus on configuring and manipulating Java objects, and let the persistence layer figure out how to generate the appropriate SQL statements, both to create and manipulate your database tables.
Here are some tips when dealing with Roo’s relationship mapping commands:
Though Roo generates some baseline sanity tests against your entities, always exercise your entities and relationships before you start coding services and.
Just because the built-in test goes green doesn’t mean it does what you want it to.
If you’re defining a bidirectional one-to-many mapping as you did in the pre­ ceding example, make sure to use the --mappedBy attribute so that JPA keeps the relationship defined with two physical tables.
You may be adding the inverse relationship to the same class if not.
This is an alternate form of mapping for a one-to-many relationship that allows for switching later to a many-to-many relationship without major restructuring of your data.
So, when defining one-to-many relationships, be sure to use the --mappedBy option unless you expect this behavior.
For more information about the details of JPA 2.0 mappings, consult the books we refer to at the end of this chapter.
Now you’ve seen how to define a basic, bidirectional one-to-many relationship in Roo.
Let’s explore some other mapping options, starting with a many-to-many relationship.
The administrators also want to tag courses with a set of keywords, assigning pre­ defined labels such as developmental skills, advanced, beginner, and expert.
The end users would then be able to search by these tags to find courses of interest.
Because tags can be used by many courses, and courses can be assigned a number of tags, the association is logi­ cally defined as a many-to-many relationship.
You have two options for how to define your relationship in JPA:
You can define an intersecting entity that associates Tag entities to Course entities using two @OneToMany relationships.
Although the three-entity solution allows you to define attributes in the intersecting entity, you’ll use the simpler many-to-many relationship instead.
Regardless of how you map the entities, the relational database will require three tables, as shown in figure 4.4
Let’s create this relationship as a bidirectional, many-to-many relationship, so you can easily fetch the courses for a given tag, or the tags assigned to a particular course.
Roo responds by creating the Tag entity and adding the fields, as shown in the following listing.
Next you need to relate the Tag to your Course entity.
Assume your Roo shell focus is still on the Tag entity:
Just use the --class argument to specify the target entity.
The preceding command defines a Java Set collection, named courses, on the Tag entity:
To test your association, let’s add a method to the TagIntegrationTest JUnit test, shown in the next listing, that creates several courses and assigns a tag.
The test is remarkably similar to the preceding tests, except that you use a little more of your DataOnDemand testing framework.
First you create your CourseDataOnDemand object B, which allows you to get access to a number of Course entities, prefilled with.
You also generate a single random Tag object, which is the focus of your test.
Finally, you save the tag instance, which cascades into saving the courses.
To test, you flush and clear the entity manager and then reload the Tag from the database, verifying that it is attached to two courses.
Both the test and the CourseDataOnDemand class have backing AspectJ files.
To define your Course to Tag mapping, you’ll create another @ManyToMany relationship.
But this time you’ll add the --mappedBy option so that you can define this as the inverse relationship.
An inverse relationship provides a way to navigate between entities, but doesn’t automatically persist changes by itself:
The inverse relationship, defined on the Course entity, looks like this:
As you can see, the mappedBy attribute defines the name of the set within the Tag entity and establishes that Course is not in charge of persisting the Tags.
In a bidirectional many-to-many relationship, one side must be the primary, and the other side must be the inverse side.
The inverse side is indicated here as Course, because it defines the mappedBy attribute.
Now that the relationship is bidirectional, you need to modify both sides to make Java and JPA happy.
The JUnit test method, added to CourseIntegationTest, is shown next.
You’ll notice that you add the tags to the tags collection on course B, and also ask each tag for its courses collection, adding the course to that collection as well  C.
As before, you then flush and clear the persistence context via the course, and try to load the course again to verify that it contains a reference to two tags.
It turns out that this code wouldn’t work if you only updated the tags collection in course.
Try it out by commenting out the two lines that add the course to the tags.
The assertion would fail, because the Course entity isn’t the active side of the relationship.
You need to know which side is active; updating the inverse side may not actually trigger JPA persistence, but updating the active end will always do so.
You picked this side by making the other side define the mappedBy annotation attribute.
For most bidirectional one-to-many relationships, the appropriate active end is the many side, as the foreign key lives in the child.
For many-to-many relationships, the choice is arbitrary and something you need to decide on a case-by-case basis.
Next you’ll deal with registering students for your courses, which will help you learn about inheritance hierarchies and JPA.
Now you’ve come to a very important part: actually registering students and tracking instructors.
Courses would be useless unless you provide both instructors and stu­ dents.
You will define your students and teachers by using JPA entity inheritance.
This feature allows you to define common fields in a base class, while placing fields specific to an entity in the refined subclass.
To implement entity inheritance in your model, you’ll define an abstract Person entity, with typical fields such as firstName and lastName, and then define separate entities for Instructors and Students, which will extend the Person entity.
While you could use the Roo shell to define your fields, in this example you’ll just enter the field definitions in the editor.
You can use the STS Organize Imports feature ([CTRL/CMD]-SHIFT-O) to automatically find your annotations.
This technique is used during rapid prototyping and enables developers to make changes to a data design quickly.
When defining a complex data model, generate your integration tests and prototype a user interface using the scaffolding to see what Roo can support out of the box.
You have several additional entities to create—students, instructors, and course registrations.
Let’s start this process by defining the people who are taking and teaching courses.
Sometimes an instance of one entity is a more specific instance of another (referred to by the moniker is a")
These are exposed in Roo using the familiar entity and field commands.
You have two types of people that you track in your system—students and instructors.
Both have some common elements, so you can define an inheritance hierarchy to collect the common elements in a parent entity.
You’ll define this hierarchy using three entities, as shown in figure 4.5
You’ll use Person to hold common elements: address information and a name, for example.
For Students, you need to track dietary preferences and emergency contact information.
You’ll also need to track your Instructors’ tax ids, and whether they are still active trainers within your organization.
You’ll define these attributes in the Student and Instructor entities, which you’ll inherit from Person.
From the Java side, this is a straightforward inheritance design.
Student and Instructor entities can simply extend the Person entity.
But JPA needs additional information to map this hierarchy to a database.
Table 4.2 outlines the mapping options, which you can specify with the Roo entity attribute, --inheritanceType.
One important issue with Roo and the hierarchical relationships is that it doesn’t completely support all settings in the entity shell command.
For example, Roo doesn’t have a command to let you configure the discriminator for the SINGLE_TABLE model, so you’ll just have to edit the classes and add the proper annotations yourself.
SINGLE_TABLE Puts all data from the parent and child classes into a single table.
Each row is identified with a discriminator that defines which entity to create when fetching the row from the database.
Note that each field must be nullable in the child classes, so that the SQL statement can insert the row without those columns.
All parent entity data is defined in each physical child table.
Fields can be nullable or required in the child tables.
The JPA provider will create the parent and child tables for the relationship, and use SQL joins to fetch the data for a given entity.
For this relationship, you’ll choose the TABLE_PER_CLASS option, since you’re not going to query across the different subtasks on a regular basis.
This command is slightly different than the ones before it.
You make the person abstract because you don’t want anyone to create a generic one.
You’ll just add the fields and annotations to this class directly, rather than running the Roo shell commands.
The completed Person entity is shown in the following list­ ing.
Keep your Roo shell running so that it can adjust your ITDs once you save the changes to Person.
You’ll fill it in with the appropriate field definitions in the IDE:
The difference between this and any other entity is minimal; the extends is the only part of the code that changes.
But because of Java inheritance, Student now includes fields from Person.
In JPA, all of these fields are combined into a new table in the data­ base named student.
If your Roo shell is running it will immediately update the ITDs.
Nothing different again, except the fact that it extends Person.
Because you defined both Student and Instructor using the --testAutomatically flag, you just have to run the integration tests to verify their behavior.
From SpringSource Tool Suite, just open up the InstructorIntegrationTest entity and run the tests.
If you want to run all tests for the project at once, either use the Roo perform tests command or Maven’s mvn test command.
If you’d like to write more complex tests, ones that use the Student with other entities, feel free to do so.
Roo uses JPA annotations to define the primary key of each entity, holding them in.
On database engines that use an IDENTITY data type, such as MySQL, you can’t use the AUTO key generation strategy.
When using Hibernate as the persistence engine, your integration tests will fail when running on these databases, due to a database mapping failure on startup (see http://mng.bz/PpLH for details)
You can use another generation strategy, such as TABLE or SEQUENCE (with databases that support it)
The additional code you’ll add to your Java entity class when selecting the TABLE strategy looks like this:
The TABLE strategy defines a table that keeps track of the next highest value for a given entity’s primary key.
The SEQUENCE strategy uses a high performance internal number sequence, which the database will increment automatically when creating the primary key.
On databases that support sequences, you’ll get far higher performance by selecting the SEQUENCE strategy.
Push-In Refactor and Roo will move the ele­ ments for you.
You can make the change above and rerun the Roo shell.
Roo will also remove the getter and setter from the Person_Roo_JavaBean.aj file automatically.
Let’s take a look at the database tables that Roo generated for the Student and Instructor entities.
You configured your database for MySQL using the persistence setup command and then used the mysql client tool to describe your tables.
You can see in this example that Roo changes camel-cased variables to under­ scored table field names when generating the DDL.
Interestingly, if you choose EclipseLink as your JPA provider, you get a slightly dif­ ferent schema:
EclipseLink also uppercased all fields except the primary key id and version col­ umns.
Roo defines a @Column annotation for the id and version attributes, each of which defines the field name in lowercase.
You should always take a good look at your database table mappings and learn to use your JPA provider effectively.
Since you don’t specify the @Column annotation for your fields, EclipseLink’s defaults kick in, which are different than Hibernate’s defaults.
For example, the emergencyContactName field should be defined as follows:
This will cause the proper mapping for the field in all JPA systems, regardless of whether they support Bean Validation.
Again, you see the tax_number and active fields from the Instructor entity and the common fields from the Person entity.
By now you should be able to use the Roo shell to create the empty entity definition and just type in the fields themselves.
Whenever a student registers for a course, you enter a row in the registration table via the Registration entity:
This schema gives you a good combination of data to experiment with.
In chapter 5, you’ll learn to use Roo’s user interface features to build a web-based frontend to this database.
Reverse engineering your database 113 Spring Roo makes it easy to work with JPA relationships and hierarchies.
Remember to write integration tests to confirm your assumptions about related data.
This will help you when you begin to build your web application layer in the next chapter.
What if you’re given a separate database schema, and you need to reverse engineer it into your current entity model? Roo has this covered using the database reverse engineering add-on.
Using the database reverse engineer Roo shell command, you can scan an existing database and have Roo generate entities automatically.
As your database evolves, Roo can keep the database and your entity model in sync.
Suppose you have to interface into a payments system via two SQL tables, invoice and payment.
If these tables exist in your current schema, you can have Roo generate entities for them automatically using the database reverse engineer command:
The preceding command takes several parameters, as shown in table 4.3
As with other entities, you can generate automated tests with --testAutomatically.
This operates on the configured database con­ nection in database.properties.
By default, all tables are included, except those listed by the --excludeTables option.
This option can list multiple tables, separated by spaces, in quotes.
Use this when you wish to exclude a certain table or set of tables.
You’ll need to install a piece of software known as an add-on, which will provide the JDBC driver for your database.
The Roo shell uses this JDBC driver to perform the database reverse engineering process.
But if you’re not using one of those data­ bases, you can follow a series of steps to OSGi-ify a JDBC driver for use by the.
For example, when you run this command against a project that points to a MySQL database, you get this (cleaned up for print) message:
HINT] use 'addon info id --searchResultId ..' to see details about a.
HINT] use 'addon install id --searchResultId ..' to install a specific.
Roo is telling you that the Roo add-on #01 is actually a JDBC Driver for MySQL.
You can install this add-on into the Roo shell so that it can communicate with MySQL.
Hint] Please consider rating this add-on with the following command:
Adding a service layer	 115 MORE ABOUT ADD-ONS Add-ons provide additional functionality to the Roo shell.
We devote two chapters to writing add-ons in this book.
If you’re successful, Roo will generate JPA entities automatically, as well as define a set of tests.
You can now run your suite of tests again, using the Maven mvn test command.
If Roo can properly test the entities, you can then write further tests to assert whether your mappings are properly defined.
Reverse engineering tips The Roo reverse engineering features heavily rely on the quality of the database schema.
If your schema has nontraditional database keys, mappings, or data types, expect that you might run into trouble.
Roo defines your database schema data in a file under src/main/resources, dbre.xml.
This is an XML file that is managed by the database reverse engineer command.
To detach a Roo entity from the reverse engineering system, you need to perform the following steps:
Copy the field definitions from the Entity_Roo_DbManaged.aj file into your entity Java class, or use the push-in refactoring feature in STS.
Rerun the Roo shell, which should delete the unused ITD.
So far, we’ve looked at how to create your own entities and database elements, and how to relate them to each other using one-to-many, many-to-one, many-to-many, and inheritance mapping strategies.
You also saw how to reverse engineer them from an existing schema.
Roo makes coding applications using this persistence model rather easy—just create or look up entities using their ITD findbyId, merge, persist, and remove methods, or define a finder.
You could code this logic directly in a web-based controller, for simple applica­ tions.
And Roo actually will do this automatically, using the web scaffolding feature we discuss in chapter 5
But you can also take advantage of your Spring platform and define business methods so that you can expose services to your web and other client tiers in a more organized fashion.
Now let’s use that technique to define a service layer in your Roo application.
If you recall from chapter 3, Roo can provide repositories to back your objects, rather than using the Active Record approach we’ve been focusing on.
You were able to cre­ ate repositories, based on the Spring Data API, that you could then inject into other Spring components.
You can define services in your application in two ways:
Using the service create command, which fronts one or more entities and/ or their repositories with a Spring service bean automatically.
Both approaches give you a traditional Spring bean for wiring to components such as controllers and web service interfaces.
Your services can either directly interact with your Active Record models or use a repository.
Roo will automatically detect the correct approach and write the service code appropriately.
Defining a service to expose the Course entity is quite simple:
CourseService_Roo_Service.aj—Contains the method signatures for the methods you’d normally find in your Active Record API:
Any userdefined business methods can be defined here, provided you expose the method definition in the CourseService.java interface:
In this aspect, which we omit for brevity, the CourseServiceImpl is weaved with the annotation, marking all methods transactional by default; also the code for managing persistence is woven into the class.
For repository-based entities, methods delegate to an injected Repository bean:
If you want to write your own service methods, Roo has already provided the interface and a stub implementation class, so you can place your signature in CourseService and the implementation code in CourseServiceImpl.
Your service methods will just come along for the ride.
Again, Roo saves you a lot of time and coding effort.
You may find that you want more control over your persistence code, or want to access JPA or provider-specific features yourself.
Since Roo is a Spring JPA application devel­ opment platform, there’s no reason why you can’t use JPA code yourself.
If you’ve reviewed the entity ITD files, such as Course_Roo_Entity.aj, you’ve seen that Roo uses an entity manager object to do its work.
You can also access the entity manager and make calls yourself.
There are two basic approaches you can use to gain access to the entity manager:
Tell Spring to inject an entity manager into your repository.
You’ve already seen the first way in your Registration.java custom query method; instance.
That’s great if you’re in the middle of coding against the Roo APIs in your own service, and just need to make a single call to JPA that isn’t provided by the ITD.
But if you wanted to move your query into a formal Spring Repository, and sepa­ rate it from the Roo entity itself, you need to.
Create an interface to define the repository with the finder method signature.
Implement the interface and move the finder implementation method into it.
Inject an entity manager using the Java EE @PersistenceContext annotation.
The next listing shows this technique, defining both the CourseQueryRepository interface and an implementing class, CourseQueryRepositoryJPA.
The finder method is largely the same as it would be in the finder itself.
The difference is that you’re starting to use some of the more familiar Spring Framework conventions.
First you define a business interface, CourseQueryRepository, to define your exposed Spring bean, provides translation of all persistence exceptions to Spring’s DataAccessException exception hierarchy.
You mark the method as @Transactional, in case the method is called by any external services.
You can now use the CourseQueryRepository bean by autowiring it into your controllers.
You don’t even need to use Roo’s entities, con­ trollers, or services.
You can treat Roo like a big army knife; use it as you see fit.
A word of warning, though: Roo may not support the automatic generation of webbased applications based on handwritten services and repositories.
The scaffolding feature in chapter 5 will only work against the Roo-generated ITDs.
Finally, we should point out that you can even use Roo with JDBC.
Just configure your Spring application with the appropriate JDBC driver and data source, and then start using the Spring JdbcTemplate API, or MyBatis (a common SQL-mapping API), or even a non-SQL database platform.
You may not get all of the baked-in features of Roo, such as automatic website generation, but perhaps future add-ons will support these APIs.
If you query that data using SQL before it’s been written, you may not find the data you’re looking for.
Always be careful about using method on the entity or entity manager before executing SQL queries.
Normalization kills query performance —Because relational data is normalized, or factored in to the least duplicated form, it can become hard to query across a number of entities.
Consider the performance issues with querying an overly normalized database that leads to a crazy 10 table joins.
Each column must be defined with a specific type, and the database engine optimizes indexing and performance around this structure.
Difficulty querying large volumes of data quickly —Although some database vendors have rolled out text searching capabilities, and other developers are using tools such as Lucene to index their data, databases themselves can’t quickly search through large volumes of loosely structured text without scanning vast amounts of data.
This makes them less than ideal for searching through content stored in XML or JSON format.
The term NoSQL was coined by Carlo Strozzi in 1998 as a name for his nonrelational, RDB derivative database.
This project is ongoing, and can be visited at http://www.strozzi.it.
For these and other reasons, the NoSQL movement was born.
A number of types of NoSQL databases have been developed, but they generally fall into several types, as outlined in table 4.4
Each entry in a document store is a single document.
Data is related in a node-to-node graph struc­ ture, and can be quickly navigated across these nonfixed relationships.
Great for storing associations of data elements where the net­ work of data can be reorganized quickly.
Places focus primarily on the column, rather than collected rows of data.
Powers huge websites such as Facebook, Twitter, Digg, and oth­ ers.
Google pioneered column-based storage with BigTable when indexing the internet through linear means proved too difficult.a.
If the world is a hashmap, this is your data­ base.
The objects can be structured in any way possible, such as primitive values or serialized objects, and are fetched by unique keys.
Facebook created Cassandra, a column store NoSQL database, and open sourced an implementation.
We won’t get into the religious debates about which NoSQL variant or engine to choose in this book.
But as Roo supports at least one (at the time of publication) NoSQL database, we will show you how to use it as a database store.
As discussed earlier, document store NoSQL databases treat each element as a search­ able document.
To use this data store, you’ll need to install a MongoDB engine, configure it, and then use a variant of the entity command to create your Mongo-based entities.
Native MongoDB data is stored in a JSON data format, and can be accessed using a number of APIs.
Here’s a sample code snip­ pet from this client that creates and then retrieves a document from the data store:
The first block of code creates a new element in the newly defined db.people object.
The data held within it is defined as a JSON string.
We didn’t have to predefine the object, or field definitions, or even the database.
Like other servers, you’ll install the database engine and client by downloading it and configuring it as a standalone service.
To install MongoDB, visit the project website at http://mongodb.org and down­ load the server for your operating system.
We’ve used the OS X utility, brew,2 to install it on our machines with a minimum of fuss.
You’ll also have to configure an empty database directory, /data/db by default.
After you’ve created several documents and experimented with the client, you should be ready to build your first MongoDB­ based application.
Our tutorial assumes that you’ve configured a working MongoDB database and that your mongod daemon process is running when you work with MongoDB and Roo.
Obviously, Java programmers need a bit more structure than that.
First of all, they deal mostly with classes in the real world, so one way of approaching a MongoDB imple­ mentation would be to serialize and deserialize JSON using a Java POJO.
To build your course with Mongo support, you’d first set up your MongoDB database layer:
This configures support for MongoDB, assuming that the engine is running on the same machine, on the default port.
You can use parameters to adjust your MongoDB settings, or edit them later in database .properties.
You’ll start by defining the entity with the new entity mongo shell command:
Comparing this entity with the others, the major difference is the @RooMongoEntity annotation.
Beyond this, you can treat it the same way as your other entities.
Let’s add some fields and a relationship to a simplified Offer object.
Next, you’ll define your Offering POJO, for embedding within your Course:
Note, this is just a simple Java POJO which you’ll embed into your database.
To enable access to your Roo MongoDB entity, you need to build a repository.
This command will build a CourseRepository interface and build an ITD, CourseRepository_Roo_Mongo_Repository.aj, to back it.
The other methods, such as find(BigInteger), save(Course), and update(Course) are provided by the ITD, which uses Spring Data MongoDB calls to perform the persis­ tence activities.
They’re similar in feature to the JPA repository CRUD methods.
But they act on a NoSQL database, so the method signatures aren’t an exact match.
You should thor­ oughly research MongoDB before writing an application that uses it for persistence.
You can then execute code against the repository, as in this test, which uses a.
Creating a service is the same procedure, whether you are using a JPA or MongoDB repository.
If you aimed your tests against the service, your methods would look similar to the SQL-based service wrapper methods.
Here’s the same test, but focused on a service instead:
The major differences between NoSQL and regular database services are.
Relationships will behave differently and may need special supporting code.
The example above just nests an Offering POJO within each Course, and doesn’t attempt to create a true two-way relationship similar to JPA.
This feature is quite new, and may change in the future.
But SpringSource is commit­ ted to the Spring Data API and to supporting both SQL and non-SQL data stores.
For more information, please refer to the Spring Data project and the various subprojects for databases of interest.
In this chapter, we discussed how Spring Roo enables quick creation of JPA relation­ ships and hierarchies.
We showed how to work with transactions, and to create a tradi­ tional layered, service-based architecture that you’ll usually find in other web-based applications using services and repositories.
We also discussed the support in Roo 1.2 for MongoDB, via the new Spring Data API.
Spring Data will prove to be a huge asset to Spring Roo projects, as you saw in this chapter, and also enhance standard JPA, as you saw in the previous chapter.
Coming up in chapter 5, we’ll begin to discuss web-based application development using Spring Roo.
You’ll configure your project as a web-based application, and learn how to leverage Roo to generate and manage your web user interfaces.
Pay close attention to the various GIT repositories that contain examples for the various features of the API.
With the back-end data persistence out of the way, we’ll switch gears in part 3 to focus on the user interface layer of your application.
You’ll also learn how to web scaffold the entities to cre­ ate web pages as well as RESTful controllers that take care of the CRUD requirements of entities.
You'll also get a high-level overview of the theming concept‚ and we’ll wrap up the chapter with a discussion on localization.
There are several other web technologies, such as the Dojo Toolkit, GWT, JSF, and AJax.
Application security is a critical part of any software application.
We’ll also look at how to enable security event logging so you can log all security events that occur when your application is running.
If you’re like us and have written a lot of web application code, you probably expect to spend a significant amount of time to configure a web application.
Because you want to get started, you may just want to dive right in, install Spring MVC by hand‚ and write some code against these entities.
In this chapter we use a simple Roo shell command, web mvc controller, to install Spring’s MVC web framework, and generate a sample controller and view.
Then we use web mvc scaffold to generate full web pages complete with create, read, update, delete‚ and searching capability.
We review the scaffolding in depth so that you understand how it functions, and to prepare you for customizing the user interface in chapter 6
You’ll see that Roo provides a comprehensive Spring MVC solution at a fraction of the time it would take you to configure your own, and that it installs and configures key usability features, such as layout management and internationalization.
Spring MVC is an annotation-driven model-view-controller web framework that runs within the Spring container.
The key components used by Spring MVC are as follows:
This servlet controls the lifecycle of the HTTP request; it selects and processes the appropriate controller, captures the resulting model, and ren­ ders the correct view.
Controller —Spring relies on user-defined MVC controllers to process the HTTP request.
Spring MVC controllers are just specialized Spring beans; they can use the.
Model—Generally, controllers execute calls to other Spring beans, and then gather results that need to be rendered to the end user.
These results are loaded into a model object, a simple map-based class that can be injected into a Spring MVC controller method.
The dispatcher servlet then passes along this model for rendering by the correct view.
View—A view is the output of a Spring MVC operation, a representation of the results of a given request.
Views can access any object provided in the model, and can be written using a number of rendering technologies, such as JSP, Velocity, FreeMarker, or even using PDF or Excel.
Spring Roo is configured to use XML-compliant JSPs, which are commonly referred to as JSPX views.
Roo’s JSPX views are configured to use Apache Tiles, which is a layout engine that separates boilerplate code such as headers, footers‚ and other panels from the code specific to the view being rendered.
In the next chapter we look at other web frameworks supported by Roo, including Google Web Toolkit and JSF.
It takes a significant amount of time and expertise to completely configure a webbased Spring application by hand.
But as you’ve seen, Roo helps you by handling your dirty work, and for a web project architect there’s plenty of that to go around.
Roo takes care of configuring Spring MVC for you so you can focus on coding your web applications.
Let’s dive in and convert your project to a web application.
Remember the pizza shop example from chapter 1? The MVC setup was only two lines of Roo commands.
In this section, you’ll see how to direct Roo to generate and configure an entire web application structure, even the Tomcat and Jetty web servers, in just one command.
We’ll review components that Roo creates, such as the controller and view, and explain how to pass model information to the view for rendering.
When Roo built your Course Manager application, it just configured it as a jar project.
To get Roo to change the project type to a web application and output a war artifact, you need to execute the Spring MVC setup command:
As usual, Roo just did your dirty work for you.
This directory can contain raw HTML, JavaScript, CSS files, and other static resources.
Table 5.1 shows key subdirectories of this root directory and their purpose.
The overall Tiles page layouts are defined in this directory.
WEB-INF/tags Spring Roo custom JSPX tag libraries, used by views to render pages, forms, fields, and other elements.
WEB-INF/views Contains the view files, which are comprised of JSPX pages and Apache Tiles view composition files.
If you had to configure all of the installed features yourself, you’d probably spend the better part of a couple of days researching and experimenting, perhaps with some cut­ and-paste operations from other projects and examples on blogs and forum posts.
Instead, Roo gives you a good starting place: a fully configured MVC project.
Ultimately you just want Roo to create a controller for you, so to do this you issue the web mvc controller command:
Roo builds the TestDriveController class and view artifacts, and even configures an entry on the menu system as well.
Let’s take a look at the generated TestDriveController, shown in the following listing.
This controller uses the @RequestMapping annotation, which tells Spring MVC to map any requests with the given pattern to methods within this controller.
The classlevel mapping, /testdrive/**, makes sure anything with a URL that begins with /testdrive is handled by this controller.
Each method then provides its own request mapping, defining a unique URL subpattern, based on portions of the path, request attributes, request types (POST, GET), and other options.
This method actually functions, returning a view with the path of demo/index, which Spring’s dispatcher servlet then resolves to a file named WEB-INF/views/ testdrive/index.jspx‚ and renders the JSP file.
Controllers wouldn’t be useful without a way to display the data that they place in their models.
Let’s take a look at the next component of your web application, the view.
Spring MVC and convention-driven programming To better understand what’s going on here, you need to know the underlying conven­ tions.
Spring MVC is a convention-driven API, which means that it processes methods based on the presence or absence of annotations, parameters‚ and return types in controller method definitions.
Here are a few key concepts to keep in mind as you begin to look at some of these methods.
If you define an HttpServletRequest, HttpServletResponse, HttpSession, ModelMap (map of values to render in the view), an Errors object‚ or a number of other components, they’ll be injected automatically.
As you saw earlier, index and post are all annotated with @RequestMapping, and although the post method currently does nothing, it can respond to POST requests to /testdrive.
The index method responds to /testdrive/id, where id is a number.
You’ll see why this is important when we discuss Roo scaffolding in section 5.3
One of the more complex parts of Spring Roo is the way it configures and manages MVC views.
These files must be XML-parseable, so that the Roo shell can manipulate them.
As you’ll see later, Roo can generate and maintain forms and form fields in your views automatically.
In addition, Roo makes heavy use of its own JSPX custom tags to simplify the view code.
This is a pretty compact view file, for several reasons.
First Roo installs several tag libraries—the Spring MVC spring: tag library, JSTL tags, and the Roo-specific util: tag library.
Next, because Roo uses Apache Tiles, the bulk of the page structure is hid­ den within a template.
You’re viewing only a fragment of the page, known as the tile, that represents the display area for your controller.
The page:page tag wraps the page content in a bordered box, complete with a title bar.1 The content is a simple message.
This is actually a Dojo rich JavaScript component, as are the fields that provide client-side validation and dropdown date fields.
You can use Dojo to build your own view with your own hand-selected components.
For now, keep in mind that Roo uses rich web interface components like this to give your web application a dynamic look and feel.
You may change your application’s friendly name by editing that file.
Generally you don’t need to add anything to this file that’s application-specific.
Roo will not overwrite your entries, and will not touch the ones created even by itself—once an entry is created in this file, it’s available for customization by you from that point forward.
When you’re defining your own labels for nonscaffolded controllers, generally you’ll want to place them in the application.properties file in src/main/resources/META­ INF/spring.
You’ll also have to register the filename (without extension) in the p:basenames property of the ReloadableResourceBundleMessageSource in src/ main/webapp/WEB-INF/webmvc-config.xml.
You could place messages in application.properties, as well, but since Roo adjusts that file each time it scaffolds, you could have a harder time organizing your properties.
Issue the following Maven command in your Roo project directory:
The package keyword builds your Roo application, as you’ve seen in earlier chap­ ters.
Choose between Tomcat and Jetty by issuing tomcat:run or jetty:run.
Browse to http://localhost:8080/coursemanager to view your web application’s default page.
If you’re a SpringSource Tool Suite user, you can drag the project to a configured server in the Servers pane and install it in Tomcat or SpringSource tc Server automatically.
If you leave your web server running, STS will automatically redeploy the application when it recompiles the project.
In fact, some developers really dig Jetty because it’s so easily customizable, and it’s quite polite: it even tells you your web application name if you hit the root of the server by mistake! To kick off your application with Jetty, just use.
Running on a different port Tomcat runs by default on port 8080
You can customize what port the Tomcat web server runs on by modifying the plug-in settings within the pom.xml file.
For example, replace the existing plug-in definition with something like this:
Review other options for the Tomcat plug-in by visiting the plug-in’s website at http:// mng.bz/IgJ5
You can edit the Maven pom.xml file in the root of your project, and change the jetty-maven-plugin to take advantage of this feature:
Now every time you perform an mvn package command, Jetty will automatically reload.
There are a ton of other configuration features in jetty-maven-plugin; it’s worth spending an hour reviewing the documentation, at http://mng.bz/1MM6
It can’t automatically figure out what you want the method before it returns the view name.
What if you wanted to render the current time? You’d have to place the current date and time in the Model, so that you can render it in the view.
To do this, you just add a parameter to the index method, Model map, and then use the addAttribute method of the model to inject the currentDate attribute to like this:
When Spring MVC sees the ModelMap class, it injects it into the method automatically.
In the testdrive/index.jspx view file, you can now reference ${currentDate} and.
It is now ${currentDate} - you should be doing something productive.
Figure 5.3 shows the newly customized example, complete with dynamic evaluation from the controller.
How does Spring MVC resolve the right view? When the method returns testdrive/index, Spring MVC delegates to the Tiles view resolving mechanism, passing it a template named testdrive/index.
Look in the WEB-INF/views directory for the testdrive subdirectory, and review views.xml:
It uses the default layout, and the body tile resolves to testdrive/index.jspx.
To use this message in the view, replace the ${currentDate} paragraph fragment with this snippet:
Spring replaces the value of {0} in the message with the model attribute, currentDate, and uses some built-in formatting rules to render it properly.
More complex objects, including things like a list of query results, can be placed in the model map, which is generally how Spring MVC deals with data that needs to be rendered in a view.
You’ll learn more about messages and locales in chapter 6
Ken remembers someone once lamenting about the trials and tribulations of web application development.
They wanted to do all of this really cool stuff, integrating with other systems, doing complex graphical work, and meaty programming.
What do we always do, day in and day out? Suck data out of a database, show it to the user, and let them change it.
In this section we’ll delve into the world of scaffolded Roo controllers.
You’ll see how to generate a scaffolded course controller, and we’ll review each of the generated controller methods and views for the list, create, update, and delete operations.
We’ll also look at how Roo integrates finders into these controllers.
To generate a Roo scaffolded controller and views for a Course entity, just enter the following command in the Roo shell:
The options, --class and --entity, specify the name of the new controller and the entity to use, respectively.
Assuming you’ve already set up the MVC framework with the first web mvc controller command, the output will look like this:
Of course, this time Spring Roo generates a few key files, including.
We’ll focus on a number of these components, but first let’s start by identifying the views contained within WEB-INF/views/courses in table 5.2
This file defines the Tiles layout to use, which is defined in /WEB-INF/layouts/layouts.xml.
These view files are generated and configured using the Roo JSPX tag libraries, which are installed in WEB-INF/tags.
All fields available in the entity are generated as fields in these various view files.
Just as it did with entities, Roo creates the CourseController.java class, but also generates an AspectJ ITD, CourseController_Roo_Controller.aj.
Roo also edits WEB-INF/i18n/application.properties with labels for all fields and the entity name itself for form rendering purposes, and adds menu items to menu.jspx, which was created when Roo generated the web application.
Just as the Course.java Roo entity itself seems a bit simple and empty, so does the actual Java controller.
But that’s because the magic is in the generated ITD file.
Let’s review the generated Controller class, CourseController.java, in the follow­ ing listing.
This controller class manages all operations against the Course entity.
The code to implement the controller actions is stored within the AspectJ ITD.
Roo generates and maintains the JSPX pages based on the @RooWebScaffold annotation.
It’s very difficult to write a good system and then keep it up to date by forward- and reverse-engineering changes to the software.
We think that Roo is a different animal because it makes a distinction between user-editable arti­ facts and generated ITDs.
If Roo generates a normal file, such as a class like CourseController, or a localization file like application.properties, it won’t overwrite it later.
But if Roo creates a Roo-managed intermediate file, such as the Course_Roo_Controller.aj AspectJ ITD, it’ll manage it entirely via the Roo shell.
The gray area in all of this is the view technology.
Since Roo generated the views as user-editable elements, any changes made by a developer must generally be honored.
In fact, if you change your templates around, modify the HTML code, or otherwise modify the boilerplate code, Roo will allow this to happen.
Now, let’s take a look at the various views and controllers generated by your web mvc scaffold operation.
We’ll review the files based on the operations they provide.
The GET operations your scaffolded controller supports are both a list of all of the Course objects and the display of a single Course.
Both operations are supported by different generated controller methods and views.
We’ll look at both in turn, starting with the listing operation.
The list operation is called by performing HTTP GET operations on http://localhost :8080/coursemanager/courses.
First, review the next listing to see the list method Roo generates in the CourseController_Roo_Controller.aj file.
When you ask to GET tasks based on this URL, the controller fetches all of the tasks and places them in ${courses} to render in the view.
The controller supports paging results if the page and size parameters are passed as parameters to the URL; otherwise it fetches all rows.
The controller also tells the view how many pages of rows were available, if paging was enabled.
You’ll see the syntax {id} in many mapped URLs; this refers to the primary key in the path.
The list method returns the value courses/list, which resolves to the JSPX view file list.jspx in the WEB-INF/views/courses directory.
If you’re familiar with Spring MVC and the form taglib, you’ll be pleasantly surprised by the use of tag libraries, which shorten the amount of code in the next listing.
For more information about REST, start with the excellent Wikipedia article at http://mng.bz/1PMN.
The first thing you might notice is that you’re not defining a full JSP page.
In fact, the file looks a lot more like an XML document than an HTML page.
That’s because the combination of using Apache Tiles to render page fragments and the heavy use of JSP tag libraries reduces the view to a tighter, more compact version of the usual view.
That is, except things like those strangely long id and z fields.
Roo composes this tile fragment using the JSP tag page:list.
This tag sets up the container for the next tag, table:table, which renders an HTML table of results.
The results, coming from ${courses} in the controller, are rendered using table:column elements.
All of these tags are available for review and editing in webapp/web-inf/tags.
The resulting output of the course listing view should be similar in appearance to figure 5.4
As you can see, the results are paginated, with alternating grey and white bars for the rows.
The list is wrapped with a box that’s entitled List all Courses, and if you click on the List all Courses drop-down arrow, it collapses the entire view.
Icons are shown for various actions, which all result in further calls to methods in the course controller’s ITD.
Displays a form that you can use to enter the data for the new course.
Clicking on any of these icons navigates to the other actions.
You should spend some time getting familiar with the custom tag libraries, such as.
We’ll continue to customize the user interface as we go through the CourseController example.
Now let’s see how you can review an individual course.
If a user clicks on the  icon for a given course in the web application, the browser navigates to another URL, passing the primary key as part of the path.
The method mapped to this URL pattern is called show.
There’s a bit of interplay going on between this view and the list view in listing 5.5
The list view’s table:table tag generates a table of results, each of which contains a link to edit an individual Course.
The show method returns the value courses/show, which resolves to the view file in the WEB-INF/views/tasks directory named show.jspx.
The page looks similar to the list view above, but you’ll notice that the page is now sur­ rounded by a page:show tag, and that each field is no longer rendered by table :column, but by a field:display tag.
This form is rendered as a read-only view of a single Course.
Roo automatically shows this view if you click on the  icon for a given row in the list view, or once you create or update a row using the Create New Course menu item or click the icon.
Of course, it would be rather difficult to list or show tasks without actually creating one.
Let's see how to create a Course, using the HTTP POST operation.
Spring MVC follows a very specific pattern for form-based processing, illustrated in figure 5.5
As you see above, creating new entities requires first the display of a form that can edit the data.
To create a new empty Course and edit it with the form, users would select the Create New Course menu item, which requests /courses?form.
This URL maps to the createForm controller method in the Course_Roo_Controller.aj ITD:
This instance is then added to the model map as course and the JSPX Tiles view rendered is courses/create, which ren­ ders the view fragment located in WEB-INF/views/course/create.jspx, as shown next.
The HTML form tag is generated by the <form:create> tag, which establishes that the form will be submitted using the POST method to the URI /courses.
Users with JavaScript-capable browsers will see the automatic rich field generation, including date pop-ups for date fields, and automatic rule validation.
You should get feedback from the web page immediately upon leaving the field.
There are several field types used in the form above.
Table 5.3 lists the field types available in the Roo tag library.
Several validation options available, including regular expressions, future, past, and required.
The default for any field not selected by another strategy, and for String fields less than 30 characters in length.
Falls back to rendering reference fields if no collection rows found.
This shows a create link to build a new instance of the referenced type.
Used for String or large object fields if they exceed 30 characters.
An example exists in the Roo sample petclinic.roo: in the VisitController_Roo_Controller.aj ITD:
This fragment sets up a <field:reference> tag for the Pet entity within the Visit form.
This is the heart of the forms processing in figure 5.5:
The request accepts all POST requests to /courses, and then validates the data using the @Valid annotation.
The result of the validation is placed in the BindingResult attribute, result, and is interrogated.
If no errors are returned in the result object, you’re redirected to the single-task view, show.
However, if errors do exist, you’re redi­ rected back to the create page (and the errors are automatically displayed)
After performing the POST operation, the MVC framework is asked to redirect after posting to the list view by issuing a browser HTTP response code 302 MOVED.
This forces the browser to browse to a new location.
Push-in the CourseController.createForm method to your Course­ Controller.java and modify the code.
You can then create the course any way you wish and set values that make sense to you.
If you’re manually moving the createForm method, be sure to run the Roo shell to have it remove the ITD-generated one.
The combination of the createForm action, the create.jspx form, and the create action comprise the complete Course creation page and controller logic.
Course mod­ ification is just as easy, and follows a parallel set of files and behaviors.
Let's see how we can perform updates to existing courses in an almost identical way.
Just as the create course process is performed using a combination of the createForm method, create.jspx, and create method, the update course process is performed using an updateForm method, an update.jspx page, and an update action, as you see in figure 5.6
This method is remarkably similar to the create method in section 5.3.3
However, the major difference is that it maps to a GET method that passes a Course ID via the URL path just after /courses.
The updateForm method uses this id field to call the Course.findCourses(id) method, which fetches the entity row.
The method then adds the course to the model map, and redirects to the edit form.
Let's take a look at this form view, courses/update.jspx, in the following listing.
This is a mirror image of the create form pattern above.
The major differences are that you’re submitting your form data to the same URL using the HTTP PUT method and that you’ve embedded hidden form data including the existing primary key field value (known as id), and a version field, which can be used to detect modifications by others after you’ve fetched your data.
The reason this works is because Roo uses a HiddenHttpMethodFilter.
This method looks for an HTTP request parameter named _method, which is.
Spring Roo builds RESTful URLs using this technique, and if you install the.
You'll see an example of this in the next chapter.
Below you see the update method in the ITD, which will save your changes to the course object, or redirect you back to editing the form in the case of an error:
This is the kind of boilerplate code Roo excels at generating, saving you the time to build, wire up, and debug the methods and views.
We are almost finished looking at the basic data manipulation operations.
Finally, we should review the delete course action, so you can remove Courses you’re no lon­ ger interested in.
You can click on the icon to trigger the delete operation.
The HTTP DELETE operation is mapped to a method on the CourseController ITD named delete:
First, the course id passed to the delete method is used to look up the course using findCourse, and then the remove method removes the found course.
The rest of the code within the delete method handles any paging settings, such as the number of rows per page and the number of the current page passed to the original list view, which is where the DELETE operation is generally being called from.
The DELETE operation then redirects the browser to the list operation again, by navigating to /courses.
You can expose the finders we discussed in chapter 3 to your web pages.
Let’s assume a finder is defined on the Course entity to search using the SQL LIKE keyword, which we defined in chapter 3
To expose the finders to your scaffolded controller, you have two choices:
Just annotate the CourseController with the @RooWebFinder annotation (which has the same effect as using the web mvc finder add command)
Once you do one of the above, Roo wakes up and generates the web-tier methods and artifacts:
The shell adds a new ITD, CourseController_Roo_Controller_Finder.aj‚ with two new controller ITD methods.
It also generates input and result views to handle the search and adds the search page to the menu.
This method renders the input form, which gives you a text input field and a submit button.
As you can see, a special Roo form tag, <form:find>, is used to submit a search form.
Though it appears that the form submits to the /courses path, the <form:find> tag actually sends along a hidden field, find, whose value is set to ByNameLike, which is the name of the finder method and is sent via the attribute above named finderName.
Roo can add additional finders by changing the value of this tag.
Once you submit the search form, the finder is executed via the other method in the new ITD, findCoursesByNameLike:
The method calls Course.findCoursesByNameLike(String) and renders the list view again, which now contains search results.
In addition, Roo will keep the scaffold up to date based on changes you make during development.
Although Roo does make some decisions up front, such as the use of Apache Tiles, XML-compliant views, the use of tag libraries, localiza­ tion and personalization, and a number of other features, it does so to make you more productive.
And Roo heavily leverages your Roo-managed JPA entities, relationships‚ and finders.
If you don’t like the way Roo configures web applications, you can choose to roll your own web interface, but for getting basic work done, the scaffolding process can really do the trick.
Now it’s time to step back a bit and think about how the web framework fits within the overall picture.
Roo controllers can write logic directly against Roo entities or in layered applications.
Although Spring Roo doesn’t expect developers to write software with the level of separation that you saw in section 5.3, you may need to add Roo and Spring MVC to an existing, larger effort.
Perhaps the application logic has already been written as a series of Spring beans, or you may need to expose the business logic to a number of different consumers, from web clients to integration engines and desktop applica­ tions.
In scaffolded interfaces, Roo repositories and services are automatically detected and used.
The rule is to use the repository automatically, unless a Roo service exposes the repository.
In this way, you can easily refactor your data tier to various persistence models without modifying a single line of your scaffolded code.
If you’ve defined a repository for your Course entity, Roo will respond by adjusting the scaffolding calls.
Here’s a fragment of the CourseController_Roo_Controller.ajdelete method with a repository defined against the Course entity:
Here’s the same method fragment with a Roo service defined against the same Course:
Feel free to experiment with various persistence configurations while keeping your scaffolding in place.
You can inject Roo-generated services and repositories into your own controllers by using the @Autowired annotation.
You can then directly access the service as with any injected Spring bean.
In the preceding example, simply inject the CourseService instance and use it in your index method to fetch the number of courses.
If you’re using multimodule projects using the module command, you’ll  need to be aware of the additional syntax for referencing models from scaffolds in other projects.
Roo can scaffold controllers and views against other modules in the same project.
Roo will still detect ActiveRecord models, or services and repositories, and will do exactly the same scaffolding you’ve seen previously.
For example, if you’ve created an entity in a module known as business, which is a JAR-based Roo module, you’d need to change module focus to your web module (here shown as web) and issue the scaffolding command as in the example below:
You can use the project top-level package prefix (~.) in each case to refer to the toplevel package of the module in question.
To execute a web-based project in the Jetty or Tomcat runtimes, you’ll need to do some gymnastics:
This will install the various projects into your local Maven repository and then run the web application, looking for collaborating libraries in the repository itself.
Now let’s take a few moments to review what you’ve learned about Spring MVC and Roo.
You can see just how much power Roo packs into its Spring MVC web framework support.
At the simplest level, Roo generates a template-driven website, complete with JSP tags and a predefined MVC configuration.
For applications that require a ton of data manipulation, scaffolding can save you weeks of effort.
Roo automatically scaffolds all CRUD behavior for you, even providing finder forms and views, if those are defined on your entities.
Finally, you saw that you can easily inject your Spring beans into a Roo controller using @Autowired, so your Roo web applications can support those business logic beans your development team has been building, and so you can keep that logic out of the controller.
In chapter 7, we’ll discuss other web frameworks that can be installed in Roo, such as GWT, JSF, and Vaadin.
You can find out more information on Spring MVC in a variety of resources.
The Spring MVC Showcase sample library, located at http://mng.bz/B91V‚ contains a number of useful samples.
The Spring MVC reference guide contains a wealth of information: http://mng.bz/nZQX.
Once the scaffold has been pushed in, you can do anything you want.
Keep in mind that your views will no longer be maintained against your entity, so any new fields you add must be manually added to your view code.
In the last chapter, we discussed how to build Spring MVC web applications, apply.
Customizing Roo CRUD views 157 In this chapter you’ll learn how to customize your view layer.
We’ll start by discussing the generated scaffold CRUD views, and how to customize them by hiding, disabling, or modifying the field types attached to various form elements.
We’ll discuss how to provide reference data and how to customize date formats, and then dig into how Roo deals with layouts, localization, and themes.
By the end of this chapter, you’ll be able to strike out on your own and customize your Roo web applications.
Let’s begin by discussing Roo’s generated views and how you can customize them.
As you saw in the last chapter, the Roo web interface heavily relies on a number of fea­ tures: Apache Tiles, tag libraries, and Spring’s localization process.
Let’s take a closer look at some of these elements and see how you can configure them.
Before we begin, we need to lay out the rules behind some of the common field and component names.
Later, we’ll discuss techniques for manipulating and hiding pregenerated form elements.
Recall that most elements require an id attribute to identify them.
This id is generally created, for data-based operations, using the following scheme:
For example, your Course entity would generally have the following id:
These HTML id field naming conventions are manipulated by the custom tags to pull various other values.
This is done within the custom tag files themselves, which are located in the WEB-INF/tags directory.
In the HTML form views, all field id values are reduced to _fieldname_id so that they are easily scripted.
For example, _name_id is the HTMLid field representing the name column.
What if I’m building my own views? If you want to benefit from Roo’s predefined localization structure, you need to follow these naming guidelines.
Roo should automatically add labels for the component and fields for any entity you define, provided it’s a Roo-managed entity (@RooJpaEntity,
You can also choose to bypass these conventions, and use the custom tag attributes such as label to define your text in-line.
But these won’t be localized, so it’s up to you to decide whether you want to buck the conventions for more control, or learn them and benefit from them.
To do so, you can modify the tag attributes for the various list and form views.
If you’re modifying scaffolded forms, rather than building your own, you’ll encounter the z attribute, which is assigned a generated unique ID.
This seemingly random value tells Roo that the field is being managed by Roo itself.
You don’t want to change this value unless you decide to manage a field yourself.
A generated unique value, such as T5MViHc0PXnvBhkOlpd, meaning that this field is controlled by Roo.
Less obviously, it tells the Roo shell to ignore this field definition, and spe­ cifically not to generate another definition for this generated, but customized, element.
Beyond the ID fields and z attribute, Roo has a number of settings in the tag libraries that make it easy to customize your web views.
Above all, read through the tag libraries and learn their features.
With the conventions behind us, let’s see how to change the views to suit your needs.
List views are composed of tags nested as shown in figure 6.1
Roo automatically iterates through the rows in the collection, first outputting the.
In the list view, the tags you can customize include page:list, table:table, and table:column.
Keep in mind, you are limited in the scaffolding to showing the data returned by the controller, and may.
The label to show representing the entity if no entries are found.
Defaults to the locale key emitted, which is resolved from the localized application.properties file.
The label to show instead of the name of the entity, to the right of the title prefix List All from messages.properties.
The collection to be iterated through in the nested table.
It’s listed here so that the outer tag can determine whether to show a table of results, or a message that there are no items available.
But more important customizations occur at the table:table and table:column level.
Let’s look at the customizations you can perform on your results table in table 6.2
Whether or not to show the icons for creating, updating‚ or deleting entries from the table.
The URL path fragment to prepend to any requests to edit or remove data.
You may wish to replace the table with other form elements instead.
The field name for the primary key of the row—id is the default.
Unless overridden by this property, the label defaults to the localized label for the field name in application.properties.
You won’t want to render all 60 fields of your massive employee record, for the ones you don’t want will omit them from the page.
Tells the tag whether the value is a stored java.util.Date, or a long that can be converted into a java.util.Calendar.
For scaffolded date fields, this value will be automatically set.
The pattern to apply when formatting a field marked as a date or calendar.
Scaf­ folded controllers create these patterns and add them to the request.
In earlier versions, users were only shown 10 characters of each field.
Customizing Roo CRUD views 161 You can customize any of the attributes in these fields, as long as you don’t change the generated id field value, or, in the case of the column definitions, modify the name of the properties they’re attached to.
This way, Roo marks the customized elements as user-managed and leaves them alone.
They’re nearly identical to what you saw in the previous chapter.
The form view tags  also take  a number  of attributes.
Unlike the list view, form views are generally relatively flat.
Will be added to the localized version of the mes­ sage Create new, as in Create new Course.
By default only ren­ ders if all parent dependencies are satisfied.
There are other parameters, mostly used by the scaffolding system.
But the key cus­ tomizations take place in the form fields.
Table 6.5 has a list of fields that are common to many field types, and their relevant uses.
The label to use to identify the field on the screen.
This version is not localized, and is useful during prototyping or for applications that don’t need localization.
As with label above, identifies the field on the screen.
If this value is set to true, and the field is skipped, the client-side JavaScript val­ idators won’t allow the form to be submitted.
This may be useful if set based on user permissions using the Spring Security API or other databased permission scheme.
The regular expression defining the validation to apply for this field and the message to return when invalid.
The messageCode variant looks up the mes­ sage in the localized property stream, and the message variant takes a literal error message.
Don’t forget to apply this pattern and mes­ sage to both the create and update forms if you’re going to allow both creation and update editing of the field.
Armed with these tables of information, you should be able to customize your views nicely.
You can always drop in additional HTML elements where needed, and update your CSS styles as well.
Here are a few additional helpful techniques you can use while customizing your forms and views.
For example, you can switch the description field to use the field:editor tag, so that users can enter HTML data.
Simply replace the original field:textarea tag name with field:editor, leaving the same z value.
This is also useful when Roo has chosen a textarea field instead of a single-line input field, or when you want to switch from a checkbox to a Yes/No select list.
After you make this change, the Roo shell will update your page for you, switching the field tag value to user-managed.
But you a hidden field, and Roo will deliver the field along with the rest of the form.
The field name should be the name of the member variable in the model.
Remember that if you’d like to reset scaffolded field settings for a given field, you can remove the field from the file, and Roo will replace it with a brand-new Roo-managed field.
Roo has two attributes attached to most scaffolded field and form elements: render and disabled.
This isn’t the same as making it nonvisual; it literally removes it from the view output.
For text fields, the value will be emitted as text only, for example.
Let’s say you only want to allow Course comments once the course has been success­ fully completed.
Remove the comment field from the create.jspx form by setting the render property to false.
In a more advanced configuration, add an expression on the update.jspx page to evaluate the value of disabled for the field you want to selectively edit, based on the existence of another field value.
Sometimes Roo can get a bit tem­ peramental, ignoring updates to your view files, especially when you want to regenerate your fields.
Just quit and reenter your Roo shell to reset the state and detect the changed views.
Let’s look at another customization—modifying the appearance of date format fields.
In the Offering entity, you’ve defined your offering date using the style-based format as the parameter to the Roo @DateTimeFormat annotation:
Roo uses this annotation to define a format String for the date field in the controller ITD, so that the form field can look it up and use it.
The first character determines the format of the date portion of the field, and the second character determines the for­ mat of the time portion.
In addition to  -, which means suppress the date or time portion of the field, resolve as shown in table 6.6
During scaffolding, Roo takes this information and uses it to translate the date into a localized String using the Joda-Time library.
It does this by generating an addDateTimeFormatPatterns method to the Controller ITD.
The scaffolded field will use this format automatically in the attribute dateTimePattern during the scaffolding process:
You can use this technique yourself for your own nonscaffolded date fields.
Another way to date formats is to use the format attribute of @DateTimeFormat:
Roo simply adds the format as a String in the Controller ITD:
You can then use the dateTimePattern attribute to inject the pattern:
If you want to localize your date formats for nonscaffolded views, or want to use the same patterns across many date fields in your nonscaffolded or modified scaffold views, you can directly add the formats to a localized version of your application .properties file and use <spring:message> to load it into a variable at runtime.
Refer to the coursemanager file list.jspx in chapter 6 for the offering entity for an example.
Roo may also have problems converting these formats into a value supported by the date picker held in the field:datetime form field.
The brute-force method is to apply a format pattern to the field directly, using the dateTimeFormat attribute on the view:
Of course, this pattern won’t be updated based on changes to the entity’s @DateTimeFormat annotation.
But if you need to display a very specific date or time format for a given view, at least you have an option.
Let’s say you need to provide a list of values for a given field as a drop-down list, such as a course complexity level, a query from a database, or a list of values provided by a collection.
On the server side, you’ll need to provide the reference data to the page in the form of request data.
Use a Java enumerated type and annotate your type with the @Enumerated annotation:
Roo will provide the options by stringifying the enumeration elements.
This is the easiest, but least flexible‚ way to provide a set of choices to a view because you can’t add a new value unless you change your enumeration.
To populate the list, you can use something like this: uiModel.addAttribute("coursetypeenums",
Use a query to a Roo entity and store it in Model.
Roo does this with relationship data, so you can do it too.
Just annotate a new method in the controller with the select from a list of offerings, add.
Use your own finder, service‚ or JDBC query to populate the list.
On the view itself, you can use the field:select tag to expose the options and allow them to be selected:
The itemLabel and itemValue clauses refer to properties of the collection provided in the Offering bean, and the provided collection is assigned with the attribute items.
You can even navigate to another controller to do a search, perhaps even making a modal dialog out of the selection process.
Anything you can do in standard Spring is available to you here.
No mat­ ter: you are in complete control of that as well.
In this section we’ll tell you how to prepare your application for localization, how to set up different themes, and how to adjust your layouts.
In fact, every scaffolded text element is fetched either from the database (via the entities) or via locale-aware properties files such as application.properties and messages.properties.
Here’s how Roo identifies and renders various elements on the page:
If you’d like to change the way your entity is described, you can modify this file.
Column names —Column names are also stored within the  application .properties file in the same way as the singular and plural entity names (the field is appended to the end of the preceding label)
Error messages —Error messages are stored in messages.properties and can be customized to suit.
Remember, Roo won’t overwrite the tag libraries or layouts it creates, but it will attempt to keep fields in sync.
Now, armed with the knowledge of how Roo resolves messages, let’s dig into localization.
The icons placed in the footer.xhtml file of your standard layouts are automatically generated if you issue the web mvc language command.
Roo responds by adding a new locale file, messages_es.properties, and configuring it with all standard Roo messages relating to the default layout and features.
It will be your responsibility to copy your application.properties file to application_es .properties and translate the field labels and messages to the proper locale.
Because all files are mounted in this directory, you don’t need any additional configuration.
Roo also copies an icon for the language flag into the webapp/images directory, and updates the footer to allow you to click on that image to switch locales.
For example, to translate the site to Spanish, you can issue.
By default this setting is kept in an in-memory browser cookie.
If you’d like to make it more permanent, you can switch from the default CookieLocaleResolver to the SessionLocaleResolver.
You can store and reload the session for each user from a data store if you wish.
You can also use the AcceptHeaderLocaleResolver to automat­ ically detect the locale based on the browser’s reported language.
See chapter 11 for details on how to create other language locales by writing an add-on.
Now that we’ve talked about the mechanics of rendering the page contents, we’re ready to discuss page layout concepts.
Roo uses Apache Tiles to provide a composite view: a view composed of various individual parts.
In this section we’ll take a look at just how Roo works with localized property files; the configuration of Apache Tiles in a Roo application; how you can define page layouts via tiles definitions; and then how to customize individual elements of the Roo layout.
It’s installed as a special view resolver, a strategy object that resolves names of views returned by controllers to physical files and other resources.
TilesViewResolver processes view names, emitted in the controller, and attempts to find layout definitions within configuration files specified in the definitions property.
The main layout definitions file, layouts.xml, is what tells Roo about the two main layouts—default and public, as shown in the following listing.
In the previous example, each layout is given a physical file that defines the contents of the layout, and values to substitute for various tiles within that file, such as header, footer, and menu.
Hang in there, though: Tiles loves levels of indirection! That’s why you can create a number of layouts, assigning them to views, rather quickly by extending or modifying layouts.
This layout gives users a larger amount of screen real estate.
Let’s take a look at the default layout, as defined by WEB-INF/layouts/default.jspx, shown next.
This layout defines a very comprehensive page structure, including features such as HTML5 compatibility C, JavaScript and CSS support, the Dojo widget library, D CSS, and preinstalled tag libraries B.
The template also includes a set of div elements, each of which defines areas that can be rendered with content at runtime.1
Figure 6.3 shows the layout divs, styled by Roo’s generated stylesheet, in a simple block diagram.
Figure 6.3 JSPX files involved in the Tiles At this point, you’re probably wondering just layout process.
These files are located in / how the heck this information is relevant to web-app/WEB-INF/views.
To find out more about Internet Explorer’s support for various modes, see http://mng.bz/jQou.
Careful readers also will notice that the attribute for the page content itself isn’t being passed to the defini­ tions.
So how in the world does it know about the page? Ah, that’s because the crux of the whole matter is that views.xml file in your WEB-INF/views/testdrive directory:
Finally, you see that the layout named default will be used to render the throwaway/index page.
The header, footer‚ and menu tiles will be loaded from files based on the settings in WEB-INF/layouts, and the body tile will be loaded using the index.jspx file in the views/throwaway directory.
You can modify the content in any of these tiles just by changing the view files.
Here are a few suggestions for quick modifications you can do:
Read the documentation at the top of the menu.tagx, category.tagx, and item.tagx files for details.
Just edit and replace the logo file­ name in the banner URL within the header.jspx file.
Then again, why not completely replace the entire layout? Just modify your tiles layout and related CSS files, and go to town.
Roo also supports the concept of theming, which is closely related to layouts.
If you look closely at the footer of each Roo page in a web browser, you’ll see two clickable links for these themes.
When you click on one of these, Roo uses Spring’s theming support to switch a simple client-side HTTP cookie named theme between the values of standard and alt.
A little too complex for this book, theming boils down to special properties files, stored in WEB-INF/classes in the web application, for each theme.
Roo uses a special generated tag, theme.tagx, to generate these links, and the theme resolver accepts clicks to these links, which sets the cookie value for the browser.
Each time the browser renders a page, it passes the theme name in a cookie to Spring.
Spring accepts it, and the CSS file pointed to in the standard.properties or alt.properties files is used to mount a different stylesheet.
The upshot for you is that you can style two different themes.
Currently, the only difference between the CSS layouts is the position of the menu: standard layout puts the menu on the left, and the alternative one puts it on the right.
Feel free to custom­ ize standard.css and alt.css to suit your needs.
As you can see, you have a range of options for customizing your web application.
Change the z attribute to user-managed when changing a scaffolded compo­ nent entry.
Follow component naming conventions when adding your own fields, and read.
Learn to work within the generated layout, theming‚ and localization engines,
The same goes for Spring’s own MVC form tags, which Roo uses inside of the.
If you follow these simple guidelines, you can go far in transforming the generated Roo web application files to suit your needs.
If that fails you, just push-in refactor your scaf­ folded web application controllers and rework the pages and tags to suit your needs.
In chapter 7, we’ll look at Spring’s support for the Dojo component library and JavaScript, delve a bit into Ajax, and look at several other advanced web frameworks supported by Roo: GWT and JSF.
Although rather general, if you get into CSS and HTML editing, this is a great reference.
In the last chapter, we discussed how the Roo custom tag libraries add dynamic behaviors such as client-side validation, and how you could customize the form ele­ ments, messages, layout, and look and feel of your web pages.
In this chapter you’ll learn how to work with more advanced web frameworks in Roo.
Then we’ll discuss some of the other web platforms available to Roo developers today via add-ons: Google Web Toolkit, Vaadin, and JSF.
Roo can provide dynamic, rich application features out of the box, providing both cli­ ent-side widgets such as tab folders and tree views, and server-side support for Ajax.
It does this by installing two key technologies in every Spring Roo web application: Spring JavaScript and Spring MVC Ajax support.
In this section, you’ll learn how Roo mounts Spring JavaScript and how the Roo tag libraries use it to create rich widgets.
Then you’ll wire a text field to an Ajax serverside method and invoke it using a JavaScript event.
Roo includes the Spring JavaScript library when it generates a Spring MVC web applica­ tion.
The Dojo scripts are mounted in the /resources/dojo, /resources/dojox‚ and /resources/dijit URIs within Roo web applications.
All form elements and pan­ els in Spring Roo are built using Dojo, and Dojo validation routines provide dynamic, client-side error messages to your forms.
Spring JavaScript API—A set of Spring-developed utility JavaScript methods to install Dojo widgets and perform automatic client validation.
The <mvc:resources/> tag in the webmvc-config.xml file defines the various classpath directories to search when requesting a URL starting with /resources.
Spring will cache these resources and serve them to the client automatically.
To add a more dynamic nature to your forms, let’s create an Ajax interaction between your page and the server.
As you probably know, Ajax is a label for technology that calls web services from a previously loaded page.
The example is trivial but shows the minimum plumbing required to set up an Ajax call.
You’ll use the Dojo framework to wire changes to a course duration field to trigger calls to a Spring MVC method.
Every time you modify the field value, the Ajax method will calculate the list price of your course.
Spring MVC has full support for Ajax on the server side, as does Dojo on the client.
You’ll use a specially annotated Spring MVC method to handle the server-side call, but first you need to wire up the input field to trigger a JavaScript method every time you type a digit.
We'll use Dojo event handling to wire changes in the duration field to a method that executes the Ajax call.
This block is executed after the page is fully loaded, but before the user can access it.
In this block of code, you look up your duration field and connect a Dojo event han­ dler to it, which calls your Ajax method.
You then use the dojo.connect method C to wire up an onKeyUp event, which fires each time the user presses and releases a key.
The connect method's third param­ eter is an anonymous function which handles the event.
The dojo.xhrGet method executes a GET call as an Ajax method.
In this exam­ ple, it sends the amount typed as a URL parameter you'll construct beforehand D, and it expects the return as a text value.
The call is handled asynchronously, and results in a call to the anonymous function specified in the load parameter E.
In that method, you place the returned value in your listPrice text field.
You do so by using the dijit.byId method to locate the listPrice field and then calling the listPrice.set F method to modify the Value attribute, which is what holds the HTML form field data for the list price.
If an error occurs, the function assigned to the error parameter is called instead.
Further, you can assign an anonymous function as a prop­ the load and error properties.
Your last step is to actually implement the Ajax calculation method.
To calculate the list price, you’ll use the Spring MVC @ResponseBody annotation.
This annotation tells Spring MVC to return the result of the method as the output, and not trigger traditional view resolution.
In this method, mapped to the URL /courses/calcCostByDay, Spring MVC accepts a single integer, days, as a request parameter, calculates the list price, and then returns it as a String response.
That’s the entire Ajax server method—of course, the serverside developers have it easier than the web developers do in this case.
Save your controller and kick off your application with the mvn tomcat:run com­ mand.
Try changing the duration of the class—if the list price changes, everything’s working.
If not,  open up Firebug and check the console—chances are you have a scripting error.
You can also use the console.log method and the JavaScript debug­ ger to troubleshoot the page.
If you try to type anything other than numbers into the numDaysduration field, the listPrice field will be replaced with a large amount of HTML text.
The text returned is actually a standard HTML error page that reports an invalid mapping; because your method was coded to accept an integer parameter, it didn’t find a suitable method to map to the incoming request, which, since specified as a set of characters, was not numeric.
There are a number of ways to solve this little problem.
The easiest is to simply zero out the field if the user submits invalid data.
You can change your method in the CourseController to look like this:
But unless you want to give yourself repetitive stress injuries from hitting Enter, the better way to debug is to use the excellent FireBug JavaScript devel­ opment plug-in tool in FireFox, or one of the other provided debuggers in Chrome or Safari.
The console.log method is your logging method for JavaScript, and any­ thing you put in there automatically ends up in the JavaScript log output in FireBug’s Console pane.
Be careful to remove these statements if you’re going to host your application on an older browser such as Internet Explorer 6.0, or you may find error messages about not finding a console object when the page loads.
The create.jspx file can be customized the same way; the major difference is that you don’t have to carry along hidden id and version fields, and you use the POST method to create a new course using the /courses URL.
So far, you’ve learned how to configure Dojo widgets and handle Ajax requests and responses.
Now let’s switch gears and take a look at two other web frameworks avail­ able to Roo developers.
WE’RE ONLY SCRATCHING THE SURFACE HERE Ajax and JavaScript user inter­ faces are a huge topic, worthy of an entire series of chapters.
We have more information available online on the book website, http://manning.com/ rimple, including articles on using the Dojo framework, passing data with JSON, and more.
It’s used to build many of their applications, including GMail and Wave.
Swing developers will feel right at home with the familiar Java, event-driven API, and XML.
Developers use Java, XML, and some HTML for pages and layouts, and Java for composition of client-side user interface components, event handling, and interaction with the server layer.
You’ll use the Roo shell to install a GWT user interface in your Course Manager application, and then we’ll walk through the implementation.
In future MEAP (Manning Early Access Program) posts we’ll outline how to customize the scaffolded interface elements.
Roo provides a simple, one-line installation command, gwt setup, that installs the GWT compiler, server-side infrastructure, and build instructions.
You’ll use your Course Manager Roo starter schema to build out a GWT application.
You’ll create a project and run the course-manager-schema-setup.roo script (available in the Example-Code/roo-scripts directory) to prep your application configuration.
Roo responds by building out your GWT application, installing the GWT Maven plugin and dependencies in the pom.xml file, and generating a scaffolded GWT web application.
You’ll need to decide whether you want to let Roo generate your GWT components using a scaffold, or whether you want to roll your own.
Table 7.1 lists the commands you can use to set up your GWT code.
These commands may take one or more of these options:
After the GWT application is generated, or you’ve developed your GWT code to suit, Roo is able to execute your GWT application from the Maven command line.
Go ahead and execute it by running the following commands:
These applications are referred to as permutations, as you may see during the build phase:
After a significant amount of processing, the application will start in an embedded Maven Jetty container.
If you use the gwt scaffold or gwt all commands to generate your GWT frontend, the user interface will be ready to test.
The frontend presented will act more like a desktop application than a typical website.
Figure 7.1 illustrates this with an example of the Courses pane.
Please refer to the Roo forums to gain details on the current version of this framework.
Also, track any Roo GWT JIRA issues at the Roo project issue tracker at http://mng.bz/rQlu.
You can also run the GWT application out of an exploded EAR by issuing.
In this mode, GWT runs as a web application only, in the same way it will run on web application servers in test or production.
Each of these permutations is a copy of the application, targeted for a supported browser type.
You can control which browsers you target by modifying your GWT con­ figuration file, ApplicationScaffold.gwt.xml, which is held within the root package in the src/main/java directory of your project.
To target a specific browser only, such as Safari, add the following configuration entry:
We’ve looked at Spring Roo’s support for building GWT-based scaffolded user inter­ faces.
The Roo development team worked closely with Google to implement the Model-View-Presenter pattern, and Roo uses the most up-to-date, state-of-the-art.
The Roo GWT add-on lets developers see what a modern implementa­ tion of Google’s RIA platform looks like.
It allows for selection of the Oracle Mojarra or Apache MyFaces implementa­ tions, and can use a number of predefined UI themes.
The pages themselves, known as facelets, are composed of containers and components.
Roo uses the PrimeFaces JSF widget library (http://www.primefaces.org), which provides a wide array of JSF components.
Let’s take a look at how to set up JSF as an alternative web framework.
To install JSF on an existing JAR-based project, use the web jsf setup command: roo> web jsf setup.
Roo responds by installing the JSF framework using the Oracle Mojarra implementa­ tion of JSF, with a JSF theme named south-street.
You can change these options later if you want to experiment with the other imple­ mentation or themes.
This means the architecture is inverted when compared with traditional Spring MVC.
Roo installs JSF files in several directories under the src/main/webapp directory, including.
Pages—All JSF pages for your views are stored in here.
They’re defined in an XML page format named facelets, which have the extension .xhtml.
These files, similar in concept to Tiles components, live here.
Facelets define the templates they use for a given view.
WEB-INF/faces-config.xml—This file is used in Roo to define localization rules, and defines the directory within WEB-INF where the localization files are stored.
We won’t go into the depths of JSF in this book.
There are plenty of resources we can point you to.
But let’s take a look at how Roo can scaffold JSF interfaces and dissect a scaffolded view and a page bean.
You can use the web jsf scaffold command to scaffold a single entity, or web jsf all to scaffold all entities.
In either case, Roo will generate page beans and pages in the appropriate directories.
Of course, by now you should assume the heavy lifting is provided by an ITD, and that the container (courseBean)
Observant Spring developers will see that these page beans are stateful.
Somehow, the allCourses collection was loaded before the view requested the course list.
In some ways, this is a simpler, more Swing-like programming model than the typical MVC approach.
Table 7.2 outlines some key methods generated by the scaffolding.
These methods are called to data-bind the form fields of the form view to the page bean before persisting or displaying a single entity.
More advanced JSF users may choose to remove the dynamic widget definitions from the populate methods and define them in the view itself by pushing in the method and modifying the code in the bean’s Java class.
Now let’s take a quick look at the JSF facelet for your course page bean.
We won’t go into the deep details of the page view, but keep in mind that it handles processing for the entire view.
And, unlike JSP-based views, the Roo JSF facelets con­ tain views for all CRUD operations in the same .xhtml page.
Figure 7.2 shows the page layout of the JSF user interface, and displays the Course list scaffolded view.
Roo uses a mechanism similar to the MVC list view, embedding all columns in each row and providing icons to delete, edit, and view each row in a form view.
Because this is a new web framework implementation for Roo, expect a num­ ber of changes in the view configuration.
Let’s take a quick look into a few ele­ ments of the facelet view, WEB-INF/ pages/course.xhtml.
This is provided by the table of results method in the page bean as shown next.
A column is defined with the various action buttons, such as view, edit, and delete.
Events are bound, such as the backing bean viewDialog method, which constructs the components to display a view.
The appeal of JSF is the use of a view to provide the driving force for events.
Rather than relying on a controller to intercept the FORM post and determine the view to dis­ play, JSF components are driven from the view outward, with the view defining which events are bound and methods are called.
To wrap up, let’s look at one of the embedded dialogs, the create dialog, which lives within the panel just after the list view definition:
The code created for the rest of the JSF implementation is beyond the scope of this book, but you can see the patterns in the example.
The dialog is defined in the back­ ing bean, and is invoked when one of the grid action buttons is clicked.
Although support for JSF is early, the feature set is rather complete, and you have the ability to define your own custom JSF views as needed.
Unlike MVC, the JSF add-on takes a slightly different approach to scaffolding.
You be careful not to remove the form views for editing, creating, and viewing.
Other Roo UI frameworks	 187 As with Spring MVC, you don’t have to use the scaffolding; just drop your views and page beans in the appropriate places and go to work.
The best way to learn is to pushin a page bean and review the interaction between it and the facelet it backs.
They range from HTML and JavaScript-based frontends to platforms such as the Flex API.
Using web flow setup from the Roo shell, you can get Roo to generate the proper installation scripts, and mount a new Web Flow script.
Visit our book website (manning.com/rimple) for some examples and an article describing how to use Spring Roo with Web Flow.
The developers originally distributed a Roo add-on for Roo 1.1
Vaadin includes a set of Eclipse IDE extensions to perform drag-and-drop editing of compo­ nents and user interfaces.
Flex—Flex is a true client/server development platform when coupled with a smart application tier such as Roo.
The Roo Flex add-on, which configures Spring BlazeDS remoting (a super-fast binary API), is currently being taken over by the Roo community.
As of the time of this writing, it doesn’t work out of the box with Roo.
Check the Flex forum on SpringSource.org for details on the current state of the add-on.
Flex users don’t need to use the Flex Roo add-on to program in Flex.
They can just install the powerful Spring BlazeDS library directly and use it them­ selves.
However, once the Flex add-on is finalized, Flex developers can enjoy automatic scaffolding of entities in Flex ActionScript and manual or scaffolded user interface views.
Refer to the source code of the Spring MVC, WebFlow, JSF, and GWT add-ons to see how it’s done.
More web and rich internet platforms will surely appear in the future, so make sure you keep up to date with the Roo add-ons by visiting the Roo forums.
Spring Roo has support for a number of rich internet APIs.
From roll-your-own JavaScript and Ajax components and using Spring’s excellent support for partial server requests, to the embedded rich web components and Ajax libraries in Spring JavaScript and Dojo, to sophisticated frameworks like GWT, Vaadin‚ and Flex, you have tons of options to choose from.
If you’re looking to support a rich user interface but don’t want the sophistication of a GWT or Flex approach, the Dojo and/or other JavaScript toolkit approaches will serve you well.
But it would be wise for your team to bone up significantly on JavaScript mastery, because there are many pitfalls awaiting the Java developer who attempts to treat JavaScript as just another programming language.
If your development team consists mostly of Java Swing developers, GWT is a great alternative to the HTML/CSS/JavaScript programming model.
The downside is that the current MVP design causes a ton of code generation and can be difficult for the uninitiated programmer to approach.
A more easy-to-grasp alternative is JSF, because it nests in the same way Swing components do, and has a component-driven lifecycle.
Kovalyov, both of which are in Manning Early Access status at the time of this.
The folks at SitePoint (http://www.sitepoint.com) support and write about Dojo.
Douglas Crockford has abundant resources, including extensive videos, at http://
Most applications have to provide some level of security to prevent unauthorized users or external programs from accessing the system.
In traditional Java EE appli­ cations, developers would delegate security to the application server infrastructure.
As a result, integrating security into applications ends up being a one-off affair for each application server a team encounters.
Spring developers know there’s a better solution: configure the Spring Security API.
Originally called ACEGI Security (and later acquired by SpringSource), the.
Spring Security API is a platform-neutral, general-purpose, security API that can be hosted on any Java application server without changing the code written by a developer.
In this chapter, you’ll learn about the Spring Security API and how to install it within a Spring Roo application, including the web URL security and a customized login page.
You’ll review the security artifacts and how to tailor security configurations to suit your needs.
You’ll also learn how to turn on security event logging, which logs all security-related activity, allowing you to run security analytics and receive alerts to any unauthorized access to your application.
Let’s get started by installing Spring Security in the Roo application.
Security commands aren’t available until you install the web components of a Roo application.
After you’ve typed in the controller command, the Roo framework will generate the controller classes and configuration files.
Now you’re ready to install and configure the security API in the Roo application.
Issue a security setup command inside the Spring Roo shell, and install the framework.
Configure a Spring context file to define your security rules.
To install Spring Security in an existing Roo application, issue the command security setup:
A brand-new Spring application context file to store the security configuration, META-INF/spring/applicationContext-security.xml.
A login page (called login.jspx) and a views.xml layout file.
The views.xml file has the tile definitions for different views in the application.
An updated web.xml web descriptor file, which includes the Spring Security servlet filter.
Because Spring Security follows the convention-over-configuration philosophy to enable authentication and authorization in web applications, Roo’s security configu­ ration command doesn’t create or modify any Java classes.
Let’s take a look at some of these changes in detail, starting with the new security context file.
The following listing details the new applicationContext-security.xml Spring Security context file.
The first part of the previous listing uses the Spring Security namespace (http:// www.springframework.org/schema/security) B as the primary namespace, so you don’t have to use a separate prefix when defining the Spring Security XML elements.
You’ll use the HTTP element C to configure HTTP security, basic authentication, and other defaults.
From an authentication standpoint, you’ll use the form-login D and logout E elements to enable a login page, with a login failure URL and a security logout page, respectively, for your web application.
When you use the form-based login approach, it’s important to note that the form submit must be encrypted to protect the user’s password, and the credentials must be sent in encrypted form rather than in plain text.
The URL patterns you want to secure are defined using the interceptor-url F element.
Note that this configura­ tion element also takes care of the role-based authorization for specific web pages (URLs)
The next section in the configuration file deals with authentication details, such as the authentication manager G, an in-memory database H, an administrator user named admin I, and another user named student J, who will have public access to the website.
Note that the passwords should be hashed using salt, which makes the hashed passwords more secure.
Without salt, the hashed passwords are vulnerable to security attacks like SQL injections, dictionary attacks, and brute-force attacks.
Though beyond the scope of this book, you should become familiar with the many other implementation best practices in the application security space.
Websites such as OWASP’s (The Open Web Application Security Project) Top Ten Project list security vulnerabilities and provide helpful discussions of application security best practices.
Ben Alex discusses another authentication option in his blog post on a wedding RSVP application (http://mng.bz/9z4D)
He suggests you configure the authentica­ tion setup to have the password ignored.
This is useful when you want to let users access the web application using a single credential like a token, or as in Ben’s sample appli­ cation, the RSVP confirmation code.
This security configuration is shown in the follow­ ing listing.
Listing 8.2 Spring configuration snippet with special identification for anonymous users.
When you set the password value in the previous listing to ignored, you make the authentication occur based only on the username.
For this to work, you also need to edit the login page (src/main/webapp/WEB-INF/views/login.jspx) to change the password HTML field (j_password) to be a hidden field and remove the password label.
Don’t forget to comment out the password-encoder element as well; otherwise, the authentication will fail, with a message such as Bad Credentials.
The file applicationContext-security.xml is the heart of the Spring Security config­ uration.
It defines the overall security configuration, which consists of two key facets that drive the security engine: the authentication and authorization settings.
Authentication is the act of verifying the identity of the agent requesting access to your system.
In Spring Security, authentication can be tied to various physical security mechanisms, such as BASIC authentication, form-based security, certificate-based authentication (CERT), or SSH-based key pairs.
It tells Spring Security to automatically configure the default set­ tings for security, which allows for a basic form-based login, a special identification of.
In addition to these settings, Roo also configures the use-expressions attribute of the http element C, which allows you to express your security constraints using the Spring Expression Lan­ guage (SpEL)
Note that in both form-based and basic authentication the user credentials are sent unencrypted to the web server.
You can use a secure HTTP (HTTPS) mechanism to address this concern by enabling the SSL certificates.
But unlike basic authentication, with form-based authentication you have the flexibility to add or modify any custom security event–related auditing, as well as user attributes and level of logging for your requirements.
You can set limits so the login page is SSL-encrypted, but for your web­ site’s other pages that contain only static content and no user-sensitive information, you can use HTTP.
Finally, a login form allows you to present a page with a look and feel consistent with your overall application.
The basic authentication option only provides a dialog, which you can’t customize.
Authorization (also known as access control) is the process by which Spring Security checks whether or not a given authenticated user has access to a given resource.
As you’ve learned, Spring Security has already configured both authentication and authorization.
These roles are attached to the admin and user logins.
You can install the Spring Security engine into any web container using a standard servlet filter.
Installing the DelegatingFilterProxy filter allows the web application to make requests to the Spring Security configuration when web requests are issued.
As you can see with the URL pattern of /*, all URLs pass through the filter, which means Spring Security can protect more than just controllers.
Let’s take a look at an excerpt of that page, login.jspx:
This is similar to how a tradi­ tional Java EE web security implementation works.
If the security system recognizes the credentials of the passed user, Spring Security marks this fact and authenticates the user.
Otherwise, the error is passed back to the page, and rendered in the errors div above the form.
This security configuration can be extended and customized by adding more JSTL scriptlets and conditions using the Expression Language (EL)
For example, you can implement a feature called Remember Me so the application remembers the identity of a logged-in user between sessions (a feature supported in the Spring Security framework)
Also, once you modify and customize the configuration files, Roo remembers those changes and doesn’t override them the next time you run the Roo commands.
Now that you’ve been briefed on the configuration elements, let’s discuss how to use Spring Security to configure security in a simple application.
Let’s discuss the application security module of the Course Manager application.
You’ll learn more details about these later in the book.
With these application security requirements in the areas of authentication and role-based authorization defined, you’re ready to secure the web application.
First, you have to replace the default URL protections installed by Spring Security.
You’ll change the intercept-url tags to something that makes sense for your applica­ tion, such as.
Both roles may view the course catalog and course details, but only the admin can delete them.
Any web request can access the GET method on /coursecatalog, making it effec­ tively public.
This is a specific set of choices, but one that can be easily tweaked by modifying the tags in the previous code.
Note that the access attribute is populated with a permitAll value for some of the URL patterns.
This configuration allows all users access to the URLs matching the pat­ tern value specified in the pattern attribute of the intercept-url element.
In realworld applications, you shouldn’t allow access to URLs that aren’t explicitly protected.
If a user tries to access a URL that’s not specified, you should use a denyAll value to prevent access to the pattern that the URL matches.
This approach gives you better control over what URLs in the application are accessible to a specific group of users and results in a more secure web application.
Disables Spring Security for this URL pattern and allows access to all.
Allows entry only if no security context is estab­ lished for the given principal (that is, they’re not logged in)
You can also apply more arbitrary expressions in this configuration, but this list will do for simple security configurations.
Listing 8.3  Spring Security JSP tag library to control access to web page elements.
To use Spring Security tags detailed in the previous listing, you’ll first specify the tag library namespace (http://www.springframework.org/security/tags) B and then use security tags such as authorize C with an attribute like ifAllGranted to specify the role or roles that will have access to the specific web page element (in this case, the delete menu item)
This will address the access control requirements in the view components, but what about the controller layer? You can restrict access to the delete and update use cases for a scaffolded entity by adjusting the @RooWebScaffold annotation (located in the org.springframework.roo.addon.web.mvc.controller package) in the specific controller class, adding delete and update attributes, and setting them to false.
This will cause the Roo shell to automatically remove the delete and update methods from the controller class and update the corresponding JSPX view components:
The next step is to define a more permanent authentication storage mechanism by persisting roles and principals into a database.
Later in this chapter, you’ll also learn how to configure LDAP-based authentication in a Roo application.
In a real system, you’d never configure security credentials within a configuration file, because you’d have to redeploy every time you needed to add a new user.
First, you’ll create entities and controllers to manage your security credentials.
This Roo script defines a table, security_principals, with username, password, and enabled fields.
For all of these entities, let’s define the controller classes using the web mvc scaffold command:
You should also secure these new URLs so that only ROLE_ADMIN users can access them.
Add the following intercept-url entry to protect all URLs below /security:
You can do this by using the --path /security/pathname element in the web mvc scaffold Roo command, which automatically places controller request URLs and view paths in the pathname path, within the /security superpath.
It’s important to note that the Roo add-on community is working on automating the steps required to use JDBC-based authentication configuration, which will make the job of enabling database-driven user authentication much easier in the future.
At this point, you’ve defined your database entities and the controllers to manipu­ late them.
But, so far, you haven’t attached them to the security system.
Spring Security lets you define user services to access your user databases.
Because the concept of a principal has been abstracted, you can plug in any kind of implementa­ tion: database-managed, LDAP, or flat-file.
Spring Security also supports external sin­ gle sign-on (SSO) systems such as Central Authentication Service (CAS), OpenSSO, and SiteMinder.
First, you’ll configure your users using a relational database, accessing entities defined within the same Roo application.
To do this, you’ll have to update your Spring Security configuration file, applicationContext-security.xml.
You’ll add a real, data source–backed authentication database, as illustrated in the following listing, before the original user-service tag.
The previous listing shows how to configure the database-backed authentication.
This approach is great for development-time databases, but you may want to con­ sider making this an optional security configuration element, and leave it out when you get ready to move to a real production environment.
Note that the password values in the security_principals table should never be stored in plain text.
They should be stored using a hash algorithm like SHA-256
The password-encoder element in the previous listing will authenticate the users by retrieving the password (which was stored after hashing the plain-text password value using the SHA-256 hash algorithm) from the table and un-hashing it to compare it with the password entered on the login screen.
Also, when using the hashed pass­ words, it’s a good security practice to use a salt value to protect against dictionary attacks.
You’ll want to use a randomly generated salt value for each user, which will allow you to use the username property for generating the salt.
Then you’ll configure all of this in the salt-source element in the Spring Security configuration file.
Spring Security provides support for LDAP-based authentication and authorization out of the box.
To enable the LDAP authentication, you’ll need to make a few minor edits to the applicationContext-security.xml file.
To use Spring Security LDAP authentication, you’ll first need to add the following Spring LDAP dependencies in the Maven pom.xml file:
Next, add the tags for the ldap-server and ldap-authentication-provider ele­ ments to the applicationContext-security.xml file, as shown in the following listing.
You can use an open source LDAP server such as the OpenDS directory server for testing the previous LDAP user authentication configuration.
The OpenDS server documentation (https://docs.opends.org/2.2) has instructions on how to install, configure, and launch the open source LDAP server.
Refer to the readme.txt file in the sample application code provided with this book for instructions on how to configure and run the OpenDS server.
If your organization has a user data repository in a legacy system that doesn’t support JDBC- or LDAP-based authentication, you can use a custom authentication provider for user authentication.
In this scenario, the authentication configuration would look like the following:
Securing a sample application 203 Your custom authentication provider MyCustomAuthenticationProvider class would extend the Spring Security framework’s abstract class AbstractUserDetailsAuthenticationProvider (located in the org.springframework .security.authentication.dao package)
As noted previously in this chapter, in Roo you have to manually configure and cus­ tomize the security configuration to use a JDBC- or LDAP-based authentication.
Adding the ability to specify LDAP or JDBC options as additional command-line parameters when running Roo's security command makes for enhancement of the security command.
These additional parameters can be used to specify the type of authentication (for example, JDBC, LDAP, or custom authentication) and other nondefault authentication details.
After you’ve updated the authentication provider configuration using either a JDBC-based or an LDAP-based authentication provider and you run the application, you’ll see the authentication and authorization functionality in action.
There are two more steps to take before you’re ready to test your security configuration.
To handle this error more gracefully, let’s create a new view page called AuthzError .jspx with a user-friendly message, such as the one shown in the following code snippet:
Let’s also create a user-friendly error page (called Error.jspx) for handling the HTTP 404 errors.
Now you need to add these custom error pages to the web.xml file, as shown in the following:
The last step in making your code example a complete web application is to add links in the footer section for the login URL.
Note that the links in the footer tile of the web page don’t display the login link.
The footer tile displays only the logout link when you’re already logged in.
You’ll have to type the URL http://localhost:8080/coursemanager/login in the browser window to navigate to the login page of the Roo application.
Then you’ll add the following JSTL code in the footer.jspx file (located in the src\main\webapp\WEB-INF\views folder) below the home link:
Now the login link will display next to the home link when the user isn’t logged in.
Adding security event logging 205 Now that you’ve completed all of the security configuration steps in this chapter, it’s time to build the application running the mvn package command.
After a successful build, launch the servlet container using the mvn tomcat:run command.
Navigate to the main page of the web application and verify that the restricted menu items aren’t visible.
To do this, log in as user and make sure that only the menus that the ROLE_STUDENT role is allowed to view are visible.
If you’re interested in logging all of the security events (when a user logs in or logs out of the Roo application), you can do so by adding the LoggerListener Spring bean provided by the Spring Security framework.
The LoggerListener class (which is located in the org.springframework .security.authentication.event package) outputs authentication-related applica­ tion events to the logger.
All the authentication events are logged at the warning (WARN) logger level.
Note that this security event logger is part of Spring Security and not a Spring Roo feature, but it’s included in the discussion here because most real-world applications require logging for troubleshooting as well as security compliance purposes.
The following log output snippet shows the security event logger output messages after you enable LoggerListener:
The default logger level in the generated log4j.properties file is ERROR, so you’ll need to modify the logger level to either WARN or INFO to be able to view the security event log messages.
Run the following Roo commands to change logging level from the ERROR to the INFO level.
Make sure that the ERROR log level is set for the application that’s running in the production environment and set the INFO level to run only in nonproduction environments:
The logging command shown in the previous example defaults to all packages in the web application‚ but you can use the optional --package argument to specify the logging command again, but this time it specifies the package name for the classes in the Roo project (using the variable PROJECT, which maps to the org.rooinaction .coursemanager package):
This will add the following line to the log4j.properties file:
If you want to modify the log level for Spring Security Java classes, specify SECURITY as the value for the package argument in the setup command and it will add the DEBUG level to the org.springframework.security package.
This is helpful for troubleshooting any security-related bugs in the application.
The following listing shows the complete configuration with all of the custom changes discussed in this chapter for the applicationContext-security.xml security configuration file.
This is the power the Spring Security framework brings to the table‚ and Roo takes complete advantage of this approach.
The Spring Security framework makes the job of every application architect and developer easier, because they can spend their focus, time, and effort on the business logic part of the application instead.
In this chapter, you learned how to implement security (which includes authentication and authorization aspects) in a Roo application.
You reviewed the Spring Security concepts and the configuration details of application security in a Roo application.
You also learned how to change the authentication provider configuration from the hardcoded username and password values that are used for testing purposes to a realworld user-credentialed data store like a relational database or an LDAP repository.
You looked at how to protect and restrict URLs and adjust the views for different web pages in the application based on what type of user is accessing that specific web page.
Finally, you enabled the security event logging in the application to view the authentication event details as and when users log in to your web application.
In the next chapter, we’ll switch gears a bit and discuss Roo’s testing facilities.
We’ll review unit, integration, and web tests, and you'll learn how to test Roo services, entities, and web pages using JUnit and Selenium.
You’ll learn how to integrate enterprise services such as email and messaging with Roo applications.
You’ll also be introduced to another great feature of the Roo framework: support for add-ons.
Mock objects are a great way to test a class with lots of dependencies.
You’ll learn how to mock entities and services as well as test Roo services and reposito­ ries inside the container.
You’ll learn, with the help of sample application use cases, step­ by-step details of implementing email notification and messaging using a JMS topic as well as a queue.
You’ll also learn how to monitor messaging activity using tools like VisualVM and Spring Insight.
First, you’ll learn how to find and install Roo add-ons from the central repository.
You’ll then build your own add-on to install jQuery and jQuery UI libraries.
In the advanced add-ons discussion, you’ll learn how to install CoffeeScript language into your local development environment.
You’ll also learn how to publish the add-ons using the OSGi Bundle Repository (OBR) and the Roo addon service.
Spring Roo helps you build your applications rapidly, but that doesn’t mean you should skimp on your testing plans.
Chances are, you’re building the applications so fast that it would help to slow down a bit and write some useful tests.
The more you test up front, the fewer surprises you’ll find in production.
You’ve already learned that simple actions, such as using the --testAutomatically flag to create entities, help ensure you have a baseline of entity persistence tests for your application.
You can also write integration tests for your Spring beans and install Selenium for end-to-end testing.
In this chapter, you’ll see how Roo makes it easy to set up your test environments and how you can test using Roo’s integration and web testing technologies, such as the Spring test runner and Selenium.
A web-based application can be tested at several levels using isolated, method-level unit tests; more sophisticated, in-container integration tests; and live, externally exe­ cuted website tests.
Roo supports all three levels of testing, as shown in figure 9.1
Think of these testing models as layers in a kind of testing cake.
Without all of the layers, your tests are one-dimensional, and they look at your application from only a single viewpoint.
You’ll find different bugs at each level, so implementing each of these types of tests is key to finding all of the bugs hiding in your application.
The review of the testing levels in this chapter follows the same order as depicted in the previous figure—you’ll start with unit testing and finish with functional testing.
Unit tests —Exercise single units of code, usually Java methods.
Where necessary, other collaborating objects are either stubbed or mocked so that they can behave in predictable ways.
For example, a Spring CourseManager bean may method of CourseManager, but you’d want to generate a predictable result from the tax calculator bean reference, so you’d mock or stub it.
JUnit is a popular testing API, and Roo uses it for all unit tests.
Integration tests—Exercise methods in components such as Spring beans, but run the tests in a live container.
Figure 9.1 Testing levels in Roo, Spring, and most other frameworks.
Note how complexity increases as the runtime environment is loaded or user interactions are posed, and how much faster tests run when isolated as unit tests.
Roo testing philosophy	 213 the component behaves in its own environment, such as when connected to a database.
These tests are also written in JUnit, but using a special test runner that mounts the application server before running tests.
Functional tests—Exercise the application using an external testing tool, such as a web browser emulator.
Selenium is an open source web testing tool that can be used to test your application’s web frontend.
Let’s see how Roo provides access to these test frameworks.
In this chapter, you’ll learn about each of these commands in detail as well as the APIs of which you need to be aware, and how to approach specific testing scenarios.
Before you get started with the commands, though, you need to review a key Roo testing fea­ ture that makes working with entity data easier: the DataOnDemand test framework component.
The DataOnDemand component is a useful test class that helps you generate test fix­ tures, the data required to set up your test case.
You’ll create these DataOnDemand classes in two ways: when you generate the automated entity integration tests‚
The DataOnDemand component provides three key methods for test data genera­
Table 9.1 provides detail on the methods in the CourseDataOnDemand aspect.
Table 9.1 A sample of DataOnDemand methods, using the Course entity.
Configures and persists ten instances of the Course entity, held in a member list variable, data.
Entities created by this mechanism are that take an index parameter.
This method doesn’t have to be called directly, because the other methods returning test entity instances will call it when necessary.
If you call it after the elements are initialized, it returns without modifying the collection.
This method doesn’t persist the course; hence the name includes the term transient.
If your validations are too complex for a simple static definition of a field, you may push one of these methods in to the DataOnDemand class, and modify the behavior.
Table 9.1 A sample of DataOnDemand methods, using the Course entity (continued)
If the course index specified is too high, the method returns the course with the highest available index.
The DataOnDemand classes can be used for both unit entity tests and integration entity tests, as long as you use only methods such as getNewtransientCourse from the mock tests.
All other meth­ ods work with a persistence context and must be called from within integration tests.
Let’s dive into some detail on three key methods of the DataOnDemand framework.
You need to understand them fully to take full advantage of them and write tests quickly.
The getNewTransientEntity method returns an initialized, transient entity with sam­ ple data stored in each field.
The entity is not persistent, so this method can be used by unit tests and integration tests.
The index helps to define the values for the data.
All string-based fields hold the name of the field, an underscore, and the index value.
All date values return a randomized date, close to the value of the current date.
Relationships to single-sided entities, such as owners, may be initialized with val­
For example, if the TrainingProgramDataOnDemand component exists, CourseDataOnDemand will call it to create an instance of the training program and set the value.
A quick workaround is to override the method that sets the entity, and create the referenced entity yourself using the referred to entity’s DataOnDemand class.
For this chapter’s sample course, the test data might look something like this:
The getNewTransientEntity method is useful anywhere you want to generate a sim­ ties for the other methods.
Use of this method to set up test fixtures saves you time and energy.
Many of the tests in this book take advantage of this method.
The getSpecificEntity method returns an entity from the internal list of persisted entities.
If the list is empty, it will be initialized automatically.
Roo will initialize and persist ten instances in this list.
If the user requests an out-of-range index value, it will return either the lowest or the highest element.
This method can be used only in a JPA environment, so it’s useful only for integra­ tion tests.
The entity has already been persisted and attached to the JPA entity man­ ager, so you can modify and even delete the entity.
Remember to define your integration test methods with @Transactional so the modifications are rolled back, or you may leave the DataOnDemand instances in an inconsistent state.
If you don’t care which persistent entity instance you work with, ask for a random one because the sample range is only ten unique instances.
Let's look at some techniques you can use when working with the DataOnDemand components.
For example, when you write a unit test you’ll use the transient getter, as in the fol­ lowing example, where you start with a generated entity, and set the list price to a value you prefer:
For working in an integration test, you can get a transient course and persist it, as in this code block that checks for a generated primary key after creating an instance of a course:
Stubbed unit tests 217 Alternatively, you can grab a prepersisted instance and manipulate it, as you see in the next example, where this test asserts that an updated course has a different version number:
In the previous example, you fetch the first generated course instance, capture the ver­ sion of the course row when retrieved, and then modify the list price and update your entity.
After a JPA flush, which guarantees that the data is written to the database, you can check the version, which should be incremented, allowing the assertion to pass.
The answer is, no; instead, you construct a new instance.
It’ll initialize itself, provided a persistence context exists and you’re running a Spring Integration test.
Using the DataOnDemand framework can speed up your test writing, making the cre­ ation of simple entity instances a trivial operation.
Feel free to refactor the code as you see fit, pushing in methods that perhaps won’t deal with your more complex valida­ tion rules or data persistence strategies.
Remember to keep the core functionality in place for the three key methods mentioned previously in this chapter.
Now that you’ve seen how Roo approaches tests and how to generate test entity data, let’s start looking at the various types of entity tests you can write, and how you can allow Roo to help you during the creation and execution of those tests.
You’ll review unit and integration tests with JUnit, and then perform some web testing with the Selenium API.
Let’s begin by looking at the Roo unit testing framework.
The test stub command creates a JUnit test that constructs an instance of a class, and creates test stubs for each of the public methods.
You create the test by using the test stub command.
Let’s look at a simple service that calculates a tax amount:
This class is initialized with a BigDecimal tax amount and calculates a simple tax based on an injected tax rate.
This is injected into the component via the Spring container, either by annotation, JavaConfig, or XML injection.
This command creates DefaultTaxServiceTest.java in the src/test/java directory, stored within the same package as the DefaultTaxCalcService class.
This assumes you’ll be writing tests against the methods of the class.
The following code lists the sample test, with the stubbed test method for the calculateTax service method:
This class doesn’t compile because the DefaultTaxService constructor requires a tax rate, injected as a BigDecimal.
You can use the test stub command to quickly generate empty tests against controllers, services, and other beans, and quickly write simple JUnit tests.
Let’s take a look at the next type of Roo test command, test mock, which is useful when you need to work with collaborating services and Roo entities.1
Mock objects are objects that pretend to be instances of particular classes, but are completely controlled by the test developer.
They appear to implement the specified interfaces, and you can configure them to return predictable values when their methods are called.
You can use these mock objects instead of references to other Spring beans or collaborating classes.
There are a number of different mocking frameworks available for unit testing, including these:
Mockito (http://mockito.org)—A popular unit test mocking library, well known for its easy-to-understand syntax and literate API, which uses method names such as when, then, answer, and other English language predicates.
The Mockito API is great for mocking Spring bean and regular POJO collaborators with methods defined by an interface.
Uses a mock expectation recording and playback API, which can be a bit daunting to new users.
In addition to Spring’s interface-driven applications, it’s a popular library.
PowerMock (http://code.google.com/p/powermock)—An extension library that enhances the capabilities provided by EasyMock and Mockito.
This mocking tool can mock static methods, interfaceless classes, constructors, final classes, and so on, which other APIs cannot.
Mock objects are often used when a layered application requires a particular Spring bean to collaborate with other beans, either in the same level or lower levels of the application.
They take less time to create than a fully stubbed object, because you only have to create the mock object at runtime, define the specific behavior to mock, and ignore the rest of the methods in the class.
Stubs require you to create a concrete class, and implement each of the methods of the object under test.
That takes a lot of time, and unless you’re able to exercise the entire stub across all of your test methods, it may be a waste of your time.
What if you want to see whether the entity can be validated appropriately, or if you need to stub the entity itself behind a service? Spring provides a feature to mock the.
Refer to JUnit in Action, Second Edition for details on how to work with these APIs.
This lets you perform basic unit tests against your entities, exercising logic you may have stashed away in assertTrue methods or methods that may contain business logic, and perform operations to generate derived data.
Here’s how you can use mocks to emulate collaborating objects:
Create an instance of your object under test, manually setting or injecting your.
If you were working within a traditional, layered Spring application, you’d likely have Spring service beans that would work with Data Access Objects.
You could easily make a mock version of a DAO that returns a predefined list of students if the this example:
In the previous fragment, you’re testing a StudentService bean in isolation.
It collab­ orates with a Student DAO, which you need to mock to provide that isolation.
You’ll use the Mockito.mock(StudentDAO.class) statement to provide the mock object, and then set the mock as your collaborating Student DAO.
You then use the Mockito.when method to tell the mock object to respond with a predefined list of students (not.
As you can see, the Mockito framework makes it easy to define a mock object, such as studentDAO shown in the previous example.
You can then manually inject the mock into studentService and tell the mock to return a prefabricated student list.
You might also be interested in an API that layers on top of Mockito and its cousin EasyMock.
Named PowerMock, this API allows you to mock static methods and imple­ ments a number of other helpful features.
Mockito does a great job with typical, interface-driven Spring beans.
But it can’t mock Roo entities, because Roo uses static methods within the entity to find entity instances from the database, and holds onto a private JPA entity manager to provide persistence logic.
Rod Johnson, the creator of Spring, contributed a testing framework element to help out: the static entity method mocking API.
Spring provides a special mocking API to allow developers to write tests against static entity methods.
Because the annotation is in effect, the static method isn’t executed, but is added to the list of methods to expect.
Use the AnnotationDrivenStaticEntityMockingControl (for brevity, let’s abbreviate this as the acronym ADSEMC): call its .expectReturn method to define the result of the operation.
You don’t need to do this if the method has no return value.
Because of the static methods used by the entity finders, testing a Spring bean involving an entity requires use of the Spring entity mocking framework.
To set up a mock test case, you use the test mock command:
Roo will then create a test class that looks like the example shown in the following listing.
The @MockStaticEntityMethods annotation places the entity mock in expectation record mode.
At this point, any calls to static added to the recording queue.
Next, you use the AnnotationDrivenStaticEntityMockingControl object to record an expectation: a definition of the behavior to trigger when calling the last return the value 13 when executed.
You’ll need to decide whether to use integration tests for accuracy, or unit tests for speed, when testing validations and business logic attached to your entities.
You’ve examined the test mock command, and how to make use of it to write unit tests of Spring Roo entities.
Now it’s time to use this in a more complex example and test what happens when you try to validate data.
A typical JUnit unit test will test a single “unit” of code, such as a method on a Spring bean.
Everything else is either stubbed or mocked, so that you can focus your energies on exercising your method under test and verifying the result.
Now let’s test an example Spring service method, RegistrationService .completeRegistration(long offeringId, List<Long> studentIds)
The method creates a number of Registration entities and associates them with the appropriate student and course offering.
The previous sequence diagram shows a fairly typical interaction with Roo’s Active Record–based entities.
Rather than relying on repositories or DAOs to wrap access to your entities, you use the static finder methods to locate them, and methods such as.
Testing this method in the Spring container, as you’ll see in section 9.4, is more involved and requires booting the application server.
If you’re purely testing applica­ tion logic, and can emulate the data access routines rather than take the integration testing overhead, you can run the test as a unit test, and improve the speed of your build process as a result.
Now, let’s implement the test using JUnit and Roo’s own entity mocking framework.
Let’s write a test that exercises a bean that processes student registrations.
The bean provides a registerStudents method that accepts a set of students and an offering, and then registers students for the provided course offering.
First, you’ll create the unit test class, using the Roo Shell test mock command:
Note that the term --entity can be any class definition.
Let’s open the bean defini­ tion for the newly created RegistrationServiceBeanImplTest and verify the class definition.
Roo should define your test class with the @MockStaticEntityMethods annotation:
This annotation enables the entity mocking framework, as you’ll see in the next example.
Now, you’ll define three DataOnDemand class instances, one each for Student, Offering, and Course, which you’ll use to decrease the amount of code in your test.
Define them in the Roo console with the dod command if they’re missing in your code:
You’ll also create the Service bean yourself, so hold onto a reference to that, too:
Now, for each method under test, JUnit will create a new instance of the RegistrationService Bean, then reinitialize all three DataOnDemand instances.
Referring back to the sequence diagram in figure 9.3, you’ll see that the first action of the method under test is to look up an Offering based on the value of the offering key passed to it.
You’ll use the OfferingDataOnDemand class to generate a test offering, and assign a fake primary key value of 1:
Now, you’ll invoke the call you’d like to have your unit execute when it’s under test, and you’ll follow that up with what you expect it to return:
You’ll do this for every interaction you expect your unit to invoke.
For example, you can pass in ten Long primary key fields of students to register for.
By now we hope you’re thinking that a straightforward integration test would be easier than this.
You’re right, but it’ll run slowly and you’ll have to run it against a live database.
If you’re trying to make sure the actions in your sequence diagram are called in the correct order, this test will do so at a fraction of the time.
Now you can perform the call, using the generated offering’s primary key (1L) and the list of fake primary keys generated for each student mock call:
If all is well, there’ll now be ten registrations, which you’ll fetch and assert, as shown in this next example:
The main ben­ efit of testing in this way is that it forces you to review the coupling of your entities and services.
If you find you’re mocking too many classes, you may have approached your design without thinking about the single responsibility principle (SRP)
What if you need to spin up the Spring container to run your tests? Perhaps you want to verify that the database schema still operates against your entities and JPA code, or you want to make sure your Spring configuration is valid.
Roo has two approaches for you—either you can use the Roo entity test framework and DataOnDemand classes, or build traditional Spring integration tests.
Let’s take a look at both approaches, starting with the entity test framework.
In either case, Roo creates a scaffolded integration test, named CourseIntegrationTest, and places it within the same package structure as the entity in the Maven src/ test/java directory.
It also uses the DataOnDemand framework to scaffold the test data, and perform tests for all entity operations, as shown in figure 9.4
The testing framework shown in the figure automatically exercises all methods in the Roo entity.
The difference between this test and the ones discussed earlier in this chapter is that it runs within the Spring container.
The funny thing is how short the Java class is:
You’ll do all of the work using the IntegrationTest aspect combined with the DataOnDemand aspect.
The following listing shows a portion of the CourseIntegrationTest _RooIntegrationTest.aj aspect.
Data on demand for 'Course' failed to provide an identifier",
Find method for 'Course' illegally returned null for id '"
Obviously, these tests may require you to do some leg work, pushing in various methods so you can change them.
For Roo-built services and repositories, any entity integration tests you define with test integration will automatically adjust between testing the entity directly and using the repository or service layer, if you’ve generated one for your entity.
This means that you already know how to test Roo-built services and repositories.
Roo doesn't actually support the generation of freestyle tests from the shell.
So, to build one, you can either create it using your IDE or use the class command to ini­ tialize it:
Roo uses Spring’s annotation-driven JUnit 4 test runner in the automated integration tests.
The @ContextConfiguration annotation defines the Spring context files to search for to load your test.
Roo stores these in META-INF/spring, so pull in the primary con­ text file, applicationContext.xml.
Next, you tell JUnit that it has to run under the Spring Framework with your @RunWith annotation.
The test will exercise the BillingService, verifying that an invoice can be created based on student registrations that haven’t yet been paid.
It also captures the id of the student that you'll use to generate the invoice:
Now you've seen how you can write tests against live Spring beans such as Roo services and repositories.
You can use this technique to test any Spring bean in your container; just autowire the bean into the test and exercise it as you would in your application code, using asserts to verify behavior.
Now that we’ve discussed how to write integration tests, we should mention that all of the tests introduced so far are rather invasive, looking at the system from the inside.
Equally valuable are tests that look at the system as a black box: tests external to the application that exercise the application as a user would.
For those tests, we’ll look at Roo’s support for web testing, using the Selenium automated web testing tool.
Testing shouldn’t stop at the unit test or integration test level.
These tests all exercise a particular component or set of components in compositions that you define yourself.
But the best way to verify that the entire stack functions properly is to use some sort of external, black box test—meaning a test external to the application itself.
At a bare minimum, what you need is a mechanism to assert tests against the user interface, so that you can start testing at the level of a user interaction.
Roo has sup­ port for this approach in the form of the Selenium web testing framework.
It can exercise browser-based tests against an application, and has a Firefox-based IDE (Selenium IDE) for building tests interactively against a live application.
Selenium tests can be written in a number of languages, from HTML to the Java JUnit API to other languages such as Ruby or Python.
Selenium tests can be used in a number of ways, including.
Feature testing—Testing various use cases in your application, using a browserbased approach.
Monitoring—Checking that a representative controller returns a valid result, which would indicate that the application is online.
Load testing—Using Selenium’s distributed testing engines, a heavy load can be placed on the application from a number of machines.
Selenium is widely adopted and there are a number of resources, such as JUnit in Action, Second Edition, that document it in detail.
We’ll focus on how to get Selenium up and running against a RESTful controller, and then we’ll look at how to add JUnitbased Selenium tests for more sophisticated testing scenarios.
As with everything else in Roo, the Selenium framework is installed with a simple Roo shell command.
The selenium test command takes several options, including the mandatory controller class to test:
Installs the Selenium dependencies and the Codehaus Maven Selenium plug-in in the Maven pom.xml file.
Builds a test-suite.xhtml master test suite file, which Roo will maintain whenever.
Builds a test case for the entity scaffolded by the controller, with the name of.
You’ll see immediately that Roo’s support for Selenium mostly focuses on scaffolded controllers.
This may be a bit limiting, but later in this chapter we’ll show you how to install support for any controller you want by using the JUnit API.
To run your tests, you first have to launch your web server.
Open a new command prompt, switch to the project root directory and issue the following command to launch the Jetty web server:
You’ll need a running instance of your application in order to run Selenium tests.
To trigger the tests, issue the following command from another operating system prompt to run your tests:
This command launches the Selenium test runner, which should launch an instance of the Firefox browser and run your tests.
Figure 9.5 Successful Selenium report showing test run of the test-tag.xhtml test.
A test report will be generated in HTML format and placed in target/surefire-reports/selenium.html.
The contents of this test are shown in figure 9.5
Looking at the test report, you’ll see that it contains counts of the number of tests, how many passes and failures, and the details for each test.
Any failed test or test com­ mand is shown in red, successes are shown in green.
You’ll also see a detailed log of each test step underneath the pass or fail data.
So now that you know how to install Selenium and generate and execute your tests, let’s take a look at the test suite and the test that you initially generated on your Tag object.
The generated tests are controlled by a master test suite file, test-suite.xhtml, located in src/main/webapp/
Let’s review the contents of that file after you’ve generated the Tag test, as shown in the following listing.
Roo maintains the test suite, adding to it every time a new Selenium test is gener­ ated from the Roo shell.
You can write your own test suites, place them in the same directory, and add them to this test suite file.
Roo also generated your test case, based on the fields of your entity.
Let’s take a look at the test-tag.xhtml test file next.
The HTML-based Selenium test language was designed so that power users and advanced business experts could read and interpret it.
You can see that the test starts by opening the URL to the tag controller B.
Then, using the HTML ID of the field ele­ ments, the type command enters a value into each field C.
Finally, the clickAndWait command D tells Selenium to press the proceed button and wait for a valid response.
Any change to the entity will also affect a change to the generated test file.
Roo will append only scaffolded tests to the test-suite.xhtml file, so you can add additional test files.
Any additional entity will add an entry to the test suite.
In this way, you can do some basic testing of the create method of the form.
But what if you’re not scaffolding, or you want to take it a step further? You have two options: either you can add the additional test to the suite and write it in HTML semantics, or you can use the JUnit framework to generate test cases.
The generated Selenium test submits form data based on legal values from the Bean Validation annotations, clicks the proceed button, and verifies that the next page is displayed.
Selenium tests can draw upon the full list of commands, collectively known as Sele­ nese.
Bear in mind, well-written tests attempt to perform a single activity and verify the result.
The test opens an entity creation page, types data on the page, and submits the form.
You can go a step farther and assert that the data submitted by the test is reflected in the new page.
Here’s a variation on the test that checks that the fields are shown in the show view, which is displayed after you submit.
Web testing with Selenium test to a test-tag-with-assertions.tagx, and add the lines in the following example to the end of the table:
These commands verify that the div with the id specified in @id hold the value in the third table element.
You can use the assertText command to fail the test and stop running further commands, but the verifyText command you’re using marks the test as failed while it continues to run the rest of the commands in the test file.
If you want to know more about Selenium, we suggest you install the Selenium IDE, a Firefox plug-in that allows you to record, edit, and play back Selenium test cases.
The Selenium IDE has full support for editing the commands generated by the tests you created in this chapter.
Fire it up and import your HTML test case into the editor.
You can run the test interactively, debugging and modifying the commands until you have the test you want.
Note: Don’t save it with a preexisting generated test name, or it’ll get overwritten when Roo adds another field to the entity.
When you’re working in the Selenium IDE, you’ll see a drop-down list of commands.
These commands are the language of Selenium, known as Selenese.
There are a num­ ber of key commands that perform activities ranging from typing text into fields, to comparing values on forms, to verifying that text is, or is not, present, to submitting forms.
You can also use this command to select from an option field, using the data value, not the visible option.
If used with the suffix AndWait, assumes a server call has been made, and waits up to the configured timeout time for a response from the server.a.
Pauses the script until a new page is fully loaded.
Many commands in the HTML Selenese dialect can be suffixed with AndWait.
Consult the Selenium reference guide, experiment with the Selenium IDE, and write your own tests.
If you want to run an additional XHTML test, you’ll have to add it to the Selenium test­ suite.xhtml file.
Assuming you named your new test test-tag-with-verify.xhtml in the same directory, you would add it to the test table, as shown in the following example:
If it seems wrong to you to write test code in an HTML or XML markup language because you think, as we do, that code is code, and XML is configuration, you can rest easy.
This means that APIs are available to a wide variety of programmers, and as such makes Selenium a go-to technology for many web testing efforts.
Write your JUnit tests, or convert them from HTML using the Selenium IDE.
Optionally, configure Maven to run your tests in the integration test phase.
To install your Java Selenium API, add the following dependency to the pom.xml.
Note that all of the other formats also display in the drop-down menu in the previ­ ous figure.
The latest Selenium IDE has removed the Format menu option, and recommends cutting/pasting in a given language format.
The following listing shows the generated code for your sample test, modified so that you can make it consistent with the rest of your application framework.
Instead of using the XTML syntax, you can use real, honest-to-goodness com­ piled Java code to write your tests.
You can also use [CTRL-SPACE] for code assistance in your favorite IDE.
Now, that feels more like it! Let’s inspect this code a little more.
See the sidebar in this chap­ ter on running a Selenium server to configure this.
You’ll also need to be running your web application; otherwise, the tests won’t run, because they can’t connect to the server.
Your test method contains calls to the selenium object, which communicates with the Selenium server to execute your tests.
Now you can script tests to execute calls to your test web browser, typing data in fields, and clicking various buttons.
Why do you have to fire up the Selenium server? It may seem strange that the HTML-based Selenium tests don’t require you to fire up your own server process, but the JUnit ones do.
There’s a simple reason: the mvn selenium:selenese goal does launch and stop the Selenium server, but when run­ ning normal JUnit tests, the Maven surfire test runner plug-in isn’t aware of your Selenium test requirements.
You can configure Selenium, and even Jetty, to run your Selenium JUnit tests during the integration test phase of Maven, rather than the unit test phase.
You can even start the Selenium server and Jetty web server when running your integration tests and execute the entire test suite automatically.
If you think starting a Selenium server in order to run tests seems complicated, and you’d like to try something more advanced, you can use the WebDriver API to write and execute Java Selenium tests in Selenium 2
This eliminates the need to fire up a Selenium server, and the API is more direct and simplified.
To use the WebDriver API, replace your Maven dependency on the Selenium Java client driver with this:
With this API, you only need to boot the web server, not the Selenium driver.
The sample coursemanager project in the chapter-09-testing folder uses the WebDriver API for two tests: ITCourseSelenium.java and ItTagSelenium.java, located in the web test directory.
Let’s take a quick look at the ItTagSelenium.java test to compare the API to the pre­ vious example:
First, WebDriver has a more fluent, chained API, and second, the web drivers are created and used.
No Selenium server needs to be configured to run WebDriver tests.
We’ve also configured the project so that the Jetty web server is booted before integration tests fire, and shut down after they’ve been run.
You can find out more about the WebDriver at the Selenium project website, http:// seleniumhq.org.
There are a number of considerations we haven’t discussed, and testing via the web is an enormous topic.
Keep in mind that the most difficult part of web testing is getting to the right level of detail.
You can certainly write web tests that dig deeply into valida­ tion rules and test service logic.
Here are other things you can do to improve your testing and overall code quality:
Install the Maven Reporting plug-in, configuring the Cobertura code coverage report as well as the Surefire Testing report.
These reports, when run with mvn site, can tell you the health of your unit and integration tests, and show you the code coverage of your application.
More information about Maven-based tests can be found in chapter 10 of JUnit in Action, Second Edition, or at the Maven website, http://maven.apache.org.
Configure a continuous integration tool, such as Jenkins (http://jenkins-ci.org), to run your build each time somebody checks in your code.
Look into other code-quality inspection tools that are compatible with Roo and Maven, such as Sonar (http://sonarsource.org)
Above all, your comfort level with changes to your application can only improve as your code coverage increases, because any change that breaks your software will instantly show up when you perform your unit testing and Spring container tests using mvn test and functional tests with Selenium, the Maven Surefire plug-in, and mvn verify.
In this chapter, you’ve learned how to test from a Roo perspective.
You’ve reviewed all of the major testing approaches, from unit tests with stubs, mocks, and Roo’s entity mocking support, to Spring container integration tests, to web testing with Selenium.
Testing is a key part of the development lifecycle, and you’re encouraged to write tests against any of your coded logic.
Let’s look at some other topics you may want to consider.
If you want to emulate more advanced features of your web tier, you can review Spring’s built-in mock objects, included in the spring-test.jar and spring­ aspects.jar artifacts, which include the mock web elements MockHttpServlet, MockHttpServletRequest, and MockHttpServletResponse.
You should also pay close attention to mock object frameworks.
They’re the best way to isolate your objects under test from other objects.
Pick one mocking framework, as doing so makes it easy to read your tests without having to switch gears constantly.
Most real-world applications also have requirements for other functionality like sending emails to customers, or asynchronous offline data processing to lower the impact on the real-time application access.
One chapter can’t convey all of the nuances and issues you’ll face when writing tests against your applications.
You have a number of big topics yet to learn on testing in general.
JUnit in Action, Second Edition (Manning Publications, 2010) is a great guide to unit and integration testing from the ground up, and includes a section on web testing with Selenium and other APIs.
In the previous two chapters, you secured your Roo application by adding the Spring Security API to the application architecture mix, and you learned how to enrich the web tier of the Roo application so it’s functional from a business stand­ point.
In addition to robust security features and a rich user interface, a real-world application also requires services such as customer email notification and offline data processing that occurs outside of your main business operations, where your customers receive notifications about results at a later time.
In this chapter, we discuss the integration that the Roo framework provides for email and asynchronous messaging using the Java Message Service (JMS) API.
We review three different use cases to demonstrate how to integrate email notifications.
We look at Roo commands to set up the infrastructure for email and JMS components.
And we define Spring bean components to abstract the connection configuration parameters to communicate with these enterprise services.
Finally, you’ll generate the template code to send emails and post messages to a JMS topic and a queue.
By the end of this chapter, you’ll understand how to implement enterprise applica­ tion services like email and JMS messaging.
You’ll also be well versed on two design patterns: publish-subscribe (pub/sub) and point-to-point (PTP)
With Roo’s built-in support for email and JMS services, you’ll also see why it’s easier to implement these requirements within your application if you use Roo.
We start with a brief overview of email and JMS support that comes out of the box with the Spring Roo framework.
We also cover how messaging works, the types of mes­ saging, and the details of how Roo implements email and messaging components in enterprise Java applications.
Roo includes excellent support for several enterprise services as well as Java Enterprise Edition (Java EE) resources such as email and messaging.
Roo also makes it easy to install the various components (configuration files as well as application code) that you need to enable email and messaging functionality in a Java application.
Roo provides the mail commands to set up the three components you’ll need to implement the email notification capability.
Mail sender —This is the Spring Bean configuration for the JavaMailSenderImpl class and the SMTP mail server configuration parameters.
Email template —This is the Spring Bean configuration for the SimpleMailMessage class.
Later in this chapter, you’ll learn how to create these components using code exam­ ples.
But first you’ll need to become familiar with the asynchronous messaging para­ digm and how it helps with offline processing requirements of Java applications.
Messaging is a communication method between software components where an appli­ cation can send or receive messages to and from another application.
Each applica­ tion connects to a messaging agent (JMS broker) that provides facilities for creating, sending, receiving, and reading messages.
Asynchronous messaging is based on a loosely coupled architecture in which the message sender and receiver don’t know anything about each other, and they don’t have to be available at the same time in.
This architecture is a Asynchronous messaging core part of service-oriented architecture (SOA) and cloud computing (CC) architec­ tures, both of which have been gaining more attention in recent years.
The JMS API defines a common set of interfaces and associated semantics that allow Java applications to communicate with other messaging implementations.
These advantages include loose coupling, reliability, scalability, and message durability.
One of the use cases discussed later in this chapter (the course registration wait-list notification) is a good example of a use case that benefits from these advantages, and helps you implement JMS messaging using Roo commands.
The following sections briefly discuss the two messaging domains called publishsubscribe and point-to-point.
Another good resource is ActiveMQ in Action (http:// www.manning.com/snyder/), which details messaging-oriented middleware applica­ tion development using Apache’s ActiveMQ container.
In a publish-subscribe, or pub/sub, messaging scenario, a service component posts messages to a topic.
Publishers and subscribers dynamically publish or subscribe to the topic.
The messaging container takes care of distributing the messages arriving from a topic’s multiple publishers to its multiple sub- Publish-subscribe messaging scribers.
Topics retain messages only as long as it takes to distribute them to current subscribSubscriber 1 ers.
In this messaging domain, each message may have one or more message consumers.
The JMS destination you use for processing the Subscriber 2
Publisher Message Topic pub/sub communication is topic (which is represented by the Java class Topic in the.
The point-to-point pattern is built around the concept of message queues, senders, and receivers.
Each message is addressed to a specific queue, and the receiving clients extract the messages from the queue or queues established to hold their messages.
Queues retain all messages sent to them until the messages are consumed, or until the messages expire.
The corre­ sponding Java class for a JMS queue is the javax.jms.Queue class.
Also included is a command for configuring the application-level JMS components and helper classes such as the JMS Template and the JMS Listener class.
If you have experience implementing asynchronous messaging using the JMS API in a Java application, you’ll understand how many different objects you need to create in order to send a simple message.
The steps include the following JMS constructs: connection factories, destinations, connections, sessions, message producers, and message consumers or listeners (for receiving messages)
Roo makes it easier to create all these messaging components by running just a few commands without having to write a lot of Java code or XML configuration..
These commands are discussed in more detail, using code examples, later in this chapter.
This application will include different use cases that use the asynchronous messaging paradigm.
The business use cases for email and messaging services discussed in this chapter include course catalog distribution and course registration confirmation notification.
The course catalog distribution use case involves publishing course catalog updates to a JMS topic, which trading partners subscribe to to get course updates.
These trading partners can include institutions such as schools, community organizations, or other vendors.
The course registration confirmation notification use case uses email and a JMS queue to notify customers who have successfully registered for a specific course.
The best way to see how these use cases work is to try them out in a sample applica­ tion.
Let’s do that with a look at three use cases in the Course Manager application.
If you’re working on any messaging-related applications in your organization, an excellent resource for mes­ saging design patterns is the Enterprise Integration Patterns book by Gregor Hohpe and Bobby Woolf.
Srini met Gregor at a Java symposium in 2004 and attended one of his sessions on EIP patterns.
Setting up JMS in the Course Manager 247 (the two we discussed previously and a third called the course registration wait-list notification use case) that use email functionality and asynchronous messaging to implement the business requirements.
Asynchronous messaging uses JMS technology and covers both the pub/sub and PTP messaging scenarios.
The Course Manager application will broadcast the course catalog updates by posting a course catalog message to a JMS topic.
Then the trading partners who subscribe to this topic will receive the message to process it and update their information systems.
Roo uses the ActiveMQ messaging container as the default JMS provider.
ActiveMQ is an open source, lightweight asynchronous messaging and integration patterns provider from the Apache team.
ActiveMQ also supports advanced messaging features such as message groups, virtual destinations, wildcards, and composite destinations.
Integration with the Spring framework is available out of the box, so you can embed ActiveMQ into Spring applications easily and configure it using Spring’s XML configuration, which is what Roo does when you run the JMS commands.
This feature benefits developers who follow test-driven development (TDD) techniques to test their application logic outside the container, without having to build and deploy the appli­ cation every time they make a code change.
The second use case is the course registration confirmation notification.
When stu­ dents successfully register for a specific course, the requirement is that the Course Manager application immediately notifies them (via synchronous notification) that their registration has been successful, and provides a confirmation number.
The final use case you’ll implement is the course registration wait-list notification.
When a student tries to register for a course that’s already full, the Course Manager pro­ gram will capture the registration details and notify the student that their registration request has been placed on a waiting list.
It will also notify the student again when some­ one else cancels their registration and there’s an open spot available for the course.
Let’s look more closely at each of these three use cases and implement them using Roo commands so you can see how the Roo framework supports enterprise services like email notification and asynchronous messaging.
Your first step is to implement the course catalog distribution use case.
In this section, you’ll create all of the messaging components needed for the use case.
The process flow diagram for the course catalog distribution use case is shown in figure 10.3
You’ll use Roo commands to create the JMS topic and the other messaging components needed to implement this use case.
All the JMS commands are contained in the org.springframework.roo.addon.jms.JmsCommands class.
The first step to enabling JMS capability is to install a JMS provider in your Roo project.
Similar to the persistence setup command, the jms setup command requires you to specify the provider details such as the JMS provider type (a required argument), the destinationType (an optional argument; specify QUEUE or TOPIC), and the destinationName (also an optional argument)
The following command is for the provider setup, where you’ll create a new JMS topic called CourseCatalogUpdateAlerts to post the course catalog details:
The following example shows the console output for this command:
In the previous example Roo added dependencies to the Maven build file (pom.xml)
These dependencies are required to implement the JMS-related code in your application.
The XBean library E included in the Maven application build file in the previous listing allows you to run the ActiveMQ messaging broker by referencing an XML configuration file located in the classpath.
The XBean URI points to an XML document, which can be parsed via the XBean API.
You’ll need the Spring JMS JAR file B to use Spring JMS classes, such as org.springframework.jms.core.JmsTemplate and org.springframework.jms.connection.CachingConnectionFactory, which simplify the JMS code in the application.
Roo also creates a new Spring configuration file called applicationContextjms.xml, which contains the Spring bean configuration details for all of the messaging components used in the application.
Note that the previous configuration file uses the ActiveMQ namespace (amq) B, which simplifies the configuration syntax for defining the JMS components.
Similarly, the Spring JMS namespace C simplifies the configuration for Spring JMS classes (like jms:listener-container, shown in the previous configuration)
The ActiveMQ messaging broker D and the JMS connection factory E beans are used to configure the infrastructure details of the JMS container.
The JMS connection factory used for the Spring JMS template is an instance of the CachingConnectionFactory class (located in the org.springframework.jms.
Listing 10.2 The Spring context configuration file with JMS components.
The advantage of using the CachingConnectionFactory class is to avoid creating a connection for each request to post a message to the JMS destination.
In the next section you’ll see how Spring’s JMS template G works.
The JMS topic you’ll use for this use case is defined by the amq:topic element H with a JNDI name of jms.topic.CourseCatalogUpdateAlerts.
The next step is to add a JmsTemplate attribute into an existing class (usually a controller or a service class)
The JMS template creation command requires two parameters: fieldName for the name of the field to add (default is jmsTemplate), and class, which is the name of the class to receive this field.
Let’s type in the command field jms template, which creates the template attribute and shows the following output: Managed SRC_MAIN_JAVA\com\rooinaction\coursemanager\web\➥
The JMS template field and a new method called sendMessage have been added to the controller class, as shown in the following code.
In the previous code example, the new variable jmsTemplate B is used for injecting the instance of JmsTemplate into the controller class.
The sendMessage method C is where you add your custom business logic for posting the message into the JMS destination (topic)
The third step in the JMS setup is to create a JMS consumer class.
You’ll use the command jms listener class for this step.
The command takes three parameters: class (mandatory parameter to specify the name of the class to create the JMS listener), destinationName to specify the name of the destination (default value for this parameter is myDestination), and destinationType,  which is used to define the type of the destination (default is QUEUE)
Type in the following command specifying the custom names you want for your JMS components:
Roo adds the JMS configuration in the applicationContext-jms.xml file, as shown in the following listing.
The JmsCourseCatalogUpdateTopicListener class D is where you’ll write the logic on how to process the message received from the CourseCatalogUpdateAlerts JMS topic.
The Spring JMS module makes it easier to expose a POJO as a message-driven component C with the help of the JMS listener container B component.
There’s also a new Java class, JmsCourseCatalogUpdateTopicListener‚ added in the package you specified (org.rooinaction.coursemanager.messaging)
This new class has a placeholder method called onMessage that you can use to add your busi­ ness logic to do the processing when a message is posted in the CourseCatalogUpdateAlerts JMS topic, as shown in the following example:
With the required JMS setup complete, you’re ready to test and validate the JMS broad­ cast functionality in the Course Manager application.
But if you want to do this testing using the web application inside an application server container, you’ll have to com­ pile, build, and deploy the web application to the container before you can do any.
You’ll also need to launch the application, navigate to the home page, update the course catalog, and publish it.
All of these steps take time, which could impact your development time and progress.
So, in the spirit of agile software development and unit testing, you’ll create few test client classes to make your job easier and your testing faster.
You’ll post the message to the JMS topic using Spring’s JMS template class in the test client.
This gives you an easy way to publish and intercept the events that you can use to unit test the JMS functionality from within the IDE, without having to build and deploy the web application to the container.
The following listing shows the code for the JUnit test class, CourseCatalogUpdateEventPublisherTest‚ that you’ll create to test JMS functionality.
When you run the unit test class, you’ll see that when the CourseCatalogUpdateEvent occurs, the message listener (JmsCourseCatalogUpdateTopicListener) will get the program control and process the JMS message.
That’s all of the steps required to enable the publish-subscribe messaging feature for the course catalog distribution use case.
We’ll come back to the point-to-point messaging domain later in the chapter, but next we’ll look at how to integrate the email notification feature in a Roo application.
This is covered in the following section as part of the course registration confirmation notification use case.
Listing 10.5 JUnit test class for testing course catalog distribution event.
The course registration confirmation notification use case involves a synchronous pro­ cess, so you want to ensure that all steps in the process are successfully completed before a confirmation email is sent to a student.
The process flow details for this use case are shown in figure 10.4
There are three main steps to implement the course registration confirmation notification use case, which we’ll cover in detail in the following section.
These steps include defining the SMTP server configuration, the email message template, and the email template attribute.
Similar to the JMS configuration, the main steps to enable the SMTP configuration using Roo mail commands include setting up the SMTP server and email message template, and adding the mail template attribute in a Java class (usually controller or service)
For your sample application, you’ll also create a custom Java class to encapsulate the email processing application logic so any class in the application can use this helper class for the notification requirements, without having to duplicate the same logic in multiple classes.
The next few sections show the different mail commands you’ll use to enable the email feature in your sample application.
Before you set up the email configuration, you need to create an interface and an implementation class for encapsulating the email processing logic to decouple it from the application logic.
The Roo shell supports creating new Java interfaces or classes from the command line using interface or class commands, respectively.
Roo creates the Java interface in the specified package and displays the following  output:
Now, run the class command to create the skeleton for the implementation class called NotificationServiceImpl:
Now that you have the helper class (and its interface that the client classes can use to delegate the email processing logic), you’re ready to build the infrastructure compo­ nents of the email configuration.
First among these components is the email sender (SMTP server)
The email sender setup command installs Spring’s JavaMailSender in this project.
This command takes several parameters with the information required to configure the Spring bean configuration for the JavaMailSenderImpl class.
Here’s a list of these parameters and what information they provide to the command.
To set up the SMTP server configuration, use the following command:
This command creates a new properties file called email.properties to store the SMTP server connection parameters.
It also adds the mailSender Spring bean configuration to the applicationContext.xml file.
In a real-world application, you should define the SMTP server as a JNDI resource.
For example, to configure an SMTP session as a JNDI object in a Tomcat container, you’d add a new Resource element in the configuration to Tomcat’s context.xml file.
The previous configuration will create a new SMTP resource in the Tomcat container and will be available for all web applications running on the servlet container.
This configuration is straightforward, but let’s look at how to view and modify the SMTP properties in the file generated by Roo.
You can use the Roo shell command called properties to view and modify the con­ tents of properties files like the email.properties file created in the previous step.
Let’s check the contents and modify one of the properties in this file.
First, to view the email.properties file contents, type in the following command:
The output of this command is shown in the following example:
You can do this by using the properties command with the set argument.
It shows the following message, which says that the properties file has been updated:
You can call the properties list command again to view an update.
A different com­ mand will display all of the properties of the Roo shell.
This command is system properties, which displays the following output (abbreviated to show only the first few entries)
After you’ve modified the SMTP properties to fit your application requirements, you’re ready to create the SMTP message template.
You need to create the email template that the Spring framework will use to send the email messages.
The command email template setup configures a template for the SimpleMailMessage class using two parameters: from and subject.
This command adds the following two additional properties to the email.properties file:
This command also adds a new Spring bean definition in the applicationContext.xml file for the MailMessage template class with the from and subject attributes set to the specified values in the command line:
In this last step, you set up the email template attribute in the newly created custom NotificationService class.
The NotificationServiceImpl class will now look like that shown in the following listing.
This class has the attributes for the SMTP mail server B and Spring’s MailMessage implementation class C to abstract the email send logic.
You can now run the Eclipse command, perform eclipse, to refresh the project contents so the Roo project is refreshed with all of the code and configuration changes you’ve made so far.
You’ll create a test client class similar to the way you tested the JMS functionality to verify the registration notification functionality.
The following listing shows the code example of the test class RegistrationNotificationEventPublisherTest.
Now that we’ve covered the first two use cases in the Course Manager sample application, you know how to enable the JMS (pub/sub) and email features in Roo applications.
Let’s look at the step-by-step details for implementing point-to-point asynchronous messaging, which involves a queue (as opposed to a topic)
The course registration wait-list notification use case involves asynchronous messaging, where the main business process stops when a customer’s registration request is placed on the waiting list.
The offline processing includes a JMS queue-based messaging solution, which uses a CourseRegistrationCancellationEvent to unregister a customer who wants to cancel a registration.
The program then notifies the first customer on the waiting list that there’s an open spot in the course and their registration has now been confirmed.
Let’s look at how you would implement this use case in a Roo application.
Similar to the first use case covered in this chapter, the JMS configuration for the course registration wait-list notification use case includes steps for setting up the JMS queue, called CourseRegistrationWaitListQueue.
You’ll use the same JMS provider (ActiveMQ messaging server) you created in that use case and create a message queue on that JMS container.
This use case requires three steps, which include creating a new message queue, a JMS template, and a message listener class.
Listing 10.10 JUnit test class for course registration confirmation notification.
The first step in the JMS configuration for this use case is to create a message queue that will be used to post the course registration wait-list notification details.
Here’s the JMS command to add the configuration for a JMS Queue with the name jms.queue .CourseRegistrationWaitListQueue:
The message queue configuration step adds a new amq:queue Spring bean in the JMS Spring configuration file.
As shown in the following snippet, a JMS queue (amq:queue) and a JMS listener container (jms:listener-container) for mapping the queue to the JMS provider are added to the applicationContext-jms.xml file:
After you configure the message queue component, the next step is to add a JMS template to the helper Java class, which in this case is the CourseRegistrationNotificationHelper class.
As the following command-line output shows, Roo added the JMS template attribute (jmsTemplate) to the CourseRegistrationNotificationHelper Java class: Updated SRC_MAIN_JAVA\org\rooinaction\coursemanager\web\➥
Now for the final step: you need to add a listener class that acts as an asynchronous message consumer.
The following is the Roo command for the message listener configuration:
The following Spring bean element for the JmsCourseRegistrationWaitListQueueListener class is added to the XML configuration file:
With the configuration steps complete, you’re now ready to test the new Java classes and configuration changes for the course registration wait-list notification use case.
To test the course registration wait-list notification functionality, you need to post a mes­ sage to the JMS queue and process the message using the listener class.
Let’s write a new unit test class (called RegistrationNotificationWaitListEventPublisherTest) to test the wait-list scenario.
The following listing shows the code for this unit test.
Listing 10.11 JUnit test class for course registration wait-list notification.
Another good case for using JMS messaging is the certificate completion use case.
Let’s say the Course Manager application organization outsources the process of printing the course completion certificates and mailing them to the students.
You can use the Trading Partner user role (ROLE_TRADING_PARTNER), for example, to notify of the course completion event and provide the student details.
This allows the course completion certificate with the student's information to be generated and sent to the student.
As previously discussed in this chapter, there are several different components that are working together in a typical enterprise messaging application to send, receive,
This is why it’s important to monitor these JMS components to see what’s going on behind the scenes of the application to be able to respond to any production problems and troubleshoot the messagingrelated issues.
This is what we’ll look at in the next section on how to monitor the Course Manager application using tools like VisualVM.
Now that you’ve implemented all of the use cases, let’s look at how to monitor your application to ensure that the various JMS resources you’ve installed and configured (JMS container, JMS topic, and JMS queue) are up and running, as well as how many messages they’re processing.
The Java standard for application and system or server monitoring is the Java Man­ agement Extensions (JMX)
For JMS message activity monitoring purposes, Roo pro­ vides a JMS add-on that enables monitoring (JMX) support by default.
So you can check the JMS message activity using tools such as JConsole, VisualVM, or any other JMX client.
To turn on the monitoring capability in the ActiveMQ messaging broker, you’ll use the useJmx parameter (with a value of true) in the amq:broker element.
After you make this change and restart the messaging server, you can use the following URL to connect to the ActiveMQ Broker JMX MBean server: service:jmx:rmi:///jndi/rmi:// localhost:1099/jmxrmi.
After you’ve enabled the JMX feature in the ActiveMQ broker, you can use a JMX client to monitor the messaging activity in the application in a server runtime environment.
The VisualVM tool comes bundled with the JDK installation, with the jvisualvm and jconsole executable files located in the%JAVA_HOME%/bin directory.
Note that JAVA_HOME is the folder where you installed JDK on your machine.
The JConsole module in VisualVM can be used for monitoring the MBean components.
Open a new command prompt and run the following commands to launch the VisualVM tool:
Figure 10.5 shows the MBean screen in the JConsole JMX client tool.
Another monitoring tool you can use in nonproduction environments is the new.
Figure 10.5 Messaging activity details using the JConsole JMX client.
Spring Insight provides a graphical look at an application's performance, responsetime charts, and histograms, providing developers with a dashboard view into the application's runtime environment to find where it’s spending most of its time in the program flow.
Spring Insight gives visibility into the application performance for each web request made in the web application.
You can see all of the JDBC requests made, how much time it took to render the web pages, or the initialization times for any of the Spring beans.
Also, the Application Health screen shows which Spring MVC control­ lers are taking considerable time and allows you to drill down into the details of the requests that took longer times.
You can also navigate to specific remote web service calls that were made.
Spring Insight uses the AspectJ load-time weaving feature to add the tracing and monitoring statistics to web applications.
This means your sample application doesn’t require any additional code or configuration changes to use Spring Insight.
Also, Spring Insight collects the response data in memory and doesn’t require a backend database or a persistent data store.
If you’re using the STS tool, you already have Spring Insight available for you to monitor your application's performance and other server metrics.
At the time of this writing, Spring Insight doesn’t have a plug-in for JMS, but it’s on the feature list to be added in a future release.
You can still see the components that were triggered by a JMS message.
Spring bean component (such as a Java class that uses one of these annotations: dashboard.
Note that Spring Insight shouldn’t be used in a production environment because it displays a detailed view of all of your application's performance details, including sensitive information about the application and server settings.
It’s meant for develop­ ers and QA testers to get runtime visibility into the applications in nonproduction environments.
The Spring Insight reference manual (see the “Resources” section at the end of this chapter) is a good resource for learning more about this application monitoring framework.
Let’s use the Spring Insight tool to monitor the activity in your application, including JMS messaging activity.
You’ll need this URL to view the dashboard: http:// localhost:8080/insight/traces.
Open a web browser and navigate to the Spring Insight dashboard page using the previously mentioned URL.
Click on the Browse Resources tab and expand the web application node in the Resources pane under the application’s root node.
When you run the Course Manager application and test the course registration functionality, you can see the details of the controller classes being called, and the messages being sent to JMS destinations (CourseCatalogUpdateAlerts topic and CourseRegistrationWaitListQueue queue) and consumed by the corresponding JMS listener objects.
You can view the attributes of various JMS components as well as invoke the operations (meth­ ods) of these components to dynamically change the JMS configuration parameters.
In this chapter, you learned how to send email notifications to your Course Manager application customers (students) from within the Spring Roo application, without having to write or configure the setup for the email provider, email processing logic, and so on.
Roo’s email add-on makes it easier because it requires only a few com­ mands to set up the SMTP provider and add Spring’s email template classes into your application.
You’ve also learned how to implement asynchronous messaging for business use cases that require offline processing capability, such as the course catalog distribution and the course registration wait-list notification use cases.
You were able to do this by leveraging another Roo add-on, the JMS add-on, provided by the Roo framework.
At this point in the book, all of the chapter discussions on the Roo application have been based on it being deployed on a server hosted by an organization’s internal server environment.
Roo once again provides excellent support for moving the Course Manager application to an externally hosted server environment.
But before that, in the next two chapters, we’ll look at how to cre­ ate custom add-on components using the Roo framework.
In the previous chapter, you learned how to process email notifications to the cus­ tomers of your sample Course Manager application.
You also took steps to imple­ ment an asynchronous processing solution based on Java Message Service technology using two different JMS destinations (topic and queue)
In this and the next chapter, we explain how to install existing Roo add-ons from the central Roo add-on repository.
Then we show you how to write and install your own add-ons, beginning with the somewhat confusingly named simple add-on.
Finally, we discuss the advanced add-on and related infrastructure features woven into Roo.
When you write Spring Roo applications you use a modular add-on architecture.
Many of the core Roo components were written as add-ons, including the entity and.
All of these add-ons are OSGi components, so if you’re confused by the terminol­ ogy, you may wish to do a little extra research.
Manning’s OSGi in Action (Hall et al., 2011) contains a thorough overview of all things OSGi, and we used it as a reference when we wrote these chapters.
Expect some of the material in this chapter to be com­ plex, because the Roo add-on API hasn’t had the rigorous refinement from hundreds of developers as have the APIs from Grails, Rails, or Maven.
Our goal in these chapters is to demystify Roo’s complexity, so we can encourage more developers to contribute to the current pool of Roo add-ons.
Without further ado, let’s roll up our sleeves and dig into Roo add-ons.
Roo was designed from the ground up to be extremely extensible.
All of the Roo features we discuss in this book are interrelated modules known as add-ons.
Each add-on can define a set of Roo commands, manipulate project configurations, and listen for changes in the file system, such as the addition or removal of a @RooToString annotation.
Roo developers can define their own add-ons and even publish them to the main Roo add-on repository.
There are add-ons in place to support web frameworks such as JSF, Vaadin, and Wicket (a recently introduced service-and-repository data mapping executable WARs; and so on.
Roo’s extensibility allows you to easily add to the set of commands and features by installing additional add-ons.
If you don’t see Roo support for your favorite feature or framework, you can write an add-on, install it, and have those capabilities in your proj­ ects.
Much like other agile development tools, Roo is only as powerful and rich as the features the community puts into it, so open source developers have the power to shape the future direction of this tool.
You already use OSGi bundles in many different software prod­ ucts, including tools such as ServiceMix, Mule, and the Eclipse IDE.
All Eclipse plugins are implemented as OSGi bundles, and you can even expose an OSGi command line by appending the -console flag to the eclipse binary.
The Roo shell environment runs atop an OSGi implementation from Apache, the Felix container.
Roo has distributed more than 37 add-on bundles that make up the base of the Roo platform.
The following list of add-ons com­ prises the base Roo install.
These add-ons may change as the Roo team continues to update the project and add new features:
Add-ons provide features in the form of specific shell commands.
You can also install other add-ons to provide support for new features and frame­ works.
Let’s review the add-on management system and some third-party add-ons.
Like other rapid development platforms, Roo has a number of add-ons available for installation over the internet, because its development team hosts a live directory of components that automatically downloads on startup.
You may see the download pro­ cess occurring on the top right of your console window, finishing with.
The downloaded file contains a list of all Roo add-ons registered with Roo-bot, a service available to Roo developers that exposes published add-ons to all Roo users.
We’ll experiment with this directory, and we’ll start by learning how to search for add-ons; then we’ll install and test an add-on; and, finally, we’ll remove an add-on.
The key thing to remember is that, unlike Grails or Rails, where the add-on is used at runtime, our add-ons are merely Roo shell extensions.
After we compile the project code, all effects of the add-on will result in standard Java EE code and web artifacts.
Use the addon list command to show a list of add-ons in the reposi­ tory, which we have excerpted in the following example:
JasperReport support you give to the project the feature of.
You’ll get a full list of the add-ons in the repository, whether or not they are compati­ ble with your version of Roo.
T)rusted—Whether the team member deploying the add-on is a trusted or.
These add-ons must be approved by the Roo team to gain the T code.
Some of the add-ons available include upgrades of key Roo compo­ nents and optional JARs, so this option weeds out internal JARs from the list.
If an addon has more documentation, you can expand the number of rows to read the result.
Use this option to force a reload of the list.
You can also use the search command to locate a specific add-on.
The --requiresCommand option searches for the commands provided by the add-on:
More than one way to install a Roo add-on There are four ways to install an add-on to your Roo configuration:
Use the addon install command to install it from the central Roo add-on repository.
Use the osgi start command to install add-ons from a URL or a file.
You’ll use this technique later in this chapter when you write your own add-ons.
Use the osgi obr repository commands to mount an OSGi repository and install the add-on from that repository.
Useful in a corporate environment where your team needs to share company-wide add-ons.
Copy the add-on JAR file to the Roo installation’s bundles directory.
We discuss the osgi start and osgi obr commands in the next chapter.
The report format is a bit basic, but we hope to soon see an add-on portal website that displays this information in a more useful way.
Commands.....: 'git revert commit' [Roll project back to a specific com.
Commands.....: 'git commit all' [Trigger a commit manually for the proj.
The Roo add-on system is a great way to find and experiment with published and contributed add-ons.
You can also install your own add-on to this repository, further contributing to the Roo platform.
Now that you’ve learned how to search for add-ons, it’s time to install one and experiment.
The first is to use the search ID of a previously executed search:
The second is to use the bundle symbolic name, abbreviated as BSN in the previous addon info command:
This method works well when you’re putting together Roo script files for your developers to use in the future, and don’t want to rely on a search result ID.
It's time to use your add-on to set up a git repository.
You can check your shell to see the new command by hitting [TAB]:
Now the git command appears alongside the rest of the Roo shell commands.
You can set up a Git repository from a Roo project.
To set up the Git repository, you can issue this oneline command:
This command will issue a git init command in your project directory, if needed, and otherwise use your existing Git configuration.
It will then issue a git commit to record the change you’ve made.
Now, any change you make to your project configuration in the Roo shell will be followed by a commit to the Git repository:
You can also force a commit right from the shell:
Working with published Roo add-ons ----------------------------------------------------------------------git revert last --message "undid the entity create - not needed."
There are more features of this add-on, so consult your addon info output and experiment.
You can use the addon upgrade command to search for and automatically install upgrades to Roo add-ons:
Due to a missing add-on, however, when we upgraded to 1.2.0, the Roo shell detected a problem and was no longer functional.
If you accidentally upgrade your Roo artifacts and the shell won’t start properly, you can go back to the original installed version by deleting the contents of the cache direc­ tory in your Roo installation directory.
You’ll also lose any additional add-ons you’ve installed previously, so it’s a good idea to store your third-party add-on installation scripts in your version control system and update them whenever you add a new approved add-on.
By default, the upgrade engine searches for any version, including releases, release candidates, and milestone releases.
You can customize this, for example, by limiting to only release-level add-ons:
Or you can list only available add-ons for your Roo shell release level:
No add-ons / components are available for upgrade for level: RELEASE.
This setting is stored between restarts, so if you want to experiment, make sure to reset it before searching for upgrades.
When a user installs add-ons using the addon command, Roo verifies whether or not the user trusts the add-on developer by checking whether they have trusted the devel­ oper’s PGP key.
You can see the following list of trusted keys that are installed into your Roo envi­ ronment by issuing the pgp key command:
You can permanently trust the keyholder of this key by issuing the pgp trust command:
This command, unlike pgp automatic trust, is a permanent decision and is kept within Roo’s configuration.
If you upgrade to a new version of Roo, you may have to redo your trust relationships.
This command is tabcompletion aware, so if you aren’t sure which add-on you want to remove, keep hitting [TAB] to autocomplete the bundleSymbolicName command-line property:
But nothing will keep it up to date, so you may want to use push-in refactoring to put the code under developer control again.
As the add-on developer, you may wish to provide a remove command so that you can clean up after yourself before developers uninstall your add-on.
This command removes the artifact from the Roo installation’s bundle cache directory.
Because all add-ons are written as OSGi bundles, it may help you to learn enough OSGi to be dangerous.
For the bold, a trip into the OSGi specification, or Manning’s OSGi in Action, is a good diversion, but you can also get started with merely a basic understand­ ing of OSGi.
It allows Java applications to load, start, stop, update, and unload artifacts such as JARs and WARs on the fly, without stopping and restarting.
Think of it as a dynamic, class-loading system that’s smart enough to resolve complex dependencies.
You use OSGi in many applications today, including Eclipse, which the SpringSource Tool Suite is based on, and which runs with a small application core under the Equinox OSGi container.
The platform has been around for years and was originally developed to manage the modularity of applications on mobile devices.
We’ll begin this investigation of OSGi with a little terminology.
OSGi bundles are JAR, WAR, or EAR files that contain a special file, META-INF/ MANIFEST.MF, with some well-defined headers.
To see these headers, open a Roo shell and type in.
You’ll see a ton of output, broken up into sections by information about each bundle.
Here’s an excerpt of the contents of Roo’s entity OSGi bundle:
OSGi components export certain Java packages, using the Export-Package header.
They also require other packages to function, as detailed by the Import-Package header.
Every Roo add-on contains a manifest that describes the exposed packages, and is identified by both a human-readable Bundle-Name, and an identifier known as a Bundle-SymbolicName.
You’ll refer to the symbolic name wherever Roo asks you for a bundle’s ID.
All valid Felix command activities are valid here as well.
Keep in mind that you’re using OSGi only to expose and use components, so the utility of this command is limited.
OSGi bundles go through several lifecycle phases, including resolved, installed, started, and stopped.
You’ll learn how to use these commands when you create an OSGi bundle.
At the time of activation, OSGi loads the component into memory.
In this way, SCR-based OSGi components behave like the dependency injection model in Spring beans.
However, OSGi compo­ nents are stateful, whereas Spring’s beans are stateless by default.
You can use the osgi ps shell command to show the status of the bundles and add-ons installed in the container.
Each OSGi bundle is listed in the previous output, along with an ID, state, starting level, and name.
You can install any OSGi JAR file, and you may need to if your Roo shell commands have to interact with a Java library that’s not already installed in your Roo shell, such as a JDBC driver.
To start an OSGi module, use the osgi start command, passing it the URL of an OSGi­ ified JAR file.
If you’ve developed an add-on and have access to the JAR file, you may mount it in this way:
If your OSGi bundle happens to be configured as a Roo add-on, the shell will initialize it when started and add any configured commands.
The add-on’s JAR file and configu­ ration settings will be installed in the cache directory of the Roo installation, and will be available until removed from the system.
You can use the osgi uninstall command to unload the same Roo add-on bun­ dle.
If you’d rather update it from the latest source file, use osgi update, and tell it which bundle and what location to reload it from:
It’s easier to load and start in one step with osgi start.
If you accidentally installed a bundle using the install variant, you can start it by issuing the osgi start command.
Roo lets you create your own add-ons, using projects built using the Roo shell addon create command.
Table 11.1 outlines the differences between them, and their pros and cons.
Performs operations such as file manipu­ lation and installation of tag libraries and other files.
Pros: Easy to understand; contains simple example code to get a minimal example working quickly.
Cons: Limited features, and managing dependencies requires use of more ser­ vices and features.
Roo wrapper add-ons Table 11.1 Roo add-ons: using the addon create command (continued)
Watches code for changes and reacts when annotations are added or deleted.
Cons: Complicated, and uses a number of non-integrated APIs and services.
Devel­ oper needs to understand OSGi, Felix, and Aspect-J ITDs to get the most out of the add-on.
Installs features needed by other plugins, such as a database driver for the reverse engineering add-on.
Command can also pull in transitory dependencies with some adjustments to the Maven POM file.
If you’re installing a Roo shell command that needs a feature in a Java library, such as a JDBC driver or an email service provider, this is the one option for installing the library.
This artifact defines a language name, flag, locale, and a message source prop­ erties file to install a language into your Roo shell.
Pros: Allows for bundling of additional lan­ guages into your application, which then can be assumed into your user interface, if working with the Roo scaffolded web template design.
All four add-on types will be covered in this two-chapter series.
In this chapter, we’ll get you started by covering how to wrap a standard JAR and provide it to the Roo shell using the OSGi wrapper add-on.
We’ll create an i18n add-on to provide a Norwegian translation of the Roo scaffold labels.
Then we’ll build a simple add-on that installs jQuery, jQuery UI, and some replacement tags in the Roo tag library.
Finally, in the next chapter, we’ll branch out and create an add-on to provide access to the CoffeeScript language, which we’ll use to simplify some of the JavaScript files.
A wrapper add-on takes a given Maven artifact and wraps it with the proper OSGi MANIFEST.MF entries, delivering it as a new JAR to be used by the Roo shell.
The JAR may then be started as an OSGi bundle with osgi start and accessed by other Roo add-ons.
For example, to wrap the Apache math library, you can search for the proper Maven artifact information on http://search.maven.org, as shown in figure 11.1
Figure 11.1 You can use https://search.maven.org to search for any public artifact.
In our search, we found version 2.2 of Apache’s commons-math and will use it to construct our wrapper class.
Now, let’s use the groupId, artifactId, and version from the Maven repository search to create a wrapper add-on.
Create an empty directory named commons-math­ wrapper, navigate to it, and open a Roo shell.
Roo creates a new project that you can use to build your add-on.
The final artifact name will be the provided topLevelPackage parameter, coupled with the artifactId and version parameters, plus “.0001.” Now, you’ll create the wrapper artifact.
Once Roo completes the bundling process, the wrapper will be built in target, and the previous example becomes org.rooinaction.bundles.commons-math-2.2.0001.jar.
You can now install this bundle into the Roo shell:
You can use this technique to expose new JDBC drivers to the Roo shell, which you can use to run the database reverse engineering command discussed in chapter 4.1
You can define a special project, known as a Roo localization add-on, that contains the standard Roo web framework localization file, messages.properties, which you can translate for your required language.
For this application, you’ll create a language localization add-on to support Norwe­ gian, which isn’t provided out of the box.
You can create a new localization project by localizing your language file, providing your icon PNG, creating a new directory, and issuing the following Roo command in the empty directory:
In this example, Roo was able to look up the flag for Norway using a web service and download the norway.png file itself.
For unknown flags, you’ll have to find a legally distributable flag image, convert it to PNG format with a size of 16-by-11 pixels, and place it in the project root directory.
From this point on, the project files will be contained in the src/main/resources directory of this project, under the package specified by the topLevelPackage param­ eter.
If the add-on builds prop­ erly, you can install it into your Roo shell with this command:
To use your add-on, switch back to your web project and issue this Roo command:
Before you create your own language add-on, use the public add-on searching feature to see if someone else has already provided one.
Supporting Oracle’s JDBC drivers requires you to create a wrapped OSGi library, because Oracle currently restricts downloads of its drivers from anywhere other than Oracle itself.
For this section, we used http://translatify.appspot.com/ to translate the properties file into Norwegian.
We had to manually extract the HTML table of translated code because the zip file returned was incomplete.
This application no longer functions in the way it was used, so you’ll need to find your own translation service.
Roo uses the Dojo form library for all client-side form validation and widgets, as we discussed in chapter 7
Many developers have embraced the more widely adopted jQuery library and a wide variety of components contained within it.
The Dojo form library poses a challenge for these developers, because it chooses both a JavaScript library and a widget library for them.
Roo allows add-on developers to modify files in the installation, so it’s easy to mod­ ify the platform to suit your needs.
Let’s build an add-on to set up a jQuery-based fron­ tend.
All of these tasks can be accomplished easily using a Roo add-on.
You can create an add-on project to hold your customizations and test them with a simple MVC project.
You develop add-ons using the add-on create command, which generates a new proj­ ect.
The output will indicate that the simple add-on has been generated as a Maven proj­ ect, and organized by the usual directories, src/main/java, src/main/resources, src/ test/java, and others.
The generated add-on contains a sample component, named Jqueryaddon, which will need to be replaced.
An interface-driven Operations class, JqueryuiOperationsImpl, and its base interface JqueryuiOperations.
This component defines methods that are exe­ cuted in response to Roo shell commands.
A commands class, JqueryuiCommands, which implements the CommandMarker interface and defines the commands exposed by the add-on.
This class contains methods annotated with two annotations, @CliAvailabilityIndicator and which methods to call in your add-on operations class.
A simple add-on: jQuery UI  An enum, JqueryuiPropertyName, which is an example of an enumerated property that can be sent to a command.
Commands such as persistence setup use this component for the --database options, such as HYPERSONIC _PERSISTENT and ORACLE.
A set of tags, located in the src/main/resources directory, for potential inclusion into the consuming project.
A legal license agreement file, which you can replace with the license your project will use.
An assembly.xml file, which provides the ability to package the entire project, including dependencies, into a zip file.
You’ll need to customize these files for your purposes, so that you install the proper commands to set up the add-on.
But before you do this, you have to do some cleanup, because Roo delivers more code than you need.
You’ll need to remove some files you aren’t using to clean up the library.
Delete the tag files in the org/rooinaction/jqueryaddon directory of src/ main/resources, leaving the directory there for use by your new tags.
Now, take a moment to define your goals for the add-on.
After executing these commands, developers can use the jQuery and jQuery UI JavaScript libraries in their applications.
To develop this add-on, you’ll need to create the proper components in your addon project, and copy the appropriate file resources to the src/main/resources directory, under the project package directory, org/rooina/jqueryaddon.
Let’s start by defining the operations that the add-on will perform.
You’ve defined two command methods, one for each of the Roo shell commands: checks whether to make each of the commands available.
As you’ll see in the following listing, you’ll gut everything but the first two lines of the class, and change them to extend the Roo support class AbstractOperations, which provides a few helper methods you’ll take advantage of during implementation.
When building this class, let your IDE find the imports for you to save time.
Your add-on operations class is an OSGi service, which makes it visible to Roo for inclusion into the system.
The class now extends AbstractOperations B, a helpful abstract class that provides some project management facilities.
You also injected references to two Roo OSGi services: instances of ProjectOperations and PathResolver, which you’ll use to access components that change your project configuration C.
Unless you have to add a class or a library to the Roo runtime path, such as a JDBC driver, you won’t need to restart after installing new Roo add-ons.
Let’s build the first Roo add-on command method—the one that installs jQuery itself.
This method first copies the jquery-1.5.1.min.js file from the org/rooina/ jqueryaddon/js/jquery directory of src/main/resources.
You’ll use the pathResolver you set up at the top of your class to find the absolute path to the web application’s / js directory.
This will be created if it doesn’t already exist.3 You then use the copyDirectoryContents method B, which comes from the AbstractOperations Roo add-on class.
It uses Roo’s FileManager component to perform the copy operation.
You’ll need to download the jQuery library from http://jquery.org and place it in the previously mentioned directory for this to work.
Note that the method XmlUtils.readXml(InputStream) will automatically close the stream, so you don't need to do any cleanup.
The same holds for the fileManager method createOrUpdateTextFileIfRequired C, as it performs bulk operations to stream the file and is responsible for its own cleanup.
This component has visibility into the currently running Roo shell, which gives you the proper OS path to the file.
This class will not compile yet; you must define a helper method next, buildAndAddJSNode, to install your JavaScript tags.
Next, you need to edit the load-script.tagx JSPX tag file, and use the HTML <script> tag to install the command.
You loaded the XML source for this file into a DOM.
You’ll add a new <script> tag to the end of the document, which you access via path, var) method does the work for you:
Some HTML browsers can’t deal with bodiless script tags, so you have to add a com­ ment to the tag using the helper addComment(document, builder) method:
This method emits the following tags to the end of the script tag file:
Each time someone uses tab completion, or the Roo shell changes the configuration in some way, all Roo components are asked whether their commands are available.
The add-on can conditionally expose their commands and hide them when they don’t make sense, such as when trying to add a web feature before the web framework is installed.
You need to determine when to show your jquery commands.
You could have searched for your exact version, but then you wouldn’t be able to detect a user-upgraded jQuery library.
Back in chapter 2, we discussed how you can create multimodule Roo projects.
Asking for the focused project or identifier scopes your request for the module you’re working on, or the top-level module if you either don’t have modules or aren’t focused on one.
There are also methods to ask for the top-level project so you can affect changes at that level.
Now, if the shell user has installed jQuery before, the script file will be available in the ‘js’ directory of the web application, so it should return false.
Otherwise, it should return true, which will allow the command to become visible in the shell.
THAT’S HOW THEY HIDE COMMANDS Add-ons can provide visibility (or invisibil­ ity) of shell commands.
For example, the Spring MVC add-on is always pres­ ent, but doesn’t make itself active until you have a valid Roo project.
The entity add-on doesn’t allow you to create an entity until you have a persis­ tence context configured in your application.
Take a good look at the exist­ ing Roo add-ons from the Roo project itself to learn how you can take advantage of this.
Now let’s look at the second level of JavaScript enhancements: installing the jQuery UI.
Some developers are happy working with Dojo for their user interface widgets, but they want jQuery for other purposes.
Others may want it all and will choose to install both.
You’ll configure another command, jquery UI setup, to install the UI library as well as assets such as stylesheets and graphics.
First, you’ll detect whether you’re able to install the command itself.
You have to check whether the application is a web application and then verify that you’ve installed the jQuery library itself.
This is a variant of the check for jQuery in section 11.8.6 earlier in this chapter:
Check whether the /js directory in your src/main/webapp project folder contains a jQuery UI main JavaScript file.
If it does, and you can’t install the jQuery library (refer­ ring back to the jQuery detection method), you can install the jQuery UI.
It comes with multiple JavaScript files, a number of images, and a stylesheet.
So your installjQueryUIApi method in the fol­ lowing listing is a bit longer, but not more complex.
You also need to add another helper method to this class—one that adds a CSS node to the load-script.tagx file:
You need to take one more step: you have to tell the Roo shell that these commands exist.
To make your commands visible to the shell, you need to define your add-on to the Roo shell system.
Inject an instance of the JqueryuiOperations class via the OSGi @Reference.
This is similar to the Spring @Autowired annotation, but works in an OSGi container.
Because you have an implementation of this class, Felix will find it and inject the instance, which in this case is JqueryuiOperations­ Impl.java.
Provide at least one Boolean method annotated with @CliAvailabilityIndicator, which will return whether a method, or a set of methods, is available to the Roo shell.
This class is used by the Roo shell every time a user attempts the tab completion mech­ anism, or types in the name of a command directly.
Roo calls any @CliAvailbilityIndicator methods exposed in running add-ons to see whether they respond to the provided command.
If a user executes a command, and the indicator method returns true, Roo executes the method annotated with @CliCommand with the same text.
This CommandMarker class forwards the command request to the Operations class, which OSGi injects for you using the @Reference annotated operations variable.
You’ll see that you refer to the injected class B via the interface, JqueryuiOperations, as you would using Spring’s depen­ dency injection features.
But your class will be bloated with methods for both types of operations, so unless the add-on is small, we recommend you separate the implementation of the add-on from exposure to commands by the add-on.
You’ll install your add-on and put it through its paces next.
You can build your add-on the usual way, using mvn package to compile and turn it into a JAR file.
Any JUnit tests you write will be executed, as usual.
Please note that, at this time, Spring Roo doesn’t have explicit support for writing any sort of Roo integra­ tion tests in the Felix OSGi container.
The way you test add-ons is to install them in a test project.
Roo has attached additional steps to your Maven packaging stage, including the gen­ eration and installation of OSGi entries in the META-INF/MANIFEST.MF file contained within the JAR, as shown in the next listing.
How did Roo know to build an OSGi bundle here? Because add-ons aren’t standard JAR or WAR projects; rather, they’re defined in the pom.xml file with the packaging type of bundle, and are configured using a Maven plug-in, maven-bundle-plugin, which sets up the appropriate entries in the manifest.
Let’s take a look at the relevant sections in the pom.xml file:
Anyone who’s experimented with OSGi modules in the past will welcome Roo’s use of BND tool (see http://mng.bz/D593)
Although you didn’t write the OSGi manifest file yourself, Roo used BND to put it together for you.
OSGi expects you to explain which tion, such as the Bundle-Name, a human-readable name, and the BundleSymbolicName, the name used to uniquely identify the bundle in the Roo shell.
You’ll note that the packages from libraries used in the source code, such as org.w3c.dom and org.springframework.roo.support.util, are listed in both the them in the pom.xml file, in the build/plugins/plugin section.
For example, to exclude the export of org.w3c.dom from your add-on so that it doesn’t get installed in the container automatically, change the bundle to use the Export-Package tag:
This becomes important in more complex add-ons, because the Roo shell will take BND’s defaults and export all packages found in the source code.
To install your add-on, you’ll use the osgi start command:
You can verify the installation by using the osgi ps command; your add-on will appear at the bottom of the list:
You’ll also see your add-on in the [TAB] completion in the Roo shell, because it exposes the jquery commands.
Now for the piece de resistance: you’ll need to define a new application and install the add-on in the Roo shell for your jquery commands to appear.
You’ll start by creating a jqueryui-test Roo application: $ mkdir jqueryui-test.
Finally, tell the shell to set up your jQuery API and jQuery UI library:
To verify, take a look at the load-scripts.tagx script in src/main/webapp/WEB-INF/ tags.
You’ll see that jQuery and jQuery UI JavaScript entries have been added, and that the jQuery UI theme stylesheet has been mounted.
Your add-on worked, and it not only installed jQuery support, it also reconfigured the application to support it.
Finally, review the  contents of src/main/webapp/js, src/main/webapp/images, and src/main/webapp/styles to see the new artifacts.
Let’s modify a tag in the generated Roo tag libraries to use a jQuery UI widget, instead of a Dojo one.
You’ll edit the tag library file tags/util/panel.tagx, replacing the Dojo TitlePane widget with a jQuery UI Accordion.
Replace the DIV section and the Dojo install script with the following code:
For example, using the previous technique, you could replace all of the Roo standard tags with jQuery UI widgets, or even install other commands to provide and use other jQuery plug-ins.
You could then install those tags with a separate Roo shell command, such as the jquery tags setup.
In this chapter, we’ve looked at how to find and install Roo add-ons, and we’ve dis­ cussed how they are built on top of OSGi.
We used the pgp trust command to allow installation of signed add-ons, which let us verify their source and identity.
You then built your own add-on to install jQuery and the jQuery UI, from which you could manipulate configuration files, generate supporting tag library and JavaScript library files, and expose the commands to the shell.
You also learned how to install, update, and remove your add-ons using the various osgi Roo commands, such as osgi start.
In the next chapter, we’ll show you how to write advanced add-ons.
We’ll build an add-on to install the CoffeeScript language into your Maven build, and show you how to install it using an OSGi Bundle Repository and the Roo add-on service.
Here are some helpful links for the tools and technologies we discussed in this  chapter:
Apache Felix, the OSGi container for Roo, is documented at http://felix.apache.org.
Though you probably won’t need it, for background information the OSGi specification (Roo.
Mastering the Roo add-on system is key to providing a wealth of productivity enhancements for your development team.
In this chapter, we’ll take a look at how to build advanced Roo add-ons.
We’ll delve into Roo’s key infrastructure beans such as the fileManager and projectOperations components, how to accept parameters, and how to register for and react to changes in class definitions.
We’ll wrap up by showing you how to deploy your add-on to the Roo add-on repository, also known as the RooBot.
Let’s begin by learning how to create an advanced add-on.
Advanced add-ons are generated from a template that provides an extra level of cus­ tomization.
The advanced add-on template generates a few other key files:
You create the assembly by issuing the mvn assembly :assemble command.
A Roo annotation class—Used to install features such as ITDs.
This metadata can add and remove methods and properties from classes and generate ITDs.
With the advanced add-on, you can manipulate your entire project.
Let’s dive in and create an advanced add-on right now—one that will enable a feature to simplify your JavaScript programming.
Billed as a cross-compiler, CoffeeScript takes this simple language and turns it into a more complex JavaScript equivalent.
Don’t let the name fool you; building an advanced add-on isn’t as hard as it seems, especially if what you’re looking to do is configure additional Maven artifacts and plug-ins.
That’s all you have to do to install CoffeeScript, so let’s go.
For example, a data grid loading function in the Dojo JavaScript Toolkit API, which Roo uses to decorate standard HTML controls with client-side validation and rich internet features, may look something like this:
Using the CoffeeScript language, you can reduce the syntax and make it more read­ able.
There are CoffeeScript compilers and interpreters available for a wide variety of languages, including a Maven plug-in.
Getting interested? Then let’s set up an add-on that installs a Maven CoffeeScript compiler plug-in into your application.
To create your add-on, you’ll use the advanced add-on creation command.
Create a directory named coffeescript-addon, switch to it, and fire up the Roo shell.
You’ll define two add-on shell commands: coffeescript setup and coffeescript remove, which will add and remove the Maven CoffeeScript compiler to your project.
Open the project in the SpringSource Tool Suite, and replace the contents of CoffeeScriptOperations with the following four method signatures:
To create an advanced add-on, you need Coffee(Script) The CoffeescriptOperations interface is self-documenting—it provides both a setup and a tear-down command, as well as availability indicator methods for each.
Next, let’s define the Maven configuration setting changes so you can tell the add-on how to install the Maven CoffeeScript compiler.
Roo defines a configuration.xml file in org/rooinaction/addons/coffeescript that you can use to define the Maven artifacts you’ll be adding.
The format is arbitrary; you fetch what you want using an XML parser.
Replace the contents of this file with the Maven plug-in definition, as shown in the next listing.
Maven users will immediately recognize the plugin instruction, which is how Maven installs additional build features.
The Maven CoffeeScript plug-in installs a Java-based CoffeeScript compiler and will automatically compile any file ending in .coffee in the src/main/webapp/scripts directory, placing the JavaScript version of the file in the final /webapp/scripts direc­ tory as a JavaScript file.
Now you’re ready to define some of your command methods.
To set up your CoffeescriptOperationsImpl class, which will install your Maven plugin, open up the CoffeeScriptOperationsImpl class and remove the existing meth­
You’ll use this file to install the plug-ins, located in the XPath of /configuration/coffeescript/plugins/plugin.
Construct a list of the plug-ins you find D, adding each one to the list using the Roo Plugin class, which takes an XML DOM Element from the XmlUtils.findElements method.
This automatically turns the XML DOM Element into a form that the projectOperations instance can accept.
Although you’re adding only one plug-in this time, you can go back and add others by adding them to the configuration.xml file.
This makes managing the plug-in more flexible for more work in the future.
To create an advanced add-on, you need Coffee(Script) method B, which will install the new plugin node(s) in the pom.xml file.
One final step remains before you can make the add-on run—defining your commands to the Roo shell.
Open up the CoffeescriptCommands.java file, which will define and delegate the available commands for your add-on.
Replace the body of the class with the imple­ mentation defined in the following listing.
By now the CommandMarker class in the previous code should be more familiar.
You then delegate all calls for checking com­ mand availability and performing commands to the operations delegate.
For example, adding a compileIndividualFiles option to the coffeescript setup command:
This option is then sent to the operation method for use by your add-on code.
Note that you can specify a default value if the option isn’t passed, and hints for correct options such as true and false.
Although you could finish out the add-on implementation, let’s first take it for a spin.
You’ll build your add-on, install it in the Roo shell, and test it with a sample project.
To build your add-on, you drop to the command line and issue a Maven command:
Your target OSGi bundle is located in target as the JAR artifact.
If it was built success­ fully, copy the full path, including the root of the file path.
To install the add-on, use the same osgi start command you used with the simple add-on (the ellipsis [...] represents the full path to the JAR file):
YOU’RE NOT INSTALLING THE ADD-ON FOR A SINGLE PROJECT Unlike a lot of other frameworks, Roo holds the add-ons within the shell itself, rather than at the project level.
Because your add-on adds commands to the Roo shell itself, the installation needs to occur at that level.
Once you use an add-on, you benefit from the operations it performs, regardless of the project you’re working on.
If an add-on misbehaves, you’ll need to remove it from the entire Roo shell using osgi uninstall.
If the start command worked, hit [TAB] and you should see both the coffeescript setup and coffeescript remove commands in your tab completion list.
Now, create an empty project directory, such as test-coffeescript, and fire up the Roo shell.
When inside the shell, create a simple project with a web application.
To create an advanced add-on, you need Coffee(Script) project --topLevelPackage org.rooina.projects.test.coffeescript ➥ --projectName test-coffeescript.
If you search for the coffee-mavenplugin entry, you’ll find your plugin definition, complete from the configuration .xml file.
You can test the plug-in with a simple CoffeeScript script.
To test it, add a reference to the script in your home page, src/main/webapp/WEB-INF/views/index.jspx, near the end of the file, just before </util:panel/>:
To build and test your application from the operating system prompt, execute.
Next, start your Jetty web server to test the script:
This will build the rest of the project and launch the Jetty plug-in.
This proves that you’re running the compiled CoffeeScript file, hello.coffee, which was transformed into the following JavaScript code in /scripts/hello.js:
Use your browser’s View Source command to view the script.
The more advanced Mavenites among this book’s readers will quickly begin to customize the plug-in, including adding steps to attach the coffee goal to a Maven lifecycle step, such as prepare-resources.
Now, let’s wrap up this section by adding implementations of the script detection methods and the removal command.
This is the inverse of the add command, so you’ll refactor, extracting the common code, and adding or removing the plug-ins based on the operation.
You can review the refactored code in the following listing.
The projectOperations object method, removeBuildPlugins, takes this list and uses it to remove any plug-ins defined in the file.
Build the add-on using mvn package and then run the Roo shell osgi update command to replace the currently installed CoffeeScript add-on:
The command takes a bundleSymbolicName to reference the installed add-on, which is defined from the Maven artifactId of the CoffeeScript add-on’s pom.xml file.
To create an advanced add-on, you need Coffee(Script) Finally, try to issue the CoffeeScript remove method.
If it works, you’ll see that the pom.xml file no longer contains the CoffeeScript plug-in.
A better implementation would also allow for an optional parameter, such as --removeScripts or --convertAndRemoveScripts, which would remove the CoffeeScript files.
Experiment with your own add-on and see what additional features you might provide.
You need to provide commands that manipulate the visibility of your commands.
You haven’t installed the CoffeeScript Maven plug-in  Your project is defined as a web application.
You then check whether this file exists, which would confirm that the project is a WAR.
You’ll express the next operation (checking that the CoffeeScript Maven plug-in is not installed) as a positive-logic check.
The check isCoffeeScriptPluginInstalled lets you use it in both a positive and negative manner.
You need to ask the projectOperations object for all installed Maven plug-ins and iterate through them, looking for a hit B.
You also need to inject another support class, the FileManager, which you can do via another class-level member variable:
This step will only allow access to the command if the project is a WAR, and if the addon isn’t installed.
You also protect the command from appearing if the Roo shell hasn’t created a project yet.
Again, you don’t allow access to the command unless you’re working within a defined Roo project, and the project has to be set up as a WAR.
In addition, the project must contain an installed Maven CoffeeScript plug-in, so that you can then remove it.
Update your add-on, and remember the command to update it is osgi update:
Experiment with tab completion in your test project—if the add-on is already installed, you’ll see only the coffeescript remove command.
Conversely, if it’s not yet installed, you’ll see only the coffeescript setup command.
You’ll see the plug-in added and removed each time you run the relevant command.
Now we'll review some of the services and beans made available to add-on developers.
Key add-on beans and services 307 To get the most from your add-on system, you have to learn each of the OSGi services that Roo provides.
The following section details some of the major services and some snippets that you can experiment with in your own add-ons.
You can use the ProjectOperations service to manipulate your project in a number of ways.
Let's start by reviewing the ones that affect your Maven build.
Here are a few methods that let you manipulate your pom.xml file.
Maven resources (properties files, XML descriptors, and the like): addResource(String moduleName, Resource resource)
There are more commands you can issues as well, although you need to cast to a more specific type of ProjectOperations to do so.
You could also create a project on your own within your add-on, potentially using a separate configuration:
You can also execute any valid Maven command with executeMvnCommand (String)
The PathResolver is a service that properly accesses your project files for you.
It provides complete file paths for your root project and any modules associated with it.
You can use the resolver to fetch various file path roots:
This would equate to the file path on your file system for the src/main/webapp and src/main/java directories of your currently focused module.
This points to the index file at the root of your web application.
You used the FileManager to copy files in chapter 11, so it's not completely foreign to you.
You can gain access to it from your ProjectOperations instance using injection as well:
The FileManager is a transactional engine that writes files after an add-on task has been committed.
If any RuntimeException is thrown, such as one thrown by the Apache commons-lang3 project's Validate annotation, the writes for all files manipulated via this manager won’t be performed.
As in chapter 11, you can also use it indirectly.
The AbstractOperations base class contains a handy copyDirectoryContents method that you used to copy the jQuery JavaScript files in chapter 11:
You'll also notice the use of the pathResolver in this fragment.
Let's put this together with a simple file writing example.
Let's say you want to create a new JavaScript file in the project's src/main/webapp/js directory:
You'll use the pathResolver to look up the proper path for the /js/myscript.js file within the webapp directory.
Then, instead of creating a standard Java file structure and writing to it directly, you ask the fileManager to create a reference to a mutable file, which is a virtual buffer for the file you wish to write.
You then write your information to the file and use the Apache Commons IOUtils can throw an IOException during the write process, you have to catch it and rethrow as a runtime exception, here the IllegalStateException, to handle it properly.
It waits until the Roo shell command that issued the changes completes, and then tells the file manager to write all of the file create, update, and delete operations at once.
While not 100% fail-safe, it will generally stop an add-on from half-modifying a given file.
You’re only scratching the surface of the key services and beans provided by Roo.
We haven’t even discussed the ITD services and type system, and unfortunately, space doesn’t allow it here.
We could write an entire book on Roo add-ons, so stay tuned for that.
Because the framework is under heavy refactoring for version 1.2, we decided that documenting the internal Roo services wouldn’t be useful at this time.
One significant (albeit small) change is that the Roo team removed their own IOUtils class, and are now using the Apache Com­ mons IO library’s IOUtils methods instead.
The team also removed their own Assert class in 1.2.1, replacing it with the Apache Commons Lang project's Verify method.
The general add-on devel­ opment process should remain the same; however, expect to need to adjust your add-ons once deployed every time Roo is updated.
We encourage you to read the Roo source code, which is easily digestible, and review the various built-in add-ons.
When you’ve finished writing your add-on, and you’ve tested it  with your team,  it’s time to publish it.
Roo gives you several options: the manual installation via a URL, deployment to a Maven repository as part of an OBR repository, and indexing with the SpringSource RooBot as part of the public Roo add-on repository.
Table 12.1 shows the approaches and their respective pros and cons.
Distribute the binary JAR file through a web download or other means.
Developers can use the osgi install command to install it.
Host your own bundle repos­ itory and expose your add-on through that service.
Developers need to know URLs for each add-on you provide.
Contribute your add-on to the Roo add-on repository list as a publicly available add-on.
Contributes to the Roo add-on community and enriches Roo developers.
Your add-on will get lots of exposure, so be prepared  to support bug fixes, and communicate with the community.
Let’s take a look at each of these approaches in detail.
There are few require­ ments placed on you for this deployment option, so it’s the logical place to start.
You need to package your artifact and publish the JAR file in a publicly available location, such as a web server or a network share.
Because you don’t use a key signing process to authenticate these add-ons, they should only be installed this way for development purposes, or inside your own organization.
Table 12.2 summarizes the commands used to publish and consume the add-on.
Updates an existing add-on, using the name defined in the MANIFEST.MF file header Bundle-SymbolicName:
Shows the headers for all bundles, or a selected bundle.
You learned about using the OSGi commands osgi start and osgi uninstall during your jQueryUI add-on installation in chapter 11, so we can skip that technique and move on to deploying artifacts to an OBR Repository.
Remember, all Roo add-ons are OSGi bundles, so these commands will come in handy on a regular basis.
This file contains entries for all resources provided by the repository.
Let’s deploy your CoffeeScript Roo add-on to an OBR on the Google Code project hosting service.
To sign your OBR bundle, you’ll first need to set up a secure key, known as a PGP key pair.
An open source tool exists to do this: GPG, which stands for GnuPG.
When configured, you create a new public/private keypair using the gpg command:
We won't cover the process here, because it’s documented in a number of places, including the informative Roo manual reference instructions available at https:// help.ubuntu.com/community/GnuPrivacyGuardHowto.
After you’ve generated your keypair, write down your passphrase; you’ll need it every time you configure another machine.
You’ll also need to set the default passphrase when running the Maven build, and possibly your default GPG key.
To do this, you’ll create or edit a file named ~/.m2/ settings.xml.
The ‘~’ symbol refers to your home directory, which we’re referencing in Unix format.) This file provides settings for your Maven builds.
Useful when deployment has failed due to an unexpected problem, such as a missing dependency or Java package.
The profile you installed, with the id of gpg, adds a property named gpg.passphrase.
You activate it using the activeProfiles tag, which turns the profile on by default.
To list your keys, you can use the gpg --list-keys command.
The results we saw on Ken's system were as follows:
We set up the default key using the value of 9EC1BFA3 as the default-key property in that file:
The next step for you is to configure the settings that define your version control sys­ tem in the Maven pom.xml file.
Each time you release an update to your add-on, you'll need to upload a build to a source code repository.
In this example, we use Google Code, a cloud-based project hosting system, to host a Subversion repository at http://code.google.com/p/ sillyweasel-coffeescript-addon.
You can choose any cloud-based hosting provider as long as pubic viewing of files is available.
You’ll need to follow the sign-up instructions, and you can choose between SVN and GIT hosting models.
As an alternative to this process, you can create a public repository on GitHub.
Next, you have to supply the proper SVN URL settings in the Maven pom.xml file.
First, we edited the <scm> section to set the Maven connection and URL variables:
Next, we modified the distributionManagement section to tell Maven where to deliver our add-on:
Finally, we edited the Maven settings.xml file again (in ~/.m2) to add our credentials for the Google Code server:
After making these changes, you’re ready to develop and release your add-on.
During development, point your add-on developer team to the source tree and let them work with it using standard Subversion (or Git if you choose) commands.
At some point in the cycle, you’ll be ready to release your add-on.
The release of an add-on is generally performed by a designated member of the team.
This member will coordinate all check-ins, ensure that all unit and integration tests run properly, perform tests by installing and using the add-on, and ensure that none of the artifacts used by the Maven POM of the add-on are using unreleased (snapshot) versions of the libraries referenced.
DON'T USE SNAPSHOT VERSIONS OF DEPENDENCIES Because Maven releases are meant to be 100% reproducible, all dependencies to your project need to be released versions.
For example, if the dependent library version is 1.0.2-SNAP­ SHOT, it’s considered unstable, and under development.
If you’re testing your add-on and want to run through the release process without having to check for snapshots, you can temporarily issue your mvn release:prepare command using the flag -Dignore­
Deployment in Maven uses the somewhat complex but useful maven-release-plugin.
You should read the Maven documentation on the plug-in for the most up-to-date details, but the general process involves two steps:
The release prepare process asks for three pieces of information: the name of the release version, the SCM tag for the release, and the new development version of the project (including the version of the release to deploy, the label to use for the release in the version control tag, and the next development version):
After answering these questions, Maven will build the code, tag the release with the release tag, and commit the tag to the version control system.
This marks the time of the release so that you can then perform the release itself:
Maven checks out the code tagged by the release:prepare step, which was tagged at the time the development coordinator felt the team was ready to release the code:
Maven then executes the deploy goal, which does a full build, deploying the final target artifact to your defined target repository, which is defined in this case as dav: https:/ /sillyweasel-roo-addons.googlecode.com/svn/repo.
It also writes a pom.xml file in the release directory:
The repository has both signatures as well as copies of the artifacts, as shown in figure 12.1
Because add-on projects include the maven-bundle-plugin, Maven sets up the OBR entry and adds your new release properly to the right location as part of the release pro­ cess.
In our project, that file is located at https://sillyweasel-coffeescript­ addon.googlecode.com under the directory /svn/repo/repository.xml.
Now you’ve got an official release, deployed on a Maven repository, which is OBRenabled.
To use this repository, you can use the osgi obr commands to attach to the OBR and install an add-on from it.
You will install the add-on for the Roo shell, not for a specific project.
Here’s an example, using our sillyweasel-coffeescript-addon (please type on one line):
And to start the add-on, we have the bonus feature of [TAB] completion:
The fun part is having to trust your own Roo encryption key before you install the add-on.
Now is a good time to refer back to the trust section in chapter 11 and install your key.
The key OSGi OBR commands are shown in table 12.3
Now that you’ve seen how to build, sign, upload, and release your OBR-based.
Roo add-on, it’s time to consider ‘going public’ and publishing it to the Roo central repository.
Without specifying the version of the bundle, it displays all ver­ sions found.
Appending a version, such as ;0.1.1, displays information about an individual version.
Shows all add-ons, optionally matching the text in the keywords option.
The URL must point  to the location of a repository.xml file stored in your repository, and that file must be visible to the developers accessing the repository.
Use this when checking for updated versions of your add-on.
It’s easy to upload an artifact to the Roo add-on repository, as of the time of this publi­ cation.
In the future this may change, but provided your artifact exists in a proper OBR, you only need to send an email to s2-roobot@vmware.com, with the full URL to the OBR’s repository.xml file.
Using a GMail client, the email you send would look something like figure 12.2
After you send this email, the RooBot will wake up and process the request.
This URL may change in the future if the add-on submission procedure is adjusted.
Summary 319 ----------------------------------------------------------------------gist of this process, however, is to submit your repository URL so that your add-ons get incorporated into the Roo add-on central repository.
The following code is an example of what you can get from the RooBot when sub­ mitting an erroneous add-on request.
In this example, we used the httppgp:// URL syntax in our email request, which is incorrect procedure.
The source control reposi­ tory needs to support PGP signed keys and URLs, but the repository itself must be a clear http: or https: URL:
If you get no messages in this URL, don't worry.
Try restarting the Roo shell, and use the add-on search command:
Now you can install it, provided you’ve removed the prior version with osgi uninstall.
This process may change as Roo finds wider adoption, and if an approval process is put in place.
The basic concept of exposing a Roo repository and down­ loading it is a nifty way to use an OSGi framework extension.
This exposes a large number of developers to software automatically.
This is a use case for OSGi we can certainly get behind.
As you’ve seen in this chapter, Roo has a powerful add-on API, capable of completely transforming the stock Roo platform into any type of development environment you can imagine.
Add-ons are a complex topic, worthy of their own book.
We suggest that add-on developers learn the basics of OSGi bundle development, get cozy with the stock Felix shell, understand as much as they can about the OBR and SCR technologies, and above all, read other add-on code, particularly the built-in Roo add-ons from the Roo source tree.
As the add-on framework continues to evolve and becomes more useful.
The following books and articles may be useful to you as you continue your journey.
Details on the Apache Felix Maven bundler plug-in, which is used to assemble Roo add-ons in to OSGi bundles: http://felix.apache.org/site/apache-felix-maven-bundle-plugin­ bnd.html.
In this final part of the book, we show you how to deploy Roo applications in the cloud where your application will run on a third-party hosting provider.
Cloud computing solutions offer flexibility in deploying applications without requiring any internal server infrastructure.
We look at one particular cloud service offering from VMware called Cloud Foundry.
You’ll learn about the Roo add-on for Cloud Foundry and how to install the add-on.
Then you’ll use the add-on commands to deploy your Roo application to a Cloud Foundry instance.
We also look at the ways to view appli­ cation logs and memory settings to monitor an application running in the cloud.
Spring Integration is a framework for implementing event-based messaging applications.
You’ll see how the new Spring Integration add-on helps with creating and managing vari­ ous enterprise integration components you can use to simplify the design of the course registration use case.
In this chapter, you’ll learn how to package and deploy the sample Roo application to an external hosting service using a new web application deployment paradigm called cloud computing (CC)
We’ll discuss this new paradigm and the cloud service offering from VMware1 called Cloud Foundry.
Roo includes an add-on component for Cloud Foundry to help developers with the tasks of deploying Roo applications to the cloud.
We’ll show you how to configure and deploy your Roo applications using the Cloud Foundry add-on.
Why are organizations turning to cloud computing? Scalability (for scaling up as well as down on demand) is one reason.
Another is that using cloud computing means no equipment, maintenance, or operational costs.
The parent company of the SpringSource team who created the Spring Roo framework.
In the previous two chapters, you learned how to write and install custom Roo addon components, both simple and advanced add-on types.
Let’s look at the different service and deployment models offered by cloud computing; but first we’ll define CC.
Organizations are attracted to the option of hosting their applications on the cloud because it offers them a low-cost and highly scalable implementation.
There are three types of service models in cloud computing.
The infrastructure as a service (IaaS) model helps organizations to outsource the.
In a platform as a service or PaaS model, web applications are developed in-house and  deployed to an external hosting site to  be  hosted on the  cloud.
In the third cloud architecture model, called software as a service, or SaaS, applica­ tions are developed, hosted, and maintained as third-party programs by an external vendor.
In this chapter, you’ll learn how to deploy the Roo sample Course Manager appli­ cation you’ve developed to the Cloud Foundry server environment.
Here again, Roo provides excellent support to perform the steps necessary to run the Roo application in the externally hosted server environment.
The National Institute of Standards and Technology (NIST) defines2 cloud computing as follows:
Cloud computing as a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (for example, networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.
This cloud model promotes availability and is composed of five essential characteristics, three service models, and four deployment models.
For more information on these characteristics refer to NIST Special Publication 800-145 that defines cloud computing and describes the different cloud computing models.
What is cloud computing? NIST defines the platform as a service model as follows:
The capability provided to the consumer is to deploy onto the cloud infrastructure.
Several PaaS cloud providers can deploy Java-based web applications to the cloud infrastructure, including Heroku, CloudBees, and Cloud Foundry.
Heroku started as a cloud provider for Ruby on Rails–based web applications, but now it also supports Java applications.
Its architecture is based on isolated processes called Dynos, which receive web requests from a routing (load balancer) component, connect to application resources via environment variables, and write output to a logging com­ ponent called LogPlex.
There are two types of Dynos: A web dyno is a web process running the application code and responding to HTTP requests.
More web dynos provide more concurrency to access the web application.
The second type is a worker dyno, which is a background process that runs the application code and processes jobs from a queue.
Heroku’s architecture model also includes a routing component, fine-grained con­ trol of DNS, custom domains, and SSL features.
Heroku has logging and visibility capability to monitor the application’s operations with real-time logging and auditing, process status inspection, and an audit trail.
To deploy and manage the Java applica­ tions and their operations, Heroku provides the following interfaces:
Heroku supports databases like PostgreSQL, and the add-on features include support for NoSQL databases like Redis, MongoDB, and Neo4J; scheduling support; caching frameworks like memcached; and messaging products like RabbitMQ.
The CloudBees PaaS lets developers build, test, and deploy Java web applications in the cloud.
CloudBees allows development teams to move their development and pro­ duction activities to the cloud without infrastructure costs or overhead.
It provides integration with the Jenkins continuous integration (CI) tool for application builds, and it also offers a private cloud option if organizations prefer to install a cloud infra­ structure within their network.
Cloud Foundry, the third cloud provider we mentioned earlier in this section, will get more attention later in this chapter.
For information on other available PaaS cloud providers, review the list of websites in the Resources section at the end of this chapter.
First, we’ll look at how the Cloud Foundry product is different from other cloud solutions and what it offers to application developers and operations teams.
Cloud Foundry is an open source PaaS cloud solution from SpringSource, the same organization behind the Spring Roo framework.
It allows the deployment of applica­ tions written using Spring, Rails, and other modern frameworks.
Cloud Foundry sup­ ports different programming models and services from VMware and third parties.
The Cloud Foundry application platform includes an application execution engine, an automation engine for application deployment and lifecycle management, and a scriptable command-line interface.
It provides integration with development tools like Spring Tool Suite (STS) to help with development and deployment processes.
It shows all of the program­ ming models, application services, and deployment options that Cloud Foundry brings to the table.
As you can see from the architecture model diagram, the Cloud Foundry platform offers diverse services in the areas of cloud deployment models, programming lan­ guages, and enterprise application services.
In the deployment area, Cloud Foundry currently has three offerings:
It provides a multitenant PaaS that runs on the vSphere cloud platform.
It runs in a  virtual  machine on a developer’s Mac or PC.
Developers can use Micro Cloud Foundry to run a cloud on their own computers for development and testing purposes.
You can build cloud applications locally and deploy them to Cloud Foundry without changing the code.
Cloud Foundry supports the following program models for developing cloud-based applications:
As you can see, Cloud Foundry supports a diverse set of programming languages and runtime environments.
It also supports the following databases for data storage and persistence requirements:
MongoDB is one of the NoSQL databases (also known as nonrelational databases or NRDBMS), and it’s gaining in popularity for storing document-based, unstructured data.
PostgreSQL database support was added in Spring Roo 1.2 to provide another choice (in addition to MySQL) of open source relational database services offered by Cloud Foundry.
Messaging services such as RabbitMQ are also offered as part of the Cloud Foundry service infrastructure.
Messaging patterns play a significant role in developing loosely coupled application architectures, which is a big part of cloud computing models.
You can expect to see more integration and innovation in this area in future versions of cloud computing architectures.
The deployment process of moving a web application to Cloud server instances involves several steps.
Performing these steps manually takes a great deal of time and effort because there are many environment variables that need to be set up correctly for the application to function as expected on remote servers.
It would be nice to take these steps in a more automated manner using simple commands.
Here is where the Cloud Foundry Roo add-on comes to the rescue.
The add-on makes it easy to deploy Java applications from the Roo console.
In the next section, you’ll learn how to install and use the Cloud Foundry Roo addon component.
You’ll also deploy and manage the cloud services from the Roo com­ mand shell using the add-on.
Using the Roo add-on commands, you can perform various Cloud Foundry tasks, such as logging in to Cloud Foundry, viewing the already deployed applications, binding to services, and deploying new applications.
There are several Cloud Foundry com­ mands added to the Spring Roo shell to make it easy to view, deploy, and monitor your cloud applications.
Let’s look at how to install the Cloud Foundry add-on so you can start issuing the commands provided by the add-on component.
Before you start developing Roo applications to deploy to the cloud, you need to cre­ ate an account on Cloud Foundry.
You can do this by signing up for a Cloud­ Foundry.com account at http://www.cloudfoundry.com/
Using the new credentials you receive from the Cloud Foundry team, you can log in to the website to deploy applications to the cloud.
You can also download the virtual image of Micro Cloud Foundry to test the applications locally on your PC or Mac.
To get started, you need to run the pgp automatic trust command to enable auto­ matic PGP key trusting, and ensure that the signed bundles needed by the Cloud Foundry add-on can be installed on your system.
Because you don’t want to leave the system with this setting, as soon as the add-on files are installed, you should disable the automatic PGP trusting by running the same command again:
Then you run the addon install command to instruct Roo to download and install the Cloud Foundry support.
This command takes a few minutes to download all of the required JAR files.
Hint] Please consider rating this add-on with the following command:
Now, type the pgp automatic trust command again to disable key trusting.
Here’s the output of this command showing the PGP key trusting is now disabled:
Automatic PGP key trusting disabled (this is the safest option)
Type in the command cloud foundry and press TAB twice.
You’ll see displayed the available Cloud Foundry com­ mands, as shown in the following snippet:
Now that you’ve installed Cloud Foundry support, you can begin to issue any of the 30-plus Cloud Foundry Roo add-on commands to perform various tasks in the cloud application development lifecycle.
In the next section, you’ll find more details about some of these commands and learn how to use them to deploy and run your applica­ tion in the Cloud Foundry server environment.
As you can see in the following example, the Cloud Foundry add-on offers various commands to manage the applications on the cloud server instances.
These com­ mands are used for different tasks to deploy and monitor cloud applications:
You’ll use the key commands required to deploy your sample application.
You’ll use commands to log in to Cloud Foundry website, deploy the new application, and verify that the application has been deployed correctly.
You’ll also test the application from the Cloud Foundry site using the application URL you specify during the deployment step.
The following section provides a step-by-step approach to all of the add-on com­ mands you’ll use in the application deployment process.
Cloud Foundry also offers a command-line interface (CLI) called vmc, which allows you to interact with the Cloud Foundry instance from the command shell.
With the vmc tool you can deploy Java-, Ruby-, and Node.js-based web applications to the Cloud Foundry servers.
You can also configure the deployed applications to use the built-in services provided by the Cloud Foundry platform.
The interface is written in Ruby, so you’ll need Ruby and Ruby Gem installed before you can use the CLI commands.
The following list contains the vmc commands you can use to deploy and manage the applications in Cloud Foundry:
Deploying the Course Manager application to the cloud vmc frameworks.
For more information on the vmc tool, check the support page (http://mng.bz/ SfWG) on the Cloud Foundry community website.
You now have the add-on installed and ready for use.
Let’s see how to deploy the sample application using the new Cloud Foundry add-on commands.
To deploy the Roo application to the cloud, first log in to the Cloud Foundry site, which you can do by running the following command on the Roo command shell:
This command takes in three arguments: email, password, and cloudControllerUrl.
When logging in to Cloud Foundry for the first time, the email and password argu­ ments are mandatory parameters.
Roo will store the login credentials locally for sub­ sequent logins so you aren’t required to enter the email and password every time you log in.
It defaults to the cloud ser­ vice provided by VMware (http://api.cloudfoundry.com)
You can change it to point to other private Cloud Foundry server instances.
If you want to clear the login credentials stored in memory, you can run the command cloud foundry clear login details, which will remove the email and password val­ ues from the cache and will prompt for user account credentials the next time you try to log in.
Now you can type commands like cloud foundry info to get the usage details of your user account at VMware’s cloud application platform.
For example, type the command cloud foundry list apps and you should see the following output on the console:
Alternatively, you can type the command cloud foundry list services to see the following output on the console.
The services command shows the name, description, and version of each system service available in the current release of Cloud Foundry:
The command you use to deploy applications to the Cloud Foundry instances is cloud foundry deploy.
The CREATE option in the previous example will trigger the Maven build commands to clean, compile, and package the application.
The deploy command will also move the WAR file to the Cloud Foundry instance.
If all of these steps complete successfully, you should see the following message at the end of the Maven build process:
Now, to verify that the coursemanager Roo application has been successfully deployed, let’s run the cloud foundry list apps command again to view all of the applications currently deployed.
Here’s the output of this command, which shows that the new application, coursemanager‚ has been deployed with a web URL of coursemanager.cloudfoundry.com and with a status of STOPPED:
Let’s start the application by issuing the command cloud foundry start app --appName coursemanager.
If you run the cloud foundry list apps command one more time, you’ll see that coursemanager has been started and is ready to receive web requests.
You can access Course Manager application running on the cloud by using the specified URL (http://coursemanager.cloudfoundry.com) as shown in figure 13.2
After you’ve deployed the application, you’ll need to check runtime statistics like the JVM-related information, add new services like a database, and bind them to your web application.
The following section covers these topics and shows how to perform them using the add-on commands.
Let’s take a look at the add-on command to get statistics, such as number of cores, memory, disk space, and uptime of the application.
The next step is to bind services provided by Cloud Foundry to your application.
As you saw earlier with the command cloud foundry list services, these services include databases (both relational and NoSQL databases) and messaging services.
To provision a new service, you use the following command by specifying the name and the type of the service.
Let’s create a new service to store and retrieve MongoDB from the NoSQL database, which is used to store document-based, unstructured data.
In this example, these values are mymongodb and mongodb, respectively:
Now you need to look at the list of available and provisioned services by running the list services command you ran before (cloud foundry list services)
Here’s the new output of this command showing the new MongoDB service you created:
To bind your application coursemanager to this new service, use the following command:
After the application is bound to a service, you can start using the service in the appli­ cation functionality.
Application monitoring in the cloud 335 Let’s restart the application after binding the service using the following command:
If you need to delete an existing service, you can use the following command specify­ ing the service name:
Let’s do a quick check on what you’ve accomplished so far.
Your application is up and running now, so the next step is to monitor the application running in the cloud.
The Cloud Foundry add-on provides some monitoring commands to keep an eye on how the application is performing, if it’s up and running, and other aspects.
The application log information can be obtained by running the command cloud foundry view logs --appName coursemanager --instance 0
If you want to see if your application had any crashes, you can run the command cloud foundry view crashes.
You can use the command cloud foundry view crash logs to view the log informa­ tion about when application crashes happened.
This gives operations and developer teams the ability to check the availability and uptime of their applications in the cloud and troubleshoot any outages (crashes) that may occur during the application usage.
You can view the current memory setting of a cloud application, and update memory if you need to, from the cloud foundry view app memory --appName coursemanager command.
This command allows you to see the memory used by the application (256MB)
To change the allocated memory you can run cloud foundry update app memory --appName coursemanager with the new memory setting.
As you can see, the Cloud Foundry add-on commands are extensive and useful in deploying and monitoring cloud applications.
Cloud Foundry is a relatively new technology and is growing in terms of new features with every product release.
There’ll be some additional Her­ oku tooling needed for Spring Roo applications.
The Heroku team is also working on aligning the cloud computing framework with continuous delivery.
They are working on creating a deployment platform that supports continuous delivery, while allowing developers to use a framework of their choice among the supported frameworks, with few changes to developer experience and workflow.
In this chapter, you learned about Cloud Foundry, the cloud computing product from VMware, and how to install the Cloud Foundry add-on in Roo.
You used the add-on commands to deploy to a Cloud Foundry instance.
You found out how to view the application logs, memory settings, and information on system crashes.
You also used the other add-on commands to perform tasks such as starting and stopping applications and binding services.
Cloud Foundry is based on the open source PaaS cloud computing model and has great potential to innovate in the cloud computing space.
It allows developers to increase their productivity without getting bogged down with infrastructure setup and maintenance overhead.
Cloud Foundry’s integration with Roo gives you the ability to develop applications on your local development environment (which should be easier when you use Micro Cloud Foundry), and the means to deploy and manage applica­ tions, all from within the Roo command shell.
The next chapter builds on discussions from previous chapters and focuses on the integration Roo provides when working with Spring Integration.
This framework is used for Enterprise Service Bus (ESB) and workflow-based use cases.
In the previous chapter, you learned how to deploy Java applications to the cloud.
Using the Roo framework made it easier and faster to package and migrate your application from a local environment to the cloud server instance.
In this chapter, we discuss the support for the Spring Integration framework that Roo provides for workflow-based applications.
The Spring Integration frame­ work is a SpringSource project that’s been grabbing the spotlight recently.
The framework implements the popular enterprise integration patterns, a set of common components in applications involving some type of workflow, where multiple steps in the business process are executed either sequentially or in parallel.
Because Spring Integration is an add-on like the JMS and email add-ons, this chap­ ter is similar from a content flow standpoint to previous chapters where we covered those two add-ons, and our discussion focuses mainly on Roo commands and how each command works.
By the end of this chapter, you’ll know how to use enterprise integration patterns to implement the advanced types of use cases in enterprise Java applications.
You’ll also be comfortable using the Spring Integration framework as well as its add-on for Roo, which will let you implement Spring Integration components using Roo com­ mands in less time than it would take if you were to manually configure the Spring Integration workflow components.
Let’s get started with a discussion of workflow applications and the enterprise inte­ gration patterns (EIPs)
Workflow-based applications include business processes that consist of multiple steps, with each step requiring a different type of trigger mechanism (time-based versus event-based), a different interaction model (synchronous versus asynchronous), or a different type of order for execution (sequential versus parallel)
This type of architec­ ture provides a great deal of flexibility and extensibility to application design and offers several advantages over traditional asynchronous messaging.
Enterprise integration patterns help in this space by providing a set of messaging architecture and design patterns to successfully implement your workflow requirements.
Enterprise application integration (see http://mng.bz/u7is) helps software architects and developers design and implement integration requirements in their applications.
These patterns are based on asynchronous messaging architectures that make the application design more modular and loosely coupled from other components within the application.
These EAI patterns are driven by design principles such as loose coupling, eventdriven architectures, and synchronous and asynchronous interaction models.
Two types of dependencies (or couplings) are involved—a component-level dependency and a system-level dependency.
A component- or type-level dependency deals with associating between various components in the application.
For example, a controller class may depend on a service class, which may in turn depend on a data access object (DAO) class.
These component-level dependencies can be reduced using the dependency injection (DI) principle.
Using the Spring Integration framework 339 Conversely, a system-level dependency refers to the coupling between two systems, whether they’re two internal systems within the same organization, or systems that are hosted in an external organization.
By limiting one system level of coupling to another you can evolve and implement any changes in one system without adversely impacting the other system.
Minimizing the system-level coupling also ensures that one system can function when the other system it relies on isn’t available.
The commu­ nication and interaction between these systems can happen based on business events that trigger the subsequent processing in the main system.
Event-driven architecture (EDA) is another important component of enterprise application integration.
The architectural pattern known as event-driven architecture explains how complex applications are broken down into a set of components or services that interact via events.
One of the primary advantages of this is a loosely coupled application architec­ ture, which helps to simplify the implementation of the component by eliminating concern about how to communicate with other components.
SEDA-based architectures are more scalable than are standard multithreaded applications.
They’re also tunable at runtime, allowing optimization for the current load being experienced.
Event-driven, message-based architecture centers on two main components: events and messages.
The message-based interaction operates through a structure of chan­ nels and endpoints, through which the messages are sent to carry out the functionality of the application.
With this big-picture view of event-driven, message-based architecture understood, you’re ready to see how the Spring Integration framework implements this architec­ ture style.
Spring Integration is a framework for implementing event-based messaging applica­ tions.
It provides a simple model for building enterprise integration solutions while maintaining the separation of concerns between business logic and integration logic.
Spring Integration is an extension of the Spring programming model to support enterprise integration patterns, taking advantage of the inversion of control (depen­ dency injection) capability provided in the Spring core framework.
Its architecture is based on lightweight messaging and integration with external systems using declara­ tive adapters that provide a higher-level abstraction for functionality like remoting and messaging.
For more information on this topic, refer to Spring Integration in Action  (http:// www.manning.com/fisher/) from Manning.
Integration project lead Mark Fisher and offers a wealth of resources.
Another framework that works nicely with Spring Integration is Spring Batch, which can be used to design and implement batch (offline) applications.
Spring Batch enables the development of batch-based use cases that are common in the operations of enterprise systems.
A POJO-based framework, it provides reusable functions that are essential in processing large volumes of records, such as transaction management, job processing statistics, job restart, and resource management.
The Spring Batch and Spring Integration frameworks complement each other well and produce sophisticated event-driven, high-volume, high-performance batch appli­ cations.
One scenario where using a Spring Integration and Spring Batch combina­ tion adds value to the solution architecture is when a batch job needs to be launched based on a business event.
An example of this is when a data file is uploaded to an FTP server from an internal application or an external system.
It’s also a good solution if any of the steps in the workflow need to be run as a batch with job restart or skip capa­ bilities, which are available out of the box in Spring Batch.
Currently, Roo has no add-on available for Spring Batch, making it a good add-on candidate because there are several commands in the batch framework and it would be easier to set up the jobs and other batch components using Roo commands.
If you’re interested in learning more about Spring Batch framework's features and API, refer to these additional resources: Spring Batch in Action (http://manning.com/ templier/), and the Spring Batch project website (http://mng.bz/F66T)
In this section, we’ll discuss the design details of the course registration use case with EIP patterns and Spring Integration in the mix.
You implemented the course registration use case in chapter 10
In that solution design, the messaging infrastructure you set up didn’t allow the flexibility to add other steps in the process flow.
If you need the flexibility to add (or modify or remove) any components without having to write a lot of code to change the order of tasks, you can take advantage of the Spring Integration framework.
This alternative implementation of the course registration use case is the main focus of this chapter.
Let’s revisit the course registration use case, which includes multiple steps to process the course registration request before the last step of sending a confirmation email notification.
This is a good use case for a workflow-based solution.
The beauty of this solution is that you can implement a successful registration and a wait-list scenario within the same workflow.
This is one of the advantages to using a workflow approach.
It allows you to design a solution with different branches (forks) and subprocesses in the process flow.
You’ll re-architect the solution you created for the wait-list notification use case covered earlier in this book.
This time you’ll take advantage of the workflow capabili­ ties the Spring Integration framework provides.
The course registration process, using the Spring Integration solution, includes the following steps:
When a student submits the course registration request, you post a message with the course registration details in a message queue.
A channel adapter component receives the message and performs a data trans­ formation to filter out the data in the message that’s not required for your course registration process.
Because the request data can come from different systems including external business partners, you need the transformation step to ensure that the input data to the next step is Course Manager domain friendly and doesn’t contain any unknown or invalid data.
The next step in the process is to check course availability.
If the course is avail­ able, the program will route the course registration request to the branch to continue processing the request.
This processing can be done offline without consuming any resources in the main business process.
If the course isn’t avail­ able, the request will be routed to another branch in the program flow where the wait-list processing occurs.
The Course Manager program performs all of the required updates and processing.
The final step is to notify the student with either the course registration confir­ mation or that the registration request has been placed on the wait list.
You’ll use some of the integration patterns in the implementation of the course registration use case.
Let’s take a look at these patterns in more detail.
Here’s the list of design patterns used in the solution and what they’re responsible for:
Inbound Channel Adapter—This component in the workflow receives the course registration details from a message queue.
Content-Based Router—This component routes the registration request to the course registration confirmation or the wait-list step in the process, based on course availability.
Outbound Channel Adapter—This component sends an email notification to the customer after processing the course registration request.
The EAI patterns site uses special modeling (UML) notations for each of these pat­ terns.
Figure 14.2 shows the integration patterns using the UML notations.
By now, you must be itching to start testing, so let’s get to it.
In the next section, we’ll dive into the installation, configuration, and use of the new Roo add-on compo­ nent in the sample application.
Fortunately, an add-on component exists to create and manage Spring Integration components using Roo commands without having to write the code from scratch.
The Spring Integration add-on for Roo provides quick and simple configuration of Spring Integration flows.
The discussion includes the new Spring Integration add-on (http://mng.bz/ VX0h), which is not yet in general release.
We’ll look at how to install the add-on and then how to run Roo commands for setting up Spring Integration components like SERVICE_ACTIVATOR, ROUTER, and so on.
The design philosophy of the Spring Integra­ tion add-on aligns with the enterprise application integration patterns and their implementation in enterprise applications.
This Eclipse-based IDE tool makes the job of adding different components easier, without having to configure them manually from scratch.
This project is also in the early stages of development.
The Spring Integration add-on’s current status is that of a work in progress, and at the time of this writing, it’s not in GA release.
The current version’s support is not comprehensive in that the add-on doesn’t persist the Spring configuration files after issuing the Roo commands.
But it does have good support for setting up the various Spring Integration components in the workflow.
We'll start this discussion by running different add-on commands to show you how to set up the Spring Integration workflow and associate the components to one another.
Then you’ll create the required Spring configuration files to test the work­ flow setup.
You’ll also write the Java classes needed to capture the business logic of the use case.
Finally, you’ll write a JUnit test in order to test the different course reg­ istration scenarios.
The add-on also provides a focus command, similar to the Roo focus command, but it works on integration patterns rather than on Java classes.
You’ll perform the following steps to install the Spring Integration add-on:
After completing the installation process, you’re ready to use the Spring Inte­
Let’s look at each of these steps in more detail.
Let’s first check out the add-on source code from its Git repository location to a local directory on your machine.
You can use a Git client tool like SmartGit (http:// mng.bz/n5pg) to work with the Git repository, using a graphical user interface tool.
Figure 14.3 shows the SmartGit client tool window, with the SpringIntegrationRooAddon Git project folders (in the left pane) and files (in the right pane)
Now you need to clone the project using the add-on component’s Git repository URL.2
The spring-integration-roo-parent module includes the common dependency JAR files for the other modules in the project.
And the spring-integration-roo-core module contains all the Roo commands for setting up a new project, creating various Spring Integration pipeline components, and configuring each component in the workflow.
To compile and package the add-on JAR files, run Maven clean and install com­ mands, as shown in this example:
This will create two JAR files for the core and adapter modules, which you can deploy to the Roo environment, as discussed in the next section.
The Spring Integration add-on depends on the following four libraries:
If you try to deploy the Roo add-on without having these libraries installed first, the framework will throw the error shown in the following listing.
Listing 14.1 Error when deploying without the dependent Java libraries.
You can copy the required JAR files to the target folder in the PROJECT_HOME directory, or you can install these libraries using the OSGi commands.
To do this, first you create a new directory under target called RooAddOnLibraries and copy the zip file contents into this new folder.
Install these JAR files to the bundle folder under Roo’s installation directory using the osgi start command for each JAR file, as shown in this example:
If you need to uninstall a library, you can use the following command:
The OSGi version of the Com­ mons Logging JAR file can be downloaded from the SpringSource Enterprise Bundle Repository (http://mng.bz/PpyY), which hosts OSGi-ready versions of hundreds of open source enterprise libraries commonly used to develop Spring applications.
After installing the required libraries, type the following command to view all of the installed libraries and their current status (for example, whether they’re active or not):
The output of this command is shown in the next listing.
Listing 14.2 osgi ps command output showing all active OSGi bundles.
Another way to verify that the Spring Integration add-on components are installed correctly is to use the osgi log command.
Listing 14.3 osgi log output showing current status of OSGi bundles.
So far, you’ve downloaded, compiled, packaged, and deployed the Spring Integration add-on component source code along with the libraries on which the add-on depends.
Now you can start using the add-on to implement the course registration use case.
Before you do that, you need to quickly verify that you successfully installed the add-on and that there were no errors during deployment.
To verify success of the add-on installation, run the help command in the Roo com­ mand shell window.
The fol­ lowing listing is the partial output of this command that shows Roo’s Spring Integration commands.
Listing 14.4 Spring Integration Roo commands to verify the add-on installation.
If you want context-sensitive help, you can type integration and press TAB:
Note that the exact syntax of these commands may change in more recent releases of the Spring Integration add-on, because the version of the add-on component is not in GA release at the time of this writing.
Now you’re ready to use the new add-on for your use case implementation.
In the next section, we’ll discuss the implementation of the course registration confirmation use case step by step using Roo commands to define and configure the Spring Integra­ tion components you need in the use case.
Before you can start creating the workflow components required for implementing the use case, you first need to set up the Spring Integration flow.
Let’s create a new project to see how the add-on sets up a Spring Integration project.
Change your directory to a new folder called coursemanager-spring-int and run the following command to set up the project:
This creates a new project called coursemanager-spring-int that’s similar to how Roo creates a new Java project when you run the project command.
You can now type integration flow and press TAB twice to see what command options are available.
It will show the following output on the command shell window:
Because you didn’t create an existing Spring Integration flow yet, you need to use the start option with the integration flow command:
If you want to edit an existing Spring Integration workflow, use the command integration flow edit, specifying the name of the flow, as this example shows:
The output will say that the flow is ready for edits:
To see all of the available Spring Integration commands at this time, you can press TAB twice and it will display the following list of commands:
As you can see in the previous output example, there are several commands to create.
Note that the available commands are context sensitive, meaning that you see only.
Another interesting feature to note is that the new add-on has support for main­ taining the state of the project between Roo restarts.
Now that the base Spring Integration flow is set up, you’re ready to start adding the integration components you need to implement the course registration use case requirements.
Let’s look at how to implement each of these components using Roo commands.
First, start with the input channel adapter, which is based on a JMS queue.
Post the course reg­ istration details to the message queue and the channel adapter helps with receiving the message from the queue for further processing in the subsequent steps of the workflow.
The input channel adapter in this case is acting as a producer, so you need to run the produce command to set up the adapter component.
Type produce and press TAB twice to see the available options for the produce command.
If you do this a couple of times, you’ll see the command for setting up the channel adapter.
As you can see from the output in the following listing, a number of different adapter options are available, from ftp, jdbc, and jms to some new adapters that were added in recent releases of Roo, such as twitter and xmpp.
Listing 14.5 Variations of produce command for creating channel adapter component.
Here’s the full command to configure the JMS channel adapter:
You can now use the previously mentioned focus command to switch to a specific component in the workflow.
Let’s run the focus command with the --name parameter to see the list of different components available.
You can now use the focus command with the component ID to switch the focus to the inbound channel adapter.
After running the focus command, if you press TAB twice, it will display the list of available commands:
One of the commands listed is transform, which can be used to define a transformer component in the workflow.
Let’s run the transform command, which creates a data transformer and sets the focus to this new component.
Here’s output of the command after a transformer component has been added to the workflow:
Another command that’s available is the diagram command, which you can use for viewing Spring Integration workflow details, such as what Spring Integration components are defined and assembled so far in your use case.
The output of the diagram command showing the FLOW details with the channel adapter, message channel, and transformer components is shown here:
You only have two components defined so far in the process, so the diagram doesn’t have a lot of components.
You’ll run this command again later in this section after creating all of the components to show how the FLOW diagram will look after all of the workflow components are in place.
The next workflow component you need to define is a router that can be used to send the incoming messages to different steps in the process based on the predefined.
After you create the router component, you can run another command, validate, to perform a vali­ dation of the Spring Integration flow you’ve created so far.
The last component you’ll create for your use case is the output channel adapter.
It’ll send the email notifications to customers after performing all of the steps in the course registration workflow.
Similar to the produce command you used earlier in this section to create an inbound adapter, now you’ll run the send command to define the outbound channel adapter.
You’ll also specify that you need an email-based adapter by including the mail param­ eter in the send command.
Here’s the command for defining the output channel adapter component:
When the final workflow component has been defined, you can run the diagram com­ mand one more time to see the final version of the Spring Integration flow details.
Also, when you’re finished creating and configuring all of the Spring Integration com­ ponents you need for your use case, you can run the stop command to exit the course-mgmt-int workflow.
Let’s add the Spring configuration file and Maven dependencies to test the Spring Integration components.
The following listing shows the contents of the applicationContext-integration.xml file.
Listing 14.6 Configuration details for JMS components in course registration use case.
This configuration file defines the JMS queue-related Spring beans using the ActiveMQ server as the messaging container.
There are some additional Maven build dependencies for the Spring Integration classes.
To test the course registration use case with Spring Integration, you’ll write a test cli­ ent class called CourseRegistrationSpringIntegrationTestClient.
Because most of the workflow details are captured in the configuration file, all you need to do in the test client is to post a course registration request message to the JMS queue‚ courseRegistrationRequestQueue.
To make it easier to test, use the stream support pro­ vided by the Spring Integration framework.
Instead of writing the code to create and post a message to the JMS queue, use a stdout-channel-adapter component, which allows you to type in the course registration test message at the console to trigger the course registration workflow.
Listing 14.9 Test client for testing course registration with Spring Integration.
In this chapter, you learned how to implement a workflow solution using the Spring Integration framework and the Roo add-on.
Using the Roo add-on makes the imple­ mentation process easier, without having to write a lot of code.
Following Roo’s philos­ ophy, the Spring Integration add-on allows you to easily create and manage integration components.
As you’ve seen, the Spring Roo framework has a good ecosystem in areas of appli­ cation development, with common use cases such as data access (CRUD) and user interface development, as well as advanced use cases such as asynchronous messaging, Spring Integration, and support for emerging technologies like cloud computing.
It improves productivity by enforcing correct coding practices and patterns and integrates with.
And, when you finish coding, it gets out of the way so there’s no runtime impact.
Spring Roo in Action teaches you to code Java more effi  ciently using Roo.
With the help of many examples, it shows you how to build application components from the database layer to the user interface.
The book takes a test-first approach and points out how Roo can help automate many of the mundane details of coding Java apps.
Along the way, you’ll address important topics like security, messaging, and cloud computing.
This book is for Java developers who want to get more produc­ tive by using Roo.
Ken Rimple is a veteran Java developer, trainer, mentor, and head of Chariot’s Education Services team, a VMWare training partner.
Srini Penchikala is a security architect with over 16 years of experience in software design and development.
For access to the book’s forum and a free eBook for owners of this book, go to manning.com/SpringRooinAction.
Spring Roo in Action brief contents contents foreword preface acknowledgments about this book Learning by experimenting Roadmap Things you’ll need Notes on earlier versions of Roo Code conventions Source code Author Online.
Relationships, JPA, and advanced persistence 4.3.5 Putting the people in courses...

O’Reilly books may be purchased for educational, business, or sales promotional use.
Java Network Programming, the image of a North American river otter, and related trade dress are trademarks of O’Reilly Media, Inc.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and O’Reilly Media, Inc., was aware of a trademark claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of this book, the publisher and author assume no responsibility for errors or omissions, or for damages resulting from the use of the information contained herein.
Java’s growth over the past 20 years has been nothing short of phenomenal.
Given Java’s rapid rise to prominence and the even more spectacular growth of the Internet, it’s a little surprising that network programming in Java remains so mysterious to so many.
In fact, writing network programs in Java is quite simple, as this book will show.
Readers with previous experience in network programming in a Unix, Windows, or Macintosh environment will be pleasantly surprised at how much easier it is to write equivalent programs in Java.
The Java core API includes well-designed interfaces to most network features.
Indeed, there is very little application layer network software you can write in C or C++ that you can’t write more easily in Java.
Java Network Programming, Fourth Edition, endeavors to show you how to take advantage of Java’s network class library to quickly and easily write programs that accomplish many common networking tasks.
Java is the first (though no longer the only) language to provide such a powerful crossplatform network library for handling all these diverse tasks.
Java Network Programming exposes the power and sophistication of this library.
To do so, this book provides a general background in network fundamentals, as well as detailed discussions of Java’s facilities for writing network programs.
You’ll learn how to write Java programs that share data across the Internet for games, collaboration, software updates, file transfer, and more.
You’ll also get a behind-the-scenes look at HTTP, SMTP, TCP/IP, and the other protocols that support the Internet and the Web.
When you finish this book, you’ll have the knowledge and the tools to create the next generation of software that takes full advantage of the Internet.
About the Fourth Edition In 1996, in the first edition of this book’s opening chapter, I wrote extensively about the sort of dynamic, distributed network applications I thought Java would make possible.
One of the most exciting parts of writing subsequent editions has been seeing virtually all of the applications I foretold come to pass.
Programmers are using Java to query database servers, monitor web pages, control telescopes, manage multiplayer games, and more, all by using Java’s native ability to access the Internet.
Java in general and network programming in Java in particular has moved well beyond the hype stage and into the realm of real, working applications.
The fourth edition focuses even more heavily on HTTP and REST.
As you’ll see, it is often the protocol on which other protocols are built, forming its own layer in the network stack.
Many other methods have been added to existing classes in the last three releases of Java, and these are discussed in the relevant chapters.
I’ve also rewritten large parts of the book to reflect the ever-changing fashions in Java programming in general and network programming in particular.
I hope you’ll find this fourth edition an even stronger, longer-lived, more accurate, and more enjoyable tutorial and reference to network programming in Java than the previous one.
Organization of the Book Chapter 1, Basic Network Concepts, explains in detail what a programmer needs to know about how the networks and the Internet work.
It covers the protocols that underlie the Internet, such as TCP/IP and UDP/IP.
The next two chapters throw some light on two parts of Java programming that are critical to almost all network programs but are often misunderstood and misused: I/O and threading.
Understanding how Java handles I/O in the general case is a prerequisite for understanding the special case of how Java handles network I/O.
Chapter 3, Threads, explores multithreading and synchronization, with a special emphasis on how they can be used for asynchronous I/O and network servers.
Experienced Java programmers may be able to skim or skip these two chapters.
However, Chapter 4, Internet Addresses, is essential reading for everyone.
It shows how Java programs interact with the Domain Name System through the InetAddress class, the one class that’s needed by essentially all network programs.
Once you’ve finished this chapter, it’s possible to jump around in the book as your interests and needs dictate.
Chapter 5, URLs and URIs, explores Java’s URL class, a powerful abstraction for downloading information and files from network servers of many kinds.
The URL class enables you to connect to and download files and documents from a network server without concerning yourself with the details of the protocol the server speaks.
It lets you connect to an FTP server using the same code you use to talk to an HTTP server or to read a file on the local hard disk.
You’ll also learn about the newer URI class, a more standardsconformant alternative for identifying but not retrieving resources.
Chapter 6, HTTP, delves deeper into the HTTP protocol specifically.
Chapter 7, URLConnections, shows you how to use the URLConnection and HttpURLConnection classes not just to download data from web servers, but to upload documents and configure connections.
Chapter 8, Sockets for Clients, introduces the Java sockets API and the Socket class in particular.
It shows you how to write network clients that interact with TCP servers of all kinds including whois, dict, and HTTP.
Chapter 9, Sockets for Servers, shows you how to use the ServerSocket class to write servers for these and other protocols.
Chapter 11, Nonblocking I/O, introduces the new I/O APIs specifically designed for network servers.
These APIs enable a program to figure out whether a connection is ready before it tries to read from or write to the socket.
This allows a single thread to manage many different connections simultaneously, thereby placing much less load on the virtual machine.
The new I/O APIs don’t help much for small servers or clients that don’t open many simultaneous connections, but they may provide performance boosts for high-volume servers that want to transmit as much data as the network can handle as fast as the network can deliver it.
Chapter 12, UDP, introduces the User Datagram Protocol (UDP) and the associated DatagramPacket and DatagramSocket classes that provide fast, unreliable communication.
Finally, Chapter 13, IP Multicast, shows you how to use UDP to communicate with multiple hosts at the same time.
Who You Are This book assumes you are comfortable with the Java language and programming environment, in addition to object-oriented programming in general.
This book does not attempt to be a basic language tutorial.
You should be thoroughly familiar with the syntax of Java.
It also wouldn’t hurt if you’re familiar with basic Swing programming, though that’s not required aside from a few examples.
However, this book doesn’t assume that you have prior experience with network programming.
You should find it a complete introduction to networking concepts and network application development.
I don’t assume that you have a few thousand networking acronyms (TCP, UDP, SMTP, etc.) at the tip of your tongue.
You’ll learn what you need to know about these here.
Java Versions Java’s network classes have changed a lot more slowly since Java 1.0 than other parts of the core API.
In comparison to the AWT or I/O, there have been almost no changes and only a few additions.
Of course, all network programs make extensive use of the I/O classes and some make heavy use of GUIs.
This book is written with the assumption that you are coding with at least Java 5.0
In general, I use Java 5 features like generics and the enhanced for loop freely without further explanation.
Overall, though, Java’s networking API has been relatively stable since Java 1.0
Very little of the post-1.0 networking API has ever been deprecated, and additions have been.
You shouldn’t have any trouble using this book after Java 8 is released.
New APIs, however, have been somewhat more frequent in the supporting classes, particularly I/O, which has undergone three major revisions since Java 1.0
About the Examples Most methods and classes described in this book are illustrated with at least one complete working program, simple though it may be.
In my experience, a complete working program is essential to showing the proper use of a method.
Without a program, it is too easy to drop into jargon or to gloss over points about which the author may be unclear in his own mind.
The Java API documentation itself often suffers from excessively terse descriptions of the method calls.
In this book, I have tried to err on the side of providing too much explication rather than too little.
If a point is obvious to you, feel free to skip over it.
You do not need to type in and run every example in this book; but if a particular method does give you trouble, you should have at least one working example.
Each chapter includes at least one (and often several) more complex programs that demonstrate the classes and methods of that chapter in a more realistic setting.
These often rely on Java features not discussed in this book.
Indeed, in many of the programs, the networking components are only a small fraction of the source code and often the least difficult parts.
Nonetheless, none of these programs could be written as easily in languages that didn’t give networking the central position it occupies in Java.
The apparent simplicity of the networked sections of the code reflects the extent to which networking has been made a core feature of Java, and not any triviality of the program itself.
All example programs presented in this book are available online, often with corrections and additions.
I have tested all the examples on Linux and many on Windows and Mac OS X.
Most of the examples given here should work on other platforms and with other compilers and virtual machines that support Java 5 or later.
These examples can easily be rewritten to support earlier Java versions at the cost of increased verbosity.
I do feel a little guilty about a couple of compromises necessitated by the needs of space in a printed book.
Most methods assume they are passed good data, and dispense with null checks and similar principles of good code hygiene.
Furthermore, I have reduced the indentation to two characters per block and four characters per continuation line, as opposed to the Java standard of four and eight, respectively.
On the positive side, these compromises have aided me in making this edition considerably shorter (by several hundred pages) than the previous edition.
Code examples and fragments • Anything that might appear in a Java program, including keywords, operators, data.
Command lines and options that should be typed verbatim on the screen.
New terms where they are defined • Pathnames, filenames, and program names (however, if the program name is also.
Significant code fragments and complete programs are generally placed into a separate paragraph, like this:
When code is presented as fragments rather than complete programs, the existence of the appropriate import statements should be inferred.
For example, in the preceding code fragment you may assume that java.net.Socket was imported.
In these cases, the user input will be displayed in bold, as in this example from Chapter 9:
Finally, although many of the examples used here are toy examples unlikely to be reused, a few of the classes I develop have real value.
Please feel free to reuse them or any parts of them in your own code.
They are in the public domain (although the same is most definitely not true of the explanatory text!)
Request for Comments I enjoy hearing from readers, whether with general comments about this book, specific corrections, other topics they would like to see covered, or just war stories about their own network programming travails.
You can reach me by sending an email to elharo@ibiblio.org.
Please realize, however, that I receive several hundred pieces of email a day and cannot personally respond to each one.
For the best chance of getting a personal response, please identify yourself as a reader of this book.
If you have a question about a particular program that isn’t working as you expect, try to reduce it to the simplest case that reproduces the bug, preferably a single class, and paste the text of the entire program into the body of your email.
And please, please send the message from the account you want me to reply to and make sure that your Reply-to address is properly set! There’s nothing quite so frustrating as spending an hour or more carefully researching the answer to an interesting question and composing a detailed response, only to have it bounce because my correspondent sent her feedback from a public terminal and neglected to set the browser preferences to include her actual email address.
I also adhere to the old saying “If you like this book, tell your friends.
If you don’t like it, tell me.” I’m especially interested in hearing about mistakes.
I’ve yet to make it perfect, but I keep trying.
And I’m sure that at least one of them is a really embarrassing whopper of a problem.
If you find a mistake or a typo, please let me know so I can correct it.
Before reporting errors, please check one of those pages to see if I already know about it and have posted a fix.
Any errors that are reported will be fixed in future printings.
Using Code Examples This book is here to help you get your job done.
In general, if this book includes code examples, you may use the code in this book in your programs and documentation.
You do not need to contact us for permission unless you’re reproducing a significant portion of the code.
For example, writing a program that uses several chunks of code from this book does not require permission.
Selling or distributing a CD-ROM of examples from O’Reilly books does require permission.
Answering a question by citing this book and quoting example code does not require permission.
Incorporating a significant amount of example code from this book into your product’s documentation does require permission.
An attribution usually includes the title, author, publisher, and ISBN.
If you feel your use of code examples falls outside fair use or the permission given here, feel free to contact us at permissions@oreilly.com.
Safari® Books Online Safari Books Online is an on-demand digital library that delivers expert content in both book and video form from the world’s leading authors in technology and business.
Technology professionals, software developers, web designers, and business and creative professionals use Safari Books Online as their primary resource for research, problem solving, learning, and certification training.
Safari Books Online offers a range of product mixes and pricing programs for organizations, government agencies, and individuals.
For more information about Safari Books Online, please visit us online.
How to Contact Us Please address comments and questions concerning this book to the publisher:
We have a web page for this book, where we list errata, examples, and any additional information.
To comment or ask technical questions about this book, send email to bookques tions@oreilly.com.
For more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.
Acknowledgments Many people were involved in the production of this book.
My editor, Mike Loukides, got things rolling, and provided many helpful comments along the way that substantially improved the book.
The technical editors all provided invaluable assistance in hunting down errors and omissions.
Laurent provided crucial advice on which topics deserved more coverage.
Scott Oaks lent his thread expertise to Chapter 3, proving once again by the many subtle bugs he hunted down that multithreading still requires the attention of an expert.
Ron Hitchens shone light into many of the darker areas of the new I/O APIs.
Marc Loy and Jim Elliott reviewed some of the most bleeding edge material in the book.
Rohaly was unswerving in his commitment to making sure I closed all my sockets and caught all possible exceptions, and in general wrote the cleanest, safest, most exemplary code I could write.
John Zukowski found numerous errors of omission, all now filled thanks to him.
And the eagle-eyed Avner Gelb displayed an astonishing ability to spot mistakes that had somehow managed to go unnoticed by myself, all the other.
Alex Stangl and Ryan Cuprak provided further assistance with spotting both new and lingering mistakes in this latest edition.
It isn’t customary to thank the publisher, but the publisher does set the tone for the rest of the company, authors, editors, and production staff alike; and I think Tim O’Reilly deserves special credit for making O’Reilly Media absolutely one of the best houses an author can write for.
If there’s one person without whom this book would never have been written, it’s him.
If you, the reader, find O’Reilly books to be consistently better than most of the dreck on the market, the reason really can be traced straight back to Tim.
My agent, David Rogelberg, convinced me it was possible to make a living writing books like this rather than working in an office.
The entire crew at ibiblio.org over the last several years has really helped me to communicate better with my readers in a variety of ways.
Every reader who sent in bouquets and brickbats for previous editions has been instrumental in helping me write this much-improved edition.
Finally, as always, I’d like to offer my largest thanks to my wife, Beth, without whose love and support this book would never have happened.
Network programming is no longer the province of a few specialists.
It has become a core part of every developer’s toolbox.
Besides classic applications like email, web browsers, and remote login, most major applications have some level of networking built in.
Text editors like BBEdit save and open files directly from FTP servers.
IDEs like Eclipse and IntelliJ IDEA communicate with source code repositories like.
Antivirus programs like Norton AntiVirus check for new virus definitions by connecting to the vendor’s website every time the computer is started.
Music players like Winamp and iTunes upload CD track lengths to CDDB and.
Gamers playing multiplayer first-person shooters like Halo gleefully frag each other.
Supermarket cash registers running IBM SurePOS ACE communicate with their.
The server uploads its daily receipts to the chain’s central computers each night.
Schedule applications like Microsoft Outlook automatically synchronize calendars among employees in a company.
Java was the first programming language designed from the ground up for network applications.
Java was originally aimed at proprietary cable television networks rather than the Internet, but it’s always had the network foremost in mind.
One of the first two real Java applications was a web browser.
As the Internet continues to grow, Java is uniquely suited to build the next generation of network applications.
One of the biggest secrets about Java is that it makes writing network programs easy.
In fact, it is far easier to write network programs in Java than in almost any other language.
This book shows you dozens of complete programs that take advantage of the Internet.
Some are simple textbook examples, while others are completely functional applications.
One thing you’ll notice in the fully functional applications is just how little code is devoted to networking.
Even in network-intensive programs like web servers and clients, almost all the code handles data manipulation or the user interface.
The part of the program that deals with the network is almost always the shortest and simplest.
In brief, it is easy for Java applications to send and receive data across the Internet.
This chapter covers the background networking concepts you need to understand before writing networked programs in Java (or, for that matter, in any language)
Moving from the most general to the most specific, it explains what you need to know about networks in general, IP and TCP/IP-based networks in particular, and the Internet.
This chapter doesn’t try to teach you how to wire a network or configure a router, but you will learn what you need to know to write applications that communicate across the Internet.
Topics covered in this chapter include the nature of networks; the TCP/IP layer model; the IP, TCP, and UDP protocols; firewalls and proxy servers; the Internet; and the Internet standardization process.
Experienced network gurus may safely skip this chapter, and move on to the next chapter where you begin developing the tools needed to write your own network programs in Java.
Networks A network is a collection of computers and other devices that can send data to and receive data from one another, more or less in real time.
A network is often connected by wires, and the bits of data are turned into electromagnetic waves that move through the wires.
However, wireless networks transmit data using radio waves; and most longdistance transmissions are now carried over fiber-optic cables that send light waves through glass filaments.
There’s nothing sacred about any particular physical medium for the transmission of data.
Theoretically, data could be transmitted by coal-powered computers that send smoke signals to one another.
The response time (and environmental impact) of such a network would be rather poor.
Most nodes are computers, but printers, routers, bridges, gateways, dumb terminals, and Coca-Cola™ machines can also be nodes.
You might use Java to interface with a Coke machine, but otherwise you’ll mostly talk to other computers.
Nodes that are fully functional computers are also called hosts.
I will use the word node to refer to any device on the network, and the word host to refer to a node that is a general-purpose computer.
Every network node has an address, a sequence of bytes that uniquely identifies it.
You can think of this group of bytes as a number, but in general the number of bytes in an address or the ordering of those bytes (big endian or little endian) is not guaranteed to.
The more bytes there are in each address, the more addresses there are available and the more devices that can be connected to the network simultaneously.
Manufacturers of Ethernet hardware use preassigned manufacturer codes to make sure there are no conflicts between the addresses in their hardware and the addresses of other manufacturers’ hardware.
Each manufacturer is responsible for making sure it doesn’t ship two Ethernet cards with the same address.
Internet addresses are normally assigned to a computer by the organization that is responsible for it.
However, the addresses that an organization is allowed to choose for its computers are assigned by the organization’s Internet service provider (ISP)
ISPs get their IP addresses from one of four regional Internet registries (the registry for North America is ARIN, the American Registry for Internet Numbers), which are in turn assigned IP addresses by the Internet Corporation for Assigned Names and Numbers (ICANN)
Names can change while addresses stay the same; likewise, addresses can change while the names stay the same.
One address can have several names and one name can refer to several different addresses.
All modern computer networks are packet-switched networks: data traveling on the network is broken into chunks called packets and each packet is handled separately.
Each packet contains information about who sent it and where it’s going.
The most from many ongoing exchanges can travel on one wire, which makes it much cheaper to build a network: many computers can share the same wire without interfering.
In contrast, when you make a local telephone call within the same exchange on a traditional phone line, you have essentially reserved a wire from your phone to the phone of the person you’re calling.
When all the wires are in use, as sometimes happens during a major emergency or holiday, not everyone who picks up a phone will get a dial tone.
If you stay on the line, you’ll eventually get a dial tone when a line becomes free.
In some countries with worse phone service than the United States, it’s not uncommon to have to wait half an hour or more for a dial tone.) Another advantage of packets is that checksums can be used to detect whether a packet was damaged in transit.
We’re still missing one important piece: some notion of what computers need to say to pass data back and forth.
A protocol is a precise set of rules defining how computers communicate: the format of addresses, how data is split into packets, and so on.
There are many different protocols defining different aspects of network communication.
For example, the Hypertext Transfer Protocol (HTTP) defines how web browsers and.
Open, published protocol standards allow software and equipment from different vendors to communicate with one another.
A web server doesn’t care whether the client is a Unix workstation, an Android phone, or an iPad, because all clients speak the same HTTP protocol regardless of platform.
The Layers of a Network Sending data across a network is a complex operation that must be carefully tuned to the physical characteristics of the network as well as the logical character of the data being sent.
Software that sends data across a network must understand how to avoid collisions between packets, convert digital data to analog signals, detect and correct errors, route packets from one host to another, and more.
The process is further complicated when the requirement to support multiple operating systems and heterogeneous network cabling is added.
To hide most of this complexity from the application developer and end user, the different aspects of network communication are separated into multiple layers.
Each layer represents a different level of abstraction between the physical hardware (i.e., the wires and electricity) and the information being transmitted.
In theory, each layer only talks to the layers immediately above and immediately below it.
Separating the network into layers lets you modify or even replace the software in one layer without affecting the others, as long as the interfaces between the layers stay the same.
Figure 1-1 shows a stack of possible protocols that may exist in your network.
While the middle layer protocols are fairly consistent across most of the Internet today, the top and the bottom vary a lot.
Some hosts use Ethernet; some use WiFi; some use PPP; some use something else.
Similarly, what’s on the top of the stack will depend completely on which programs a host is running.
The key is that from the top of the stack, it doesn’t really matter what’s on the bottom and vice versa.
The layer model decouples the application protocols (the main subject of this book) from the physics of the network hardware and the topology of the network connections.
There are several different layer models, each organized to fit the needs of a particular kind of network.
This book uses the standard TCP/IP four-layer model appropriate for the Internet, shown in Figure 1-2
In this model, applications like Firefox and Warcraft run in the application layer and talk only to the transport layer.
The transport layer talks only to the application layer and the Internet layer.
The Internet layer in turn talks only to the host-to-network layer and the transport layer, never directly to the application layer.
The host-to-network layer moves the data across the wires, fiber-optic cables, or other medium to the host-to-network layer on the remote system, which then moves the data up the layers to the application on the remote system.
For example, when a web browser sends a request to a web server to retrieve a page, the browser is actually talking to the transport layer on the local client machine.
The internet layer fragments the segments into IP datagrams of the necessary size for the local network and passes them to the host-to-network layer for transmission onto the wire.
The host-to-network layer encodes the digital data as analog signals appropriate for the particular physical medium and sends the request out the wire where it will be read by the host-to-network layer of the remote system to which it’s addressed.
The host-to-network layer on the remote system decodes the analog signals into digital data, then passes the resulting IP datagrams to the server’s internet layer.
The internet layer does some simple checks to see that the IP datagrams aren’t corrupt, reassembles them if they’ve been fragmented, and passes them to the server’s transport layer.
The server’s transport layer checks to see that all the data arrived and requests retransmission of any missing or corrupt pieces.
This request actually goes back down through the server’s internet layer, through the server’s host-to-network layer, and back to the client system, where it bubbles back up to the client’s transport layer, which retransmits the missing data back down through the layers.
This is all transparent to the application layer.) Once the server’s transport layer has received enough contiguous, sequential datagrams, it reassembles them and writes them onto a stream read by the web server running in the server application layer.
The server responds to the request and sends its response back down through the layers on the server system for transmission back across the Internet and delivery to the web client.
As you can guess, the real process is much more elaborate.
The host-to-network layer is by far the most complex, and a lot has been deliberately hidden.
For example, it’s entirely possible that data sent across the Internet will pass through several routers and their layers before reaching its final destination.
It may need to be converted from radio waves in the air to electrical signals in copper wire to light pulses in fiber-optic cables and back again, possibly more than once.
However, 90% of the time your Java code will work in the application layer and only need to talk to the transport layer.
The other 10% of the time, you’ll be in the transport layer and talking to the application layer or the internet layer.
The complexity of the host-to-network layer is hidden from you; that’s the point of the layer model.
If you read the network literature, you’re likely to encounter an alternative seven-layer model called the Open Systems Interconnection (OSI) Reference Model.
For network programs in Java, the OSI model is overkill.
The biggest difference between the OSI model and the TCP/IP model used in this book is that the OSI model splits the hostto-network layer into data link and physical layers and inserts presentation and session layers in between the application and transport layers.
The OSI model is more general and better suited for non-TCP/ IP networks, although most of the time it’s still overly complex.
In any case, Java’s network classes only work on TCP/IP networks and always in the application or transport layers, so for the purposes of this book, absolutely nothing is gained by using the more complicated OSI model.
To the application layer, it seems as if it is talking directly to the application layer on the other system; the network creates a logical path between the two application layers.
It’s easy to understand the logical path if you think about an IRC chat session.
Most participants in an IRC chat would say that they’re talking to another person.
If you really push them, they might say that they’re talking to their computer (really the application layer), which is talking to the other person’s computer, which is talking to the other person.
Everything more than one layer deep is effectively invisible, and that is exactly the way it should be.
The Host-to-Network Layer As a Java programmer, you’re fairly high up in the network food chain.
In the standard reference model for IP-based Internets (the only kind of network Java really understands), the hidden parts of the network belong to the hostto-network layer (also known as the link layer, data link layer, or network interface layer)
The part of the host-to-network layer made up of the hardware that connects different computers (wires, fiber-optic cables, radio waves, or smoke signals) is sometimes called the physical layer of the network.
The primary reason you’ll need to think about the host-to-network layer and the physical layer, if you need to think about them at all, is performance.
For instance, if your clients reside on fast, reliable fiber-optic connections, you will design your protocol and applications differently than if they’re on high-latency satellite connections on an oil rig.
You’ll make still different choices if your clients are on a 3G data plan where they’re charged by the byte for relatively low bandwidth.
And if you’re writing a general consumer application that could be used by any of these clients, you’ll try to hit a sweet spot somewhere in the middle, or perhaps even detect and dynamically adapt to individual client capabilities.
However, whichever physical links you encounter, the APIs you use to communicate across those networks are the same.
The Internet Layer The next layer of the network, and the first that you need to concern yourself with, is the internet layer.
In the OSI model, the internet layer goes by the more generic name network layer.
A network layer protocol defines how bits and bytes of data are organized into the larger groups called packets, and the addressing scheme by which different machines find one another.
The Internet Protocol (IP) is the most widely used network layer protocol in the world and the only network layer protocol Java understands.
Although these are two very different network protocols that do not interoperate on the same network without special gateways and/or tunneling protocols, Java hides almost all of the differences from you.
All bits and bytes are big endian; most significant to least significant runs left to right.
Besides routing and addressing, the second purpose of the Internet layer is to enable different types of Host-to-Network layers to talk to each other.
Internet routers translate between WiFi and Ethernet, Ethernet and DSL, DSL and fiber-optic backhaul protocols, and so forth.
Without the internet layer or something like it, each computer could only talk to other computers that shared its particular type of network.
The internet layer is responsible for connecting heterogenous networks to each other using homogeneous protocols.
Most notably, there’s no guarantee that they will be delivered.
Even if they are delivered, they may have been corrupted in transit.
The header checksum can only detect corruption in the header, not in the data portion of a datagram.
Finally, even if the datagrams arrive uncorrupted, they do not necessarily arrive in the order in which they were sent.
Individual datagrams may follow different routes from source to destination.
Just because datagram A is sent before datagram B does not mean that datagram A will arrive before datagram B.
The transport layer is responsible for ensuring that packets are received in the order they were sent and that no data is lost or corrupted.
If a packet is lost, the transport layer can ask the sender to retransmit the packet.
The first, the Transmission Control Protocol (TCP), is a high-overhead protocol that allows for retransmission of lost or corrupted data and delivery of bytes in the order they were sent.
The second protocol, the User Datagram Protocol (UDP), allows the receiver to detect corrupted packets but does not guarantee.
Later, you’ll see that unreliable protocols are much more useful than they sound.
The Application Layer The layer that delivers data to the user is called the application layer.
The three lower layers all work together to define how data is transferred from one computer to another.
The application layer decides what to do with the data after it’s transferred.
For example, an application protocol like HTTP (for the World Wide Web) makes sure that your web browser displays a graphic image as a picture, not a long stream of numbers.
The application layer is where most of the network parts of your programs spend their time.
There is an entire alphabet soup of application layer protocols: in addition to HTTP for the Web, there are SMTP, POP, and IMAP for email; FTP, FSP, and TFTP for file transfer; NFS for file access; Gnutella and BitTorrent for file sharing; the Session Initiation Protocol (SIP) and Skype for voice communication; and many, many more.
In addition, your programs can define their own application layer protocols as necessary.
IP, TCP, and UDP IP, the Internet protocol, was developed with military sponsorship during the Cold War, and ended up with a lot of features that the military was interested in.
The entire network couldn’t stop functioning if the Soviets nuked a router in Cleveland; all messages still had to get through to their intended destinations (except those going to Cleveland, of course)
Therefore, IP was designed to allow multiple routes between any two points and to route packets of data around damaged routers.
Second, the military had many different kinds of computers, and all of them had to be able to talk to one another.
Therefore, IP had to be open and platform-independent; it wasn’t good enough to have one protocol for IBM mainframes and another for PDP-11s.
The IBM mainframes needed to talk to the PDP-11s and any other strange computers that might be lying around.
Because there are multiple routes between two points, and because the quickest path between two points may change over time as a function of network traffic and other factors (such as the existence of Cleveland), the packets that make up a particular data stream may not all take the same route.
Furthermore, they may not arrive in the order they were sent, if they even arrive at all.
To improve on the basic scheme, TCP was layered on top of IP to give each end of a connection the ability to acknowledge receipt of IP packets and request retransmission of lost or corrupted packets.
Furthermore, TCP allows the packets to be put back together on the receiving end in the same order they were sent.
Therefore, if the order of the data isn’t particularly important and if the loss of individual packets won’t completely corrupt the data stream, packets are sometimes sent without the guarantees that TCP provides using the UDP protocol.
Although this would be a problem for uses such as file transfer, it is perfectly acceptable for applications where the loss of some data would go unnoticed by the end user.
For example, losing a few bits from a video or audio signal won’t cause much degradation; it would be a bigger problem if you had to wait for a protocol like TCP to request a retransmission of missing data.
Furthermore, error-correcting codes can be built into UDP data streams at the application level to account for missing data.
A number of other protocols can run on top of IP.
The most commonly requested is ICMP, the Internet Control Message Protocol, which uses raw IP datagrams to relay error messages between hosts.
The best-known use of this protocol is in the ping program.
Java does not support ICMP, nor does it allow the sending of raw IP datagrams (as opposed to TCP segments or UDP datagrams)
The only protocols Java supports are TCP and UDP, and application layer protocols built on top of these.
All other transport layer, internet layer, and lower layer protocols such as ICMP, IGMP, ARP, RARP, RSVP, and others can only be implemented in Java programs by linking to native code.
Every computer on an IPv4 network is identified by a four-byte number.
Every computer attached to an IPv4 network has a unique four-byte address.
When data is transmitted across the network, the packet’s header includes the address of the machine for which the packet is intended (the destination address) and the address of the machine that sent the packet (the source address)
Routers along the way choose the best route on which to send the packet by inspecting the destination address.
The source address is included so the recipient will know who to reply to.
There are a little more than four billion possible IP addresses, not even one for every person on the planet, much less for every computer.
To make matters worse, the addresses aren’t allocated very efficiently.
No more IPv4 addresses were available to be allocated to these regions; and they have since had to make do by recycling and reallocating from their existing supply.
North America, Latin America, and Africa still have a few IP address blocks left to parcel out, but they’re not going to last much longer.
This provides enough IP addresses to identify every person, every computer, and indeed every device.
A double colon, at most one of which may appear in any address, indicates multiple zero blocks.
Although computers are very comfortable with numbers, human beings aren’t very good at remembering them.
When Java programs access the network, they need to process both these numeric addresses and their corresponding hostnames.
Methods for doing this are provided by the java.net.InetAddress class, which is discussed in Chapter 4
Others, especially clients on local area networks and wireless connections, receive a different address every time they boot up, often provided by a DHCP server.
Mostly you just need to remember that IP addresses may change over time, and not write any code that relies on a system having the same IP address.
For instance, don’t store the local IP address when saving application state.
Instead, look it up fresh each time your program starts.
It’s also possible, although less likely, for an IP address to change while the program is running (e.g., if a DHCP lease expires), so you may want to check the current IP address every time you need it rather than caching it.
Otherwise, the difference between a dynamically and manually assigned address is not significant to Java programs.
They can be used on internal networks, but no host using addresses in these blocks is allowed onto the global Internet.
These non-routable addresses are useful for building private networks that can’t be seen on the Internet.
That is, these addresses always point to the local computer, no matter which computer you’re running on.
The address 0.0.0.0 always refers to the originating host, but may only be used as a source address, not a destination.
Packets sent to this address are received by all nodes on the local network, though they are not routed beyond the local network.
For instance, when an ephemeral client such as a laptop boots up, it will send a particular message to 255.255.255.255 to find the local DHCP server.
All nodes on the network receive the packet, but only the DHCP server responds.
In particular, it sends the laptop information about the local network configuration, including the IP address that laptop should use for the remainder of its session and the address of a DNS server it can use to resolve hostnames.
Ports Addresses would be all you needed if each computer did no more than one thing at a time.
Email needs to be separated from FTP requests, which need to be separated from web traffic.
Each computer with an IP address has several thousand logical ports (65,535 per transport layer protocol, to be precise)
These are purely abstractions in the computer’s memory and do not represent anything physical, like a USB port.
For example, HTTP, the underlying protocol of the Web, commonly uses port 80
We say that a web server listens on port 80 for incoming connections.
When data is sent to a web server on a particular machine at a particular IP address, it is also sent to a particular port (usually port 80) on that machine.
The receiver checks each packet it sees for the port and sends the data to any program that is listening to that port.
This is how different types of traffic are sorted out.
On Unix systems, including Linux and Mac OS X, only programs running as root can receive data from these ports, but all programs may send data to them.
On Windows, any program may use these ports without special privileges.
Table 1-1 shows the well-known ports for the protocols that are discussed in this book.
On Unix systems, a fairly complete listing of assigned ports is stored in the file /etc/services.
It is an amorphous group of computers in many different countries on all seven continents (Antarctica included) that talk to one another using IP protocols.
Each computer on the Internet has at least one IP address by which it can be identified.
Many of them also have at least one name that maps to that IP address.
The Internet is not owned by anyone, although pieces of it are.
It is not governed by anyone, which is not to say that some governments don’t try.
It is simply a very large collection of computers that have agreed to talk to one another in a standard way.
The Internet is not the only IP-based network, but it is the largest one.
Other IP networks are called internets with a little i: for example, a high-security internal network that is not connected to the global Internet.
Intranet loosely describes corporate practices of putting lots of data on internal web servers that are not visible to users outside the local network.
Unless you’re working in a high-security environment that’s physically disconnected from the broader network, it’s likely that the internet you’ll be using is the Internet.
To make sure that hosts on different networks on the Internet can communicate with each other, a few rules need to be followed that don’t apply to purely internal internets.
The most important rules deal with the assignment of addresses to different organizations, companies, and individuals.
If everyone picked the Internet addresses they wanted at random, conflicts would arise almost immediately when different computers showed up on the Internet with the same address.
Internet Address Blocks To avoid this problem, blocks of IPv4 addresses are assigned to Internet service providers (ISPs) by their regional Internet registry.
When a company or an organization wants to set up an IP-based network connected to the Internet, their ISP assigns them a block of addresses.
However, the lowest address in all block used to identify the network itself, and the largest address is a broadcast address for the network, so you have two fewer available addresses than you might first expect.
Network Address Translation Because of the increasing scarcity of and demand for raw IP addresses, most networks today use Network Address Translation (NAT)
The routers that connect the local networks to the ISP translate these local addresses to a much smaller set of routable addresses.
For instance, the dozen or so IP nodes in my apartment all share a single externally visible IP address.
The computer on which I’m typing this has the IP address 192.168.1.5, but on your network that address may refer to a completely different host, if it exists at all.
Nor could you reach my computer by sending data to 192.168.1.5
The router watches my outgoing and incoming connections and adjusts the addresses in the IP packets.
For an outgoing packet, it changes the source address to the router’s external address (216.254.85.72 on my network)
For an incoming packet, it changes the destination address to one of the local addresses, such as 192.168.1.12
Exactly how it keeps track of which connections come from and are aimed at which internal computers is not particularly important to a Java programmer.
As long as your machines are configured properly, this process is mostly transparent.
You just need to remember that the external and internal addresses may not be the same.
Subnets will still exist for routing, but they’ll be much larger.
To keep them out, it’s often helpful to set up one point of access to a local network and check all traffic into or out of that access.
The hardware and software that sit between the Internet and the local network, checking all the data that comes in or out to make sure it’s kosher, is called a firewall.
The firewall is often part of the router that connects the local network to the broader Internet and may perform other tasks, such as network address translation.
Modern operating systems like Mac OS X and Red Hat Linux often have built-in personal firewalls that monitor just the traffic sent to that one machine.
Either way, the firewall is responsible for inspecting each packet that passes into or out of its network interface and accepting it or rejecting it according to a set of rules.
For example, all traffic coming from the Class C network 193.28.25.x may be rejected because you had bad experiences with hackers from that network in the past.
Outgoing SSH connections may be allowed, but incoming SSH connections may not.
Incoming connections on port 80 (web) may be allowed, but only to the corporate web server.
More intelligent firewalls look at the contents of the packets to determine whether to accept or reject them.
Java doesn’t have much to do with firewalls—except insofar as they often get in your way.
If a firewall prevents hosts on a network from making direct connections to the outside world, a proxy server can act as a go-between.
Thus, a machine that is prevented from connecting to the external network by a firewall would make a request for a web page from the local proxy server instead of requesting the web page directly from the remote web server.
The proxy server would then request the page from the web server and forward the response back to the original requester.
Proxies can also be used for FTP services and other connections.
One of the security advantages of using a proxy server is that external hosts only find out about the proxy server.
They do not learn the names and IP addresses of the internal machines, making it more difficult to hack into internal systems.
Whereas firewalls generally operate at the level of the transport or internet layer, proxy servers normally operate at the application layer.
A proxy server has a detailed understanding of some application-level protocols, such as HTTP and FTP.
The notable exception are SOCKS proxy servers that operate at the transport layer, and can proxy for all TCP and UDP connections regardless of application layer protocol.) Packets that pass through the proxy server can be examined to ensure that they contain data appropriate for their type.
For instance, FTP packets that seem to contain Telnet data can be rejected.
Figure 1-4 shows how proxy servers fit into the layer model.
As long as all access to the Internet is forwarded through the proxy server, access can be tightly controlled.
For instance, a company might choose to block access to www.playboy.com but allow access to www.microsoft.com.
Some companies allow incoming FTP but disallow outgoing FTP so confidential data cannot be as easily smuggled out of the company.
Other companies use proxy servers to track their employees’ web usage so they can see who’s using the Internet to get tech support and who’s using it to check out the Playmate of the Month.
Proxy servers can also be used to implement local caching.
When a file is requested from a web server, the proxy server first checks to see if the file is in its cache.
If the file is in the cache, the proxy serves the file from the cache rather than from the Internet.
If the file is not in the cache, the proxy server retrieves the file, forwards it to the requester, and stores it in the cache for the next time it is requested.
This scheme can significantly reduce load on an Internet connection and greatly improve response time.
America Online runs one of the largest farms of proxy servers in the world to speed the transfer of data to its users.
If you look at a web server logfile, you’ll probably find some hits from clients in the aol.com domain, but not as many as you’d expect given the more than three million AOL subscribers.
That’s because AOL proxy servers supply many pages out of their cache rather than re-requesting them for one another.
The biggest problem with proxy servers is their inability to cope with all but a few protocols.
Generally established protocols like HTTP, FTP, and SMTP are allowed to pass through, while newer protocols like BitTorrent are not.
Some network administrators consider this a feature.) In the rapidly changing world of the Internet, this is a significant disadvantage.
It’s a particular disadvantage for Java programmers because it limits the effectiveness of custom protocols.
In Java, it’s easy and often useful to create a new protocol that is optimized for your application.
Consequently, some developers have taken to tunneling their protocols through HTTP, most notably with SOAP.
The firewall is normally there for a reason, not just to annoy Java programmers.
Applets that run in web browsers normally use the proxy server settings of the web browser itself, though these can be overridden in the Java Control Panel.
Standalone Java applications can indicate the proxy server to use by setting the socksProxyHost and socksProxyPort properties (if you’re using a SOCKS proxy server), or http.proxySet, http.proxyHost, http.proxyPort, https.proxySet, https.proxy Host, https.proxyPort, ftpProxySet, ftpProxyHost, ftpProxyPort, gopherProxy Set, gopherProxyHost, and gopherProxyPort system properties (if you’re using protocol-specific proxies)
You can set system properties from the command line using the -D flag, like this:
The Client/Server Model Most modern network programming is based on a client/server model.
A client/server application typically stores large quantities of data on an expensive, high-powered server or cloud of servers while most of the program logic and the user interface is handled by client software running on relatively cheap personal computers.
In most cases, a server primarily sends data while a client primarily receives it; but it is rare for one program to send or receive exclusively.
A more reliable distinction is that a client initiates a conversation while a server waits for clients to start conversations with it.
In some cases, the same program may be both a client and a server.
You are already familiar with many examples of client/server systems.
In 2013, the most popular client/server system on the Internet is the Web.
Web servers like Apache respond to requests from web clients like Firefox.
Data is stored on the web server and is sent out to the clients that request it.
Aside from the initial request for a page, almost all data is transferred from the server to the client, not from the client to the server.
People often use FTP to upload files from the client to the server, so it’s harder to say that the data transfer is primarily in one direction, but it is still true that an FTP client initiates the connection and the FTP server responds.
For instance, in networked games, it seems likely that both players will send data back and forth roughly equally (at least in a fair game)
The telephone system is the classic example of a peer-to-peer network.
Each phone can either call another phone or be called by another phone.
You don’t have to buy one phone to send calls and another to receive them.
Java does not have explicit peer-to-peer communication in its core networking API.
However, applications can easily offer peer-to-peer communications in several ways, most commonly by acting as both a server and a client.
Alternatively, the peers can communicate with each other through an intermediate server program that forwards data from one peer to the other peers.
This neatly solves the discovery problem of how two peers find each other.
Internet Standards This book discusses several application layer Internet protocols, most notably HTTP.
If you need detailed information about any protocol, the definitive source is the standards document for the protocol.
Although there are many standards organizations in the world, the two that produce most of the standards relevant to application layer network programming and protocols are the Internet Engineering Task Force (IETF) and the World Wide Web Consortium (W3C)
The IETF is a relatively informal, democratic body open to participation by any interested party.
The W3C, by contrast, is a vendor organization, controlled by duespaying member corporations, that explicitly excludes participation by individuals.
For the most part, the W3C tries to define standards in advance of implementation.
Despite the name, a published RFC is a finished work.
It may be obsoleted or replaced by a new RFC, but it will not be changed.
RFCs range from informational documents of general interest to detailed specifications of standard Internet protocols such as FTP.
RFCs are available from many locations on the Internet, including http://www.faqs.org/rfc/ and http://www.ietf.org/rfc.html.
For the most part, RFCs, (particularly standards-oriented RFCs), are very technical, turgid, and nearly incomprehensible.
Nonetheless, they are often the only complete and reliable source of information about a particular protocol.
Most proposals for an RFC begin when a person or group gets an idea and builds a prototype.
Before something can become an IETF standard, it must actually exist and work.
This requirement ensures that IETF standards are at least feasible, unlike the standards promulgated by some other organizations.
Table 1-2 lists the RFCs that provide formal documentation for the protocols discussed in this book.
Describes the standardization process and the current status of the different Internet protocols.
Host Requirements Documents the protocols that must be supported by all Internet hosts at different layers (data link layer, IP layer, transport layer, and application layer)
An internet layer protocol that uses raw IP datagrams but is not supported by Java.
The application layer protocol by which one host transfers email to another host.
This standard doesn’t say anything about email user interfaces; it covers the mechanism for passing email from one computer to another.
Telnet Protocol An application layer remote login service for command-line environments based around an abstract network virtual terminal (NVT) and TCP.
An application layer protocol that sends an indefinite sequence of ASCII characters to any client that connects over either TCP or UDP; also useful as a debugging tool.
This contrasts with the various NTP and Time Server protocols, which do not return data that can be easily read by humans.
The time is sent as a machinereadable, 32-bit unsigned integer.
The standard is incomplete in that it does not specify how the integer is encoded in 32 bits, but in practice a big-endian integer is used.
The application layer protocol by which Usenet news is transferred from machine to machine over TCP; used by both news clients talking to news servers and news servers talking to each other.
Domain Name System The collection of distributed software by which hostnames that human beings can remember, like www.oreilly.com, are translated into numbers that computers can understand, like 198.112.208.11
This RFC defines how domain name servers on different hosts communicate with each other using UDP.
The internet layer methods by which conforming systems can direct a single packet of data to multiple hosts.
A more precise application layer protocol for synchronizing clocks between systems that attempts to account for network latency.
An application layer protocol used by sporadically connected email clients such as Eudora to retrieve mail from a server over TCP.
A means of encoding binary data and non-ASCII text for transmission through Internet email and other ASCII-oriented protocols.
Similar to URLs but intended to refer to actual resources in a persistent fashion rather than the transient location of those resources.
Version 1.1 of the application layer protocol used by web browsers talking to web servers over TCP.
A protocol for remotely accessing a mailbox stored on a server including downloading messages, deleting messages, and moving messages into and out of different folders.
For instance, ISBN numbers may be URIs even if the book cannot be retrieved over the Internet.
The IETF has traditionally worked behind the scenes to codify and standardize existing practice.
Although its activities are completely open to the public, it’s been very low profile.
There simply aren’t that many people who get excited about network arcana like the Internet Gateway Message Protocol (IGMP)
The participants in the process have mostly been engineers and computer scientists, including many from academia as well as the corporate world.
Consequently, despite often vociferous debates about ideal implementations, most serious IETF efforts have produced reasonable standards.
Unfortunately, that can’t be said of the IETF’s efforts to produce web (as opposed to Internet) standards.
In particular, the IETF’s early effort to standardize HTML was a colossal failure.
The refusal of Netscape and other key vendors to participate or even acknowledge the process was a crucial problem.
That HTML was simple enough and high profile enough to attract the attention of assorted market droids and random flamers didn’t help matters either.
Thus, in October 1994, the World Wide Web Consortium was formed as a vendor-controlled body that might be able to avoid the pitfalls that plagued the IETF’s efforts to standardize HTML and HTTP.
Whereas the IETF is open to participation by anyone, only corporations and other organizations may become members of.
Individuals are specifically excluded, though they may become invited experts on particular working groups.
However, the number of such individuals is quite small relative to the number of interested experts in the broader community.
Membership in the IETF costs $0 a year with no commitment beyond a willingness to participate.
Clearly, the IETF is a much more democratic (some would say anarchic) and open organization than the W3C.
Despite the W3C’s strong bias toward the corporate members that pay its bills, it has so far managed to do a better job of navigating the politically tricky waters of web standardization than the IETF.
It has produced several HTML standards, as well as a variety of others such as HTTP, PICS, XML, CSS, MathML, and more.
The W3C has had considerably less success in convincing vendors like Mozilla and Microsoft to fully and consistently implement its standards.
Notes will not necessarily lead to the formation of a working group or a W3C recommendation.
Working drafts A working draft is a reflection of the current thinking of some (not necessarily all) members of a working group.
It should eventually lead to a proposed recommendation, but by the time it does so it may have changed substantially.
Candidate recommendation A candidate recommendation indicates that the working group has reached consensus on all major issues and is ready for third-party comment and implementations.
If the implementations do not uncover any obstructions, the spec can be promoted to a candidate recommendation.
Proposed recommendation A proposed recommendation is mostly complete and unlikely to undergo more than minor editorial changes.
The main purpose of a proposed recommendation is to work out bugs in the specification document rather than in the underlying technology being documented.
Recommendation A recommendation is the highest level of W3C standard.
However, neither organization actually promises to do more than acknowledge receipt of these documents.
In particular, they do not promise to form a working group or begin the standardization process.
Nonetheless, press releases invariably misrepresent the submission of such a document as a far more significant event than it actually is.
However, you should recognize these ploys for what they are.
A large part of what network programs do is simple input and output: moving bytes from one system to another.
Bytes are bytes; to a large extent, reading data a server sends you is not all that different from reading a file.
Sending text to a client is not that different from writing a file.
However, input and output (I/O) in Java is organized differently than it is in most other languages, such as Fortran, C, and C++
Consequently, I’ll take a few pages to summarize Java’s unique approach to I/O.
Different stream classes, like java.io.FileInputStream and sun.net.TelnetOutput Stream, read and write particular sources of data.
However, all output streams have the same basic methods to write data and all input streams use the same basic methods to read data.
After a stream is created, you can often ignore the details of exactly what it is you’re reading or writing.
Filter streams can be chained to either an input stream or an output stream.
For instance, the java.io.DataOutputStream class provides a method that converts an int to four bytes and writes those bytes onto its underlying output stream.
Readers and writers can be chained to input and output streams to allow programs to read and write text (i.e., characters) rather than bytes.
Used properly, readers and writers can handle a wide variety of character encodings, including multibyte character sets such as SJIS and UTF-8
Streams are synchronous; that is, when a program (really a thread) asks a stream to read or write a piece of data, it waits for the data to be read or written before it does anything else.
Nonblocking I/O is a little more complicated, but can be much faster in some high-volume applications, such.
Normally, the basic stream model is all you need and all you should use for clients.
Because channels and buffers depend on streams, I’ll start with streams and clients and later discuss nonblocking I/O for use with servers in Chapter 11
This class provides the fundamental methods needed to write data.
Subclasses of OutputStream use these methods to write data onto particular media.
For instance, a FileOutputStream uses these methods to write data into a file.
A TelnetOutputStream uses these methods to write data onto a network connection.
A ByteArrayOutputStream uses these methods to write data into an expandable byte array.
But whichever medium you’re writing to, you mostly use only these same five methods.
Sometimes you may not even know exactly what kind of stream you’re writing onto.
For instance, you won’t find TelnetOutputStream in the Java class library documentation.
However, these methods are declared to return only OutputStream, not the more specific subclass TelnetOutputStream.
If you know how to use the superclass, you know how to use all the subclasses, too.
This method is declared abstract because subclasses need to change it to handle their particular medium.
For instance, a ByteArrayOutputStream can implement this method with pure Java code that copies the byte into its array.
However, a FileOutput Stream will need to use native code that understands how to write data in files on the host platform.
Take note that although this method takes an int as an argument, it actually writes an unsigned byte.
Java doesn’t have an unsigned byte data type, so an int has to be used here instead.
The only real difference between an unsigned byte and a signed byte is the interpretation.
They’re both made up of eight bits, and when you write an int onto a network connection using write(int b), only eight bits are placed on the wire.
If an int outside the range 0–255 is passed to write(int b), the least significant byte of the.
This is the effect of casting an int to a byte.)
For example, the character-generator protocol defines a server that sends out ASCII text.
The most popular variation of this protocol sends 72-character lines containing printable ASCII characters.
Most of the arithmetic here is to make the loop rotate in that range.
After each 72-character chunk is written, a carriage return and a linefeed are written onto the output stream.
The next start character is calculated and the loop repeats.
That’s important because the character-generator server will terminate only when the client closes the connection.
Writing a single byte at a time is often inefficient.
For example, every TCP segment contains at least 40 bytes of overhead for routing and error correction.
That is, they accumulate bytes in memory and send them to their eventual destination only when a certain number have accumulated or a certain amount of time has passed.
However, if you have more than one byte ready to go, it’s not a bad idea to send them all at once.
The algorithm for calculating which bytes to write when is the same as for the previous implementation.
The crucial difference is that the bytes are packed into a byte array before being written onto the network.
Also, notice that the int result of the calculation must be cast to a byte before being stored in the array.
This wasn’t necessary in the an int as an argument.
Streams can also be buffered in software, directly in the Java code as well as in the network hardware.
Typically, this is accomplished by chaining a BufferedOutput Stream or a BufferedWriter to the underlying stream, a technique we’ll explore shortly.
Consequently, if you are done writing data, it’s important to flush the output stream.
You generally want to wait for a response before sending any more data.
However, if the output stream has a 1,024-byte buffer, the stream may be waiting for more data to arrive before it sends the data out of its buffer.
Data can get lost if you don’t flush your streams.
It’s important to flush your streams whether you think you need to or not.
Depending on how you got hold of a reference to the stream, you may or may not know whether it’s buffered.
For instance, System.out is buffered whether you want it to be or not.) If.
Failing to flush when you need to can lead to unpredictable, unrepeatable program hangs that are extremely hard to diagnose if you don’t have a good idea of what the problem is in the first place.
As a corollary to all this, you should flush all streams immediately before you close them.
Otherwise, data left in the buffer when the stream is closed may get lost.
If the stream derives from a network connection, then closing the stream terminates the connection.
Once an output stream has been closed, further writes to it throw IOExcep tions.
However, some kinds of streams may still allow you to do things with the object.
For instance, a closed ByteArrayOutputStream can still be converted to an actual byte array and a closed DigestOutputStream can still return its digest.
Failure to close a stream in a long-running program can leak file handles, network ports, and other resources.
Consequently, in Java 6 and earlier, it’s wise to close the stream in a finally block.
To get the right variable scope, you have to declare the stream variable outside the try block but initialize it inside the try block.
Furthermore, to avoid Null PointerExceptions you need to check whether the stream variable is null before closing it.
Finally, you usually want to ignore or at most log any exceptions that occur while closing the stream.
This technique is sometimes called the dispose pattern; and it’s common for any object that needs to be cleaned up before it’s garbage collected.
You’ll see it used not just for streams, but also for sockets, channels, JDBC connections and statements, and more.
Java 7 introduces the try with resources construct to make this cleanup neater.
Instead of declaring the stream variable outside the try block, you declare it inside an argument list of the try block.
For instance, the preceding fragment now becomes the much simpler:
AutoCloseable objects declared inside the argument list of the try block.
So far, JavaMail Transport objects are only exceptions I’ve encountered.
This class provides the fundamental methods needed to read data as raw bytes.
Concrete subclasses of InputStream use these methods to read data from particular media.
But whichever source you’re reading, you mostly use only these same six methods.
Sometimes you don’t know exactly what kind of stream you’re reading from.
For instance, TelnetInputStream is an undocumented class hidden inside the sun.net return only InputStream, not the more specific subclass TelnetInputStream.
The instance of the subclass can be used transparently as an instance of its superclass.
Input and output can be slow, so if your program is doing anything else of importance, try to put I/O in its own thread.
For instance, a ByteArrayInputStream can implement this method with pure Java code that copies the byte from its array.
However, a TelnetInputStream needs to use a native library that understands how to read data from the network interface on the host platform.
The following code fragment reads 10 bytes from the InputStream in and stores them in the byte array input.
However, if end of stream is detected, the loop is terminated early:
Of course, this produces a signed byte from –128 to as long as you’re clear about which one you’re working with, this is not a major problem.
You can convert a signed byte to an unsigned byte like this:
Reading a byte at a time is as inefficient as writing data one byte at a time.
The first method attempts to fill the specified array input.
The second attempts to fill the specified subarray of input, starting at offset and continuing for length bytes.
Notice I said these methods attempt to fill the array, not that they necessarily succeed.
For instance, it’s not unheard of that while your program is reading data from a remote web server over DSL, a bug in a switch at a phone company central office will disconnect you and several hundred of your neighbors from the rest of the world.
More commonly, however, a read attempt won’t completely fail but won’t completely succeed either.
Some of the requested bytes may be read, but not all of them.
They’ll arrive eventually, but they aren’t available at this moment.
To account for this, the multibyte read methods return the number of bytes actually read.
It attempts to read 1,024 bytes from the InputStream in into the array input.
To guarantee that all the bytes you want are actually read, place the read in a loop that reads repeatedly until the array is filled.
Chances are that if a file is available at all, all the bytes of a file are also available.
However, because networks move much more slowly than CPUs, it is very easy for a program to empty a network buffer before all the data has arrived.
In fact, if one of these two methods tries to read from a temporarily empty but open network buffer, it will generally return 0, indicating that no data is available but the stream is not yet closed.
The previous code fragment had a bug because it didn’t consider the possibility that all 1,024 bytes might never arrive (as opposed to not being immediately available)
If you do not want to wait until all the bytes you need are immediately available, you blocking.
This returns the minimum number of bytes you can read.
In this case, you can expect that bytesRead is exactly equal to bytesAvailable.
You cannot, however, expect that bytesRead is greater than zero.
It’s less useful on network connections than when reading from files.
Network connections are sequential and normally quite slow, so it’s not significantly more time consuming to read data than to skip over it.
Files are random access so that skipping can be implemented simply by repositioning a file pointer rather than processing each byte to be skipped.
As with output streams, once your program has finished with an input stream, it should stream, such as file handles or ports.
Once an input stream has been closed, further reads from it throw IOExceptions.
However, some kinds of streams may still allow you to do things with the object.
For instance, you generally won’t retrieve the message digest from a java.security.DigestInputStream until after the data has been read and the stream closed.
Marking and Resetting The InputStream class also has three less commonly used methods that allow programs to back up and reread data they’ve already read.
Subsequent reads then return data starting from the marked position.
However, you may not be able to reset as far back as you like.
The number of bytes you can read from the mark and still reset is determined by the readAheadLimit argument to can be only one mark in a stream at any given time.
Marking and resetting are usually implemented by storing every byte read from the marked position on in an internal buffer.
In practice, more streams don’t support marking and resetting than do.
Attaching functionality to an abstract superclass that is not available to many, probably most, subclasses is a very poor idea.
It would be better to place these three methods in a separate interface that could be implemented by those classes that provided this functionality.
The disadvantage of this approach is that you couldn’t then invoke these methods on an arbitrary input stream of unknown type; but in practice, you can’t do that anyway because not all streams support marking and resetting.
An object-oriented approach would embed this in the type system through interfaces and classes so that it could all be checked at compile time.
The only input stream classes in java.io that always support marking are BufferedIn putStream and ByteArrayInputStream.
However, other input streams such as Telne tInputStream may support marking if they’re chained to a buffered input stream first.
They read and write bytes singly or in groups, but that’s all.
However, there are certain extremely common data formats that can benefit from a solid implementation in the class library.
For example, many integers passed as parts of network protocols are 32-bit big-endian integers.
Many files transferred by FTP are stored in the ZIP format.
Java provides a number of filter classes you can attach to raw streams to translate the raw bytes to and from these and other formats.
The filters come in two versions: the filter streams, and the readers and writers.
The filter streams still work primarily with raw data as bytes: for instance, by compressing the data or interpreting it as binary numbers.
Filters are organized in a chain, as shown in Figure 2-2
Each link in the chain receives data from the previous filter or stream and passes the data along to the next link in the.
In this example, a compressed, encrypted text file arrives from the local network interface, where native code presents it to the undocumented TelnetInputStream.
A BufferedInputStream buffers the data to speed up the entire process.
Finally, the text is read into the application and processed.
The filtering is purely internal and does not expose any new public interface.
Chaining Filters Together Filters are connected to streams by their constructors.
For example, the following code fragment buffers input from the file data.txt.
First, a FileInputStream object fin is created by passing the name of the file as an argument to the FileInputStream constructor.
Then, a BufferedInputStream object bin is created by passing fin as an argument to the BufferedInputStream constructor:
However, intermixing calls to different streams connected to the same source may violate several implicit contracts of the filter streams.
Most of the time, you should only use the last filter in the chain to do the actual reading or writing.
One way to write your code so that it’s at least harder to introduce this sort of bug is to deliberately overwrite the reference to the underlying input stream.
After these two lines execute, there’s no longer any way to access the underlying file input stream, so you can’t accidentally read from it and corrupt the buffer.
This example works because it’s not necessary to distinguish between the methods of InputStream and those of BufferedInputStream given that BufferedInputStream is simply used polymorphically as an instance of InputStream.
In cases where it is necessary to use the additional methods of the filter stream not declared in the superclass, you may be able to construct one stream directly inside another.
Although these statements can get a little long, it’s easy to split the statement across several lines, like this:
There are times when you may need to use the methods of multiple filters in a chain.
Or, if you’re connecting to a web server, you may want to read the header the server sends to find the Content-encoding and then use that content encoding to pick the right Reader filter to read the body of the response.
Or perhaps you want to send floating-point numbers across a network connection using a DataOutputStream and then retrieve a MessageDigest from the DigestOutputStream that the DataOut putStream is chained to.
In all these cases, you need to save and use references to each of the underlying streams.
However, under no circumstances should you ever read from or write to anything other than the last filter in the chain.
Buffered Streams The BufferedOutputStream class stores written data in a buffer (a protected byte array field named buf) until the buffer is full or the stream is flushed.
Then it writes the data onto the underlying output stream all at once.
A single write of many bytes is almost always much faster than many small writes that add up to the same thing.
This is especially true of network connections because each TCP segment or UDP packet carries a finite amount of overhead, generally about 40 bytes’ worth.
Most network cards and TCP implementations provide some level of buffering themselves, so the real numbers aren’t quite this dramatic.
Nonetheless, buffering network output is generally a huge performance win.
The BufferedInputStream class also has a protected byte array named buf that serves requested data from the buffer.
Only when the buffer runs out of data does the stream read from the underlying source.
At this point, it reads as much data as it can from the source into the buffer, whether it needs all the data immediately or not.
Data that isn’t from a local disk, it’s almost as fast to read several hundred bytes of data from the underlying stream as it is to read one byte of data.
The gain is less obvious on network connections where the bottleneck is often the speed at which the network can deliver data rather than the speed at which the network interface delivers data to the program or the speed at which the.
Nonetheless, buffering input rarely hurts and will become more important over time as network speeds increase.
The first argument is the underlying stream from which unbuffered data will be read or to which buffered data will be written.
The second argument, if present, specifies the number of bytes in the buffer.
The ideal size for a buffer depends on what sort of stream you’re buffering.
For network connections, you want something a little larger than the typical packet size.
However, this can be hard to predict and varies depending on local network connections and protocols.
Faster, higher-bandwidth networks tend to use larger packets, although TCP segments are often no larger than a kilobyte.
BufferedInputStream does not declare any new methods of its own.
The two multibyte reading from the underlying input stream as many times as necessary.
They return only when the array or subarray has been completely filled, the end of stream is reached, or the underlying stream would block on further reads.
They read from the underlying stream or data source only once before returning.
BufferedOutputStream also does not declare any new methods of its own.
You invoke its methods exactly as you would in any output stream.
The difference is that each write places data in the buffer rather than directly on the underlying output stream.
Consequently, it is essential to flush the stream when you reach a point at which the data needs to be sent.
PrintStream The PrintStream class is the first filter output stream most programmers encounter because System.out is a PrintStream.
However, other output streams can also be chained to print streams, using these two constructors:
However, if the autoFlush argument is true, the stream will be flushed every time a byte array or linefeed is written or.
The separator to the end of the line they write.
PrintStream is evil and network programmers should avoid it like the plague!
This doesn’t cause problems when writing to the console, but it’s a disaster for writing network clients and servers that must follow a precise protocol.
Most network protocols such as HTTP and Gnutella specify that it easy to write a program that works on Windows but fails on Unix and the Mac.
Although many servers and clients are liberal in what they accept and can handle incorrect line terminators, there are occasional exceptions.
The second problem is that PrintStream assumes the default encoding of the platform on which it’s running.
However, this encoding may not be what the server or client expects.
For example, a web browser receiving XML files will expect them to be encoded.
However, a web server that uses PrintStream may well send the files encoded in CP1252 from a U.S.-localized Windows system or SJIS from a Japanese-localized system, whether the client expects or understands those encodings or not.
PrintStream doesn’t provide any mechanism for changing the default encoding.
This problem can be patched over by using the related Print Writer class instead.
This makes PrintStream suitable for textbook programs such as HelloWorld, because simple console output can be taught without burdening students with first learning about exception handling and all that implies.
However, network connections are much less reliable than the console.
Connections routinely fail because of network congestion, phone company misfeasance, remote systems crashing, and many other reasons.
Network programs must be prepared to deal with unexpected interruptions in the flow of data.
However, PrintStream catches any exceptions thrown by the underlying output stream.
Notice that the declaration of the standard five Output Stream methods in PrintStream does not have the usual throws IOException declaration:
Instead, PrintStream relies on an outdated and inadequate error flag.
If the underlying stream throws an exception, this internal error flag is set.
To do any error checking at all on a PrintStream, the code must explicitly check every call.
Furthermore, once an error has occurred, there is no way to unset the flag so further errors can be detected.
In short, the error notification provided by PrintStream is wholly inadequate for unreliable network connections.
Data Streams The DataInputStream and DataOutputStream classes provide methods for reading and writing Java’s primitive data types and strings in a binary format.
The binary formats used are primarily intended for exchanging data between two different Java programs through a network connection, a datafile, a pipe, or some other intermediary.
What a data output stream writes, a data input stream can read.
However, it happens that the formats are the same ones used for most Internet protocols that exchange binary numbers.
For instance, the time protocol uses 32-bit big-endian integers, just like Java’s int.
Both Java and most network protocols were designed by Unix programmers, and consequently both tend to use the formats common to most Unix systems.) However, this isn’t true for all network protocols, so check the details of any protocol you use.
The DataOutputStream class offers these 11 methods for writing particular Java data types:
Integers are written in two’s complement in the minimum number of bytes possible.
Thus, a byte is written as one byte, a short as two bytes, an int as four bytes, and a long as eight bytes.
Floats and doubles are written in IEEE 754 form in four and eight bytes, respectively.
This method may be useful on some network protocols that specify the ASCII encoding, but it should be avoided most of the time.
As a result, you can’t really distinguish between raw characters and characters string.
It encodes the string itself in a variant of the UTF-8 encoding of Unicode.
Because this variant is subtly incompatible with most non-Java software, it should be used only for exchanging data with other Java programs that use a DataInputStream to read.
For exchanging UTF-8 text with all other software, you should use an Input StreamReader with the appropriate encoding.
Along with these methods for writing binary numbers and strings, DataOutput Stream class has.
In addition, DataInputStream for reading complete arrays of bytes and lines of text.
In addition, DataInputStream provides two methods to read unsigned bytes and unsigned shorts and return the equivalent int.
Java doesn’t have either of these data types, but you may encounter them when reading binary data written by a C program:
If enough data cannot be read, then an IOException is thrown.
These methods are especially useful when you know in advance exactly how many bytes you have to read.
This might be the case when you’ve read the Content-length field out of an HTTP header and thus know how many bytes of data there are:
However, this method should not be used under any circumstances, both because it is deprecated and because it is buggy.
It’s deprecated because it doesn’t properly convert non-ASCII characters to bytes in most circumstances.
That task is now handled by the share the same insidious bug: they do not always recognize a single carriage return as the next character is a linefeed before continuing.
If it is a linefeed, the carriage return and the linefeed are thrown away and the line is returned as a String.
If it isn’t a linefeed, the carriage return is thrown away, the line is returned as a String, and the extra character that was read becomes part of the next line.
This problem isn’t obvious when reading files because there will almost certainly be a next character: –1 for end of stream, if nothing else.
However, on persistent network connections such as those used for FTP and late-model HTTP, a server or client may simply stop sending data after the last character and wait for a response without actually closing the connection.
If you’re lucky, the connection may eventually time out on one end or the other and you’ll get an IOException, although this will probably take at least a couple of minutes, and cause you to lose the last line of data from the stream.
Readers and Writers Many programmers have a bad habit of writing code as if all text were ASCII or at least in the native encoding of the platform.
Java’s native character set is the UTF-16 encoding of Unicode.
When the encoding is no longer ASCII, the assumption that bytes and chars are essentially the same things also breaks down.
Consequently, Java provides an almost complete mirror of the input and output stream class hierarchy designed for working with characters instead of bytes.
In this mirror image hierarchy, two abstract superclasses define the basic API for reading and writing characters.
The java.io.Reader class specifies the API by which characters are read.
The java.io.Writer class specifies the API by which characters are written.
Wherever input and output streams use bytes, readers and writers use Unicode characters.
Concrete subclasses of Reader and Writer allow particular sources to be read and targets to be written.
Filter readers and writers can be attached to other readers and writers to provide additional services or interfaces.
The most important concrete subclasses of Reader and Writer are the InputStream Reader and the OutputStreamWriter classes.
An InputStreamReader contains an underlying input stream from which it reads raw bytes.
It translates these bytes into Unicode characters according to a specified encoding.
It then translates those characters into bytes using a specified encoding and writes the bytes onto an underlying output stream.
In addition to these two classes, the java.io package provides several raw reader and writer classes that read characters without directly requiring an underlying input stream, including:
The first two classes in this list work with files and the last four work inside Java, so they aren’t of great use for network programming.
However, aside from different constructors, these classes have pretty much the same public interface as all other reader and writer classes.
The write(char[] text, int offset, int length) method is the base method in like this:
The same task can be accomplished with these other methods, as well:
All of these examples are different ways of expressing the same thing.
The one you choose to use in any given situation is mostly a matter of convenience and taste.
However, how many and which bytes are written by these lines depends on the encoding w uses.
After a writer has been closed, further writes throw IOExceptions.
OutputStreamWriter OutputStreamWriter is the most important concrete subclass of Writer.
It converts these into bytes according to a specified encoding and writes them onto an underlying output stream.
Its constructor specifies the output stream to write to and the encoding to use:
Valid encodings are listed in the documentation for Sun’s native2ascii tool included with the JDK.
If no encoding is specified, the default encoding for the platform is used.
However, on Linux it can vary if the local operating system is configured to use some other character set by default.
Default character sets can cause unexpected problems at unexpected times.
You’re generally almost always better off explicitly specifying the character set rather than letting Java pick one for you.
For example, this code fragment writes the first few words of Homer’s Odyssey in the CP1253 Windows Greek encoding:
Other than the constructors, OutputStreamWriter has only the usual Writer methods (which are used exactly as they are for any Writer class) and one method to return the encoding of the object:
The read(char[] text, int offset, int length) method attempts to read length characters into the subarray of text beginning at offset and continuing for length characters.
It also returns the actual number of characters read or –1 on end of stream.
The problem is that some character encodings, such as UTF-8, use different numbers of bytes for different characters.
Thus, it’s hard to tell how many characters are waiting in the network or filesystem buffer without actually reading them out of the buffer.
An Input StreamReader reads bytes from an underlying input stream such as a FileInput Stream or TelnetInputStream.
It converts these into characters according to a specified encoding and returns them.
The constructor specifies the input stream to read from and the encoding to use:
If no encoding is specified, the default encoding for the platform is used.
If an unknown encoding is specified, an UnsupportedEncodingException is thrown.
For example, this method reads an input stream and converts it all to one Unicode string using the MacCyrillic encoding:
Filter Readers and Writers The InputStreamReader and OutputStreamWriter classes act as decorators on top of input and output streams that change the interface from a byte-oriented interface to a character-oriented interface.
Once this is done, additional character-oriented filters can be layered on top of the reader or writer using the java.io.FilterReader and java.io.FilterWriter classes.
As with filter streams, there are a variety of subclasses that perform specific filtering, including:
The BufferedReader and BufferedWriter classes are the character-based equivalents of the byte-oriented BufferedInputStream and BufferedOutputStream classes.
Where BufferedInputStream and BufferedOutputStream use an internal array of bytes as a buffer, BufferedReader and BufferedWriter use an internal array of chars.
When a program reads from a BufferedReader, text is taken from the buffer rather than directly from the underlying input stream or other text source.
When the buffer empties, it is filled again with as much text as possible, even if not all of it is immediately needed, making future reads much faster.
When a program writes to a BufferedWriter, the text is placed in the buffer.
The text is moved to the underlying output stream or other target only when the buffer fills up or when the writer is explicitly flushed, which can make writes much faster than would otherwise be the case.
BufferedReader and BufferedWriter have the usual methods associated with readers.
If the size is not set, the default size of 8,192 characters is used:
However, it’s straightforward to make it run faster by chaining a BufferedReader to the InputStreamReader, like this:
All that was needed to buffer this method was one additional line of code.
None of the rest of the algorithm had to change, because the only InputStreamReader methods used all Reader subclasses, including BufferedReader.
The big difference is that by chaining a BufferedReader to an InputStreamReader, you can correctly read lines in character sets other than the default encoding for the platform.
This method inserts a platform-dependent line-separator string into the output.
The line.separator system property determines exactly what the string is: probably a linefeed on Unix and Mac OS X, and a carriage return/linefeed pair on Windows.
Because network protocols generally specify the required line terminator, you should not use this method for network programming.
More often than not, the required terminator is a carriage return/ linefeed pair.
PrintWriter The PrintWriter class is a replacement for Java 1.0’s PrintStream class that properly handles multibyte character sets and international text.
Sun originally planned to deprecate PrintStream in favor of PrintWriter but backed off when it realized this step would invalidate too much existing code, especially code that depended on Sys tem.out.
Aside from the constructors, the PrintWriter class has an almost identical collection of methods to PrintStream.
Most of these methods behave the same for PrintWriter as they do for PrintStream.
PrintStream class, but it’s still not good enough for network programming.
Unfortunately, PrintWriter still has the problems of platform dependency and minimal error reporting that plague PrintStream.
This chapter has been a whirlwind tour of the java.io package, covering the bare minimum you need to know to write network programs.
For a more detailed and comprehensive look with many more examples, check out my other book in this series, Java I/O (O’Reilly)
Back in the good old days of the Net, circa the early 1990s, we didn’t have the Web and HTTP and graphical browsers.
Instead, we had Usenet news and FTP and commandline interfaces, and we liked it that way! But as good as the good old days were, there were some problems.
For instance, when we were downloading kilobytes of free software from a popular FTP site over our 2,400 bps modems using Kermit, we would often encounter error messages like this one:
In fact, in the days when the Internet had only a few million users instead of a few billion, we were far more likely to come across an overloaded and congested site than we are today.
Because processes are fairly heavyweight items, too many could rapidly bring a server to its knees.
The problem wasn’t that the machines weren’t powerful enough or the network fast enough; it was that the FTP servers were poorly implemented.
Many more simultaneous users could be served if a new process wasn’t needed for each connection.
Early web servers suffered from this problem as well, although the problem was masked a little by the transitory nature of HTTP connections.
The fundamental problem is that while it’s easy to write code that handles each incoming connection and each new task as a separate process (at least on Unix), this solution doesn’t scale.
By the time a server is attempting to handle a thousand or more simultaneous connections, performance slows to a crawl.
The first is to reuse processes rather than spawning new ones.
When the server starts up, a fixed number of processes (say, 300) are spawned to handle requests.
Each process removes one request from the queue, services the request, then returns to the queue to get the next request.
Your exact mileage may vary, especially if your server hasn’t yet reached the volume where scalability issues come into play.
Still, whatever mileage you get out of spawning new processes, you should be able to do much better by reusing old processes.
The second solution to this problem is to use lightweight threads instead of heavyweight processes to handle connections.
Whereas each separate process has its own block of memory, threads are easier on resources because they share memory.
Using threads instead of processes can buy you another factor of three in server performance.
By combining this with a pool of reusable threads (as opposed to a pool of reusable processes), your server can run nine times faster, all on the same hardware and network connection! The impact of running many different threads on the server hardware is relatively minimal because they all run within one process.
However, by using a thread pool instead of spawning new threads for each connection, fewer than a hundred threads can handle thousands of short connections per minute.
Alternatives to Threading If an application needs thousands of simultaneous long-lived connections (and that’s a pretty rare application) it’s time to start thinking about asynchronous I/O instead of threads.
Selectors enable one thread to query a group of sockets to find out which ones are ready to be read from or written to, and then process the ready sockets sequentially.
In this case, the I/O has to be designed around channels and buffers rather than streams.
Given the high performance of threads in modern virtual machines and operating systems, as well as the relative simplicity of a building a thread-based server, a thread-based design is usually where you should start until you can prove you’re hitting a wall.
If you do hit a wall, you should seriously consider sharding the application across multiple.
Of course, sharding introduces design issues of its own, particularly around consistency, that aren’t present in a single system.
But it does offer you more scalability and redundancy than you’ll ever get out of a single system, no matter how efficiently implemented.
In particular, multithreaded servers (and other multithreaded programs) require developers to address concerns that aren’t issues for single-threaded programs, particularly issues of safety and liveness.
Because different threads share the same memory, it’s entirely possible for one thread to stomp all over the variables and data structures used by another thread.
This is similar to the way one program running on a nonmemory-protected operating system such as Windows 95 can crash the entire system.
Consequently, different threads have to be extremely careful about which resources they use when.
Generally, each thread must agree to use certain resources only when it’s sure those resources can’t change or that it has exclusive access to them.
However, it’s also possible for two threads to be too careful, each waiting for exclusive access to resources it will never get.
This can lead to deadlock, in which two threads are each waiting for resources the other possesses.
Neither thread can proceed without the resources that the other thread has reserved, but neither is willing to give up the resources it has already.
Running Threads A thread with a little t is a separate, independent path of execution in the virtual machine.
A Thread with a capital T is an instance of the java.lang.Thread class.
There is a oneto-one relationship between threads executing in the virtual machine and Thread objects constructed by the virtual machine.
Most of the time it’s obvious from the context which one is meant if the difference is really important.
To start a new thread running in the virtual machine, you construct an instance of the.
Of course, this thread isn’t very interesting because it doesn’t have anything to do.
To give a thread something to do, you either subclass the Thread class and override its the Thread constructor.
I generally prefer the second option because it separates the task that the thread performs from the thread itself more cleanly, but you will see both which has this signature:
You’re going to put all the work the thread does in this one method.
This method may invoke other methods; it may construct other objects; it may even spawn other threads.
A single-threaded program exits when the background tasks such as garbage collection and don’t prevent the virtual machine from exiting.)
Subclassing Thread Consider a program that calculates the Secure Hash Algorithm (SHA) digest for many files.
To a large extent, this is an I/O-bound program (i.e., its speed is limited by the amount of time it takes to read the files from the disk)
If you write it as a standard program that processes the files in series, the program is going to spend a lot of time waiting for the hard drive to return the data.
This limit is even more characteristic of network programs: they execute faster than the network can supply input.
This is time that other threads could use, either to process other input sources or to do something that doesn’t rely on slow input.
Sometimes, even if none of the threads have a lot of spare time to allot to other threads, it’s simply easier to design a program by breaking it into multiple threads that perform independent operations.)
It does this by reading the file with a DigestInput Stream.
This filter stream calculates a cryptographic hash function as it reads the file.
Then the resulting digest is printed on System.out in hexadecimal encoding.
Notice that the entire output from this thread is first built in a local StringBuilder variable result.
This is then printed on the console with one method invocation.
The more obvious path of printing the pieces one at a time soon.
Consequently, you need different ways to pass information into the thread and get information out of it.
The simplest way to pass information in is to pass arguments to the constructor, which sets fields in the Thread subclass, as done here.
Getting information out of a thread back into the original calling thread is trickier because of the asynchronous nature of threads.
Example 3-1 sidesteps that problem by never passing any information back to the calling thread and simply printing the results on System.out.
Most of the time, however, you’ll want to pass the information to other parts of the program.
You can store the result of the calculation in a field and provide a getter method to return the value of that field.
However, how do you know when the calculation of that value is complete? What do you return if somebody calls the getter.
Implementing the Runnable Interface One way to avoid overriding the standard Thread methods is not to subclass Thread.
Instead, write the task you want the thread to perform as an instance of the Runnable.
Other than this method, which any class implementing this interface must provide, you are completely free to create any other methods with any other names you choose, all without any possibility of unintentionally interfering with the behavior of the thread.
This also allows you to place the thread’s task in a subclass of some other class, such as Applet or HTTPServlet.
To start a thread that performs the Runnable’s task, pass the Runnable object to the Thread constructor.
It’s easy to recast most problems that subclass Thread into Runnable forms.
Aside from the name change, the only modifications that are necessary are changing extends Thread to implements Runnable and passing a logic of the program is unchanged.
There’s no strong reason to prefer implementing Runnable to extending Thread or vice versa in the general case.
In a few special cases, such as Example 3-14 later in this chapter, it may be useful to invoke some instance methods of the Thread class from within the constructor for each Thread object.
In other specific class, such as HTTPServlet, in which case the Runnable interface is essential.
Finally, some object-oriented purists argue that the task that a thread undertakes is not really a kind of Thread, and therefore should be placed in a separate class or interface such as Runnable rather than in a subclass of Thread.
I half agree with them, although I don’t think the argument is as strong as it’s sometimes made out to be.
Consequently, I’ll mostly use the Runnable interface in this book, but you should feel free to do whatever seems most convenient.
Returning Information from a Thread One of the hardest things for programmers accustomed to traditional, single-threaded procedural models to grasp when moving to a multithreaded environment is how to return information from a thread.
Getting information out of a finished thread is one of the most commonly misunderstood aspects of multithreaded programming.
Example 3-3 is a Thread subclass that calculates a digest for a specified file.
Example 3-4 is a simple command-line user interface that receives filenames and spawns threads to calculate digests for them.
A thread that uses an accessor method to return the result.
A main program that uses the accessor method to get the output of the thread.
The ReturnDigest class stores the result of the calculation in the private field digest, face loops through a list of files from the command line.
The problem is that the main program gets the digest and uses it before the thread has throws a NullPointerException.
If you’re lucky, this will work and you’ll get the expected output, like this:
Whether this code works is completely dependent on whether every one of the ReturnDigest threads finishes before is entered before the threads spawned by the first loop start finishing, you’re back where you started.
Worse yet, the program may appear to hang with no output at all, not even a stack trace.
Whether you get the correct results, an exception, or a hung program depends on many factors, including how many threads the program spawns, the speed of the CPU and disk on the system where this is run, how many CPUs the system uses, and the algorithm the Java virtual machine uses to allot time to different threads.
Getting the correct result depends on the relative speeds of different threads, method isn’t called until the digest is ready.
Polling The solution most novices adopt is to make the getter method return a flag value (or perhaps throw an exception) until the result field is set.
Then the main thread periodically polls the getter method to see whether it’s returning something other than the flag value.
In this example, that would mean repeatedly testing whether the digest is null and using it only if it isn’t.
If it works at all, it gives the correct answers in the correct order irrespective of how fast the individual threads run relative to each other.
However, it’s doing a lot more work than it needs to.
On some virtual machines, the main thread takes all the time available and leaves no time for the actual worker threads.
The main thread is so busy checking for job completion that there’s no time left to actually complete the job! Clearly this isn’t a good approach.
Callbacks In fact, there’s a much simpler, more efficient way to handle the problem.
The infinite loop that repeatedly polls each ReturnDigest object to see whether it’s finished can be eliminated.
It does this by invoking a method in the main class that started it.
This is called a callback because the thread calls its creator back when it’s done.
This way, the main program can go to sleep while waiting for the threads to finish and not steal time from the running threads.
Rather than the main program asking each thread for the answer, each thread tells the main program the answer.
For instance, Example 3-5 shows a CallbackDigest class that is much the same as before.
It does not attempt to actually read, print out, or in any other way work with the results of the.
However, it’s not much harder (and it’s considerably more common) to call back to an instance method.
In this case, the class making the callback must have a reference to the object it’s calling back.
Generally, this reference is provided as an argument to the invoke the instance method on the callback object to pass along the result.
For instance, Example 3-7 shows a CallbackDigest class that is much the same as before.
However, it now has one additional field, an InstanceCallbackDigestUserInterface object is set in the constructor.
The InstanceCallbackDigestUserInterface class shown in Example 3-8 holds the digest.
Example 3-8 just prints out the digest, but a more expansive class could do other things as well, such as storing the digest in a field, using it to start another thread, or performing further calculations on it.
Using instance methods instead of static methods for callbacks is a little more complicated but has a number of advantages.
First, each instance of the main class (Instance CallbackDigestUserInterface, in this example) maps to exactly one file and can keep track of information about that file in a natural way without needing extra data structures.
Furthermore, the instance can easily recalculate the digest for a particular file, if necessary.
However, there is one might logically think that this belongs in a constructor.
However, starting threads in a constructor is dangerous, especially threads that will call back to the originating object.
There’s a race condition here that may allow the new thread to call back before the constructor is finished and the object is fully initialized.
It’s unlikely in this case, because starting the new thread is the last thing this constructor does.
Therefore, it’s good form to avoid launching threads from constructors.
The first advantage of the callback scheme over the polling scheme is that it doesn’t waste so many CPU cycles.
However, a much more important advantage is that callbacks are more flexible and can handle more complicated situations involving many more threads, objects, and classes.
For instance, if more than one object is interested in the result of the thread’s calculation, the thread can keep a list of objects to call back.
Particular objects can register their interest by invoking a method in the Thread or Runna ble class to add themselves to the list.
If instances of more than one class are interested in the result, a new interface can be defined that all these classes implement.
If you’re experiencing déjà vu right now, that’s probably because you have seen this scheme before.
This is exactly how events are handled in Swing, the AWT, and JavaBeans.
The AWT runs in a separate thread from the rest of the program.
Components and beans inform you of events by calling back to methods declared in particular interfaces, such as ActionListener and PropertyChangeListener.
Your listener objects register their interests in events fired by particular components using methods in the Compo the component, the registered listeners are stored in a linked list built out of java.awt.AWTEventMulticaster objects.
More generally this is known as the Observer design pattern.
Futures, Callables, and Executors Java 5 introduced a new approach to multithreaded programming that makes it somewhat easier to handle callbacks by hiding the details.
Instead of directly creating a thread, you create an ExecutorService that will create threads for you as needed.
You submit Callable jobs to the ExecutorService and for each one you get back a Future.
At a later point, you can ask the Future for the result of the job.
If it’s not ready, the polling thread blocks until it is ready.
The advantage is that you can spawn off many different threads, then get the answers you need in the order you need them.
For example, suppose you need to find the maximum value in a large array of numbers.
Implemented naively, this takes O(n) time where n is the number of elements in the array.
However, you can go faster than that if you split the work into multiple threads, each running on a separate core.
For purposes of illustration, let’s assume two threads are desired.
Example 3-9 is a Callable that finds the maximum value in a subsection of an array in the most obvious way possible.
Each subarray is searched at the same time, so on suitable hardware and a large input this program can run almost twice as fast.
Nonetheless, the code is almost as simple and straightforward as finding the maximum in the first half of the array and then finding the maximum in the second half of the array, without ever worrying about threads or asynchronicity.
Once both threads have finished, their results are compared and the maximum is returned.
Futures are a very convenient means of launching multiple threads to work on different pieces of a problem, and then waiting for them all to finish before proceeding.
Executors and executor services let you assign jobs to different threads with different strategies.
This example used just two threads once each, but it’s possible to use many more threads, and to reuse threads for multiple tasks.
Executors hide a lot of the nitty-gritty details of asynchronicity as long as you can divide your job up into reasonably independent parts.
Synchronization My shelves are overflowing with books, including many duplicate books, out-of-date books, and books I haven’t looked at for 10 years and probably never will again.
Over the years, these books have cost me tens of thousands of dollars, maybe more, to acquire.
By contrast, two blocks down the street from my apartment, you’ll find the Central Brooklyn Public Library.
Its shelves are also overflowing with books, and over its 100 years, it’s spent millions on its collection.
But the difference is that its books are shared among all the residents of Brooklyn, and consequently the books have very high turnover.
Most books in the collection are used several times a year.
Although the public library spends a lot more money buying and storing books than I do, the cost per page read is much lower at the library than for my personal shelves.
If I need a book from the library, I have to walk over there.
I have to find the book I’m looking for on the shelves.
I have to stand in line to check the book out, or else I have to use it right there in the library rather than bringing it home with me.
Sometimes somebody else has checked the book out, and I have to fill out a form requesting that the book be saved for me when it’s returned.
And I can’t write notes in the margins, highlight paragraphs, or tear pages out to paste on my bulletin board.
Well, I can, but if I do, it significantly reduces the usefulness of the book for future borrowers, and if the library catches me, I may lose my borrowing privileges.) There’s a significant time and convenience penalty associated with borrowing a book from the library rather than purchasing my own copy, but it does save me money and storage space.
A thread is like a borrower at a library; the thread borrows from a central pool of resources.
Threads make programs more efficient by sharing memory, file handles, sockets, and other resources.
As long as two threads don’t want to use the same resource at the same time, a multithreaded program is much more efficient than the multiprocess alternative, in which each process has to keep its own copy of every resource.
The downside of a multithreaded program is that if two threads want the same resource at.
As previously mentioned, the method builds the result as a String, and then prints the String on the console using one call to Sys.
The order in which the lines are written is unpredictable because thread scheduling is unpredictable, but each line is written as a unified whole.
Suppose, however, you used result in the String variable result, simply prints them on the console as they become available:
When you run the program on the same input, the output looks something like this:
The digests of the different files are all mixed up! There’s no telling which number belongs to which digest.
The reason this mix-up occurs is that System.out is shared between the four different threads.
When one thread starts writing to the console through several.
The exact order in which one thread preempts the other threads is indeterminate.
You’ll probably see slightly different output every time you run this program.
You need a way to assign exclusive access to a shared resource to one thread for a specific series of statements.
In this example, that shared resource is System.out, and the statements that need exclusive access are:
Synchronized Blocks To indicate that these five lines of code should be executed together, wrap them in a synchronized block that synchronizes on the System.out object, like this:
Once one thread starts printing out the values, all other threads will have to stop and wait for it to finish before they can print out their values.
Synchronization forces all code that synchronizes on the same object to run in series, never in parallel.
For instance, if some other code in a different class and different thread also happened to synchronize on System.out, it too would not be able to run in parallel with this block.
However, other code that synchronizes on a different object or doesn’t synchronize at all can still run in parallel with this code.
It can do so even if it also uses System.out.
Java provides no means to stop all other threads from using a shared resource.
It can only prevent other threads that synchronize on the same object from using the shared resource.
In fact, the PrintStream class internally synchronizes most methods on the PrintStream object (System.out, in this example)
In other synchronized on System.out and will have to wait for this code to finish.
Synchronization must be considered any time multiple threads share resources.
These threads may be instances of the same Thread subclass or use the same Runnable class, or they may be instances of completely different classes.
The key is the resources they share, not what classes they are.
Synchronization becomes an issue only when two threads both possess references to the same object.
In this case, it was a static class variable that led to the conflict.
The logfile may be represented by a class like the one shown in Example 3-11
However, if the web server uses multiple threads to handle incoming connections, then each of those threads will need access to the same logfile and consequently to the same LogFile object.
One thread may write the date and a tab, then the next thread might write three complete entries; then, the first thread could write the message, a carriage return, and a linefeed.
However, here there are two good choices for which object to synchronize on.
The first choice is to synchronize on the Writer object out.
This works because all the threads that use this LogFile object also use the same out object that’s part of that LogFile.
Although it is used method that needs to be protected from interruption.
The Writer classes all have their own internal synchronization, which protects one thread from interfering with a the exception of PrintStream.
It is possible for a write to an output stream to be interrupted by another thread.) Each Writer class has a lock field that specifies the object on which writes to that writer synchronize.
The second possibility is to synchronize on the LogFile object itself.
This is simple enough to arrange with the this keyword.
Synchronized Methods Because synchronizing the entire method body on the object itself is such a common thing to do, Java provides a shortcut.
You can synchronize an entire method on the current object (the this reference) by adding the synchronized modifier to the method declaration.
Simply adding the synchronized modifier to all methods is not a catchall solution for synchronization problems.
For one thing, it exacts a severe performance penalty in many VMs (though more recent VMs have improved greatly in this respect), potentially slowing down your code by a factor of three or more.
Third, and most importantly, it’s not always the object itself you need to protect from simultaneous modification or access, and synchronizing on the instance of the method’s class may not protect the object you really need to protect.
For instance, in this example, what you’re really trying to prevent is two threads simultaneously writing onto out.
If some other class had a reference to out completely unrelated to the LogFile, this attempt would fail.
However, in this example, synchronizing on the LogFile object is sufficient because out is a private instance variable.
Because you never expose a reference to this object, there’s no way for any other object to invoke its methods except through the LogFile class.
Therefore, synchronizing on the Log File object has the same effect as synchronizing on out.
Alternatives to Synchronization Synchronization is not always the best solution to the problem of inconsistent behavior caused by thread scheduling.
There are a number of techniques that avoid the need for synchronization entirely.
The first is to use local variables instead of fields wherever possible.
Every time a method is entered, the virtual machine creates a completely new set of local variables for the method.
These variables are invisible from outside the method and are destroyed when the method exits.
As a result, it’s impossible for one local variable to be shared by two different threads.
Every thread has its own separate set of local variables.
Method arguments of primitive types are also safe from modification in separate threads because Java passes arguments by value rather than by reference.
A corollary of this is arguments, perform some calculation, and return a value without ever interacting with the fields of any class are inherently thread safe.
These methods often either are or should be declared static.
Method arguments of object types are a little trickier because the actual argument passed by value is a reference to the object.
Suppose, for example, you pass a reference to an stop some other thread that also has a reference to the array from changing the values in the array.
String arguments are safe because they’re immutable (i.e., once a String object has been created, it cannot be changed by any thread)
The values of its fields are set once when the constructor runs and never altered thereafter.
StringBuilder arguments are not safe because they’re not immutable; they can be changed after they’re created.
A constructor normally does not have to worry about issues of thread safety.
Until the constructor returns, no thread has a reference to the object, so it’s impossible for two threads to have a reference to the object.
The most likely issue is if a constructor depends on another object in another thread that may change while the constructor runs, but that’s uncommon.
There’s also a potential problem if a constructor somehow passes a reference to the object it’s creating into a different thread, but this is also uncommon.)
You can take advantage of immutability in your own classes.
It’s usually the easiest way to make a class thread safe, often much easier than determining exactly which methods or code blocks to synchronize.
To make an object immutable, simply declare all its fields the core Java library are immutable (e.g., java.lang.String, java.lang.Integer, java.lang.Double, and many more)
This makes these classes less useful for some purposes, but it does make them a lot more thread safe.
A third technique is to use a thread-unsafe class but only as a private field of a class that is thread safe.
As long as the containing class accesses the unsafe class only in a threadsafe fashion and as long as it never lets a reference to the private field leak out into another object, the class is safe.
An example of this technique might be a web server that uses an unsynchronized LogFile class but gives each separate thread its own separate log so no resources are shared between the individual threads.
In some cases, you can use a designedly thread-safe but mutable class from the java.util.concurrent.atomic package.
In particular, rather than using an int, you can use an AtomicInteger.
Rather than using a long, you can use an AtomicLong.
Rather than using a boolean, you can use an AtomicBoolean.
Rather than using an int[], you can use an AtomicIntegerArray.
Rather than a reference variable, you can store an object inside an AtomicReference, though note well that this doesn’t make the object itself thread safe, just the getting and setting of the reference variable.
These classes may be faster than synchronized access to their respective primitive types if they can take advantage of fast machine-level thread-safe instructions on modern CPUs.
For collections such as maps and lists, you can wrap them in a thread-safe version using the methods of java.util.Collections.
For instance, if you have a set foo, you can get a thread-safe view of this set with Collections.synchronizedSet(foo)
If you have a list foo, you’d use Collections.synchronizedList(foo) instead.
In order for this to work, you must henceforth use only the view returned by Collections.synchronizedSet/List/Map.
If at any point you access the original, underlying data structure, neither the original nor the synchronized view will be thread safe.
In all cases, realize that it’s just a single method invocation that is atomic.
If you need to perform two operations on the atomic value in succession without possible interruption, you’ll still need to synchronize.
Thus, for instance, even if a list is synchronized via.
Although each method call is safely atomic, the sequence of operations is not without explicit synchronization.
Deadlock occurs when two threads need exclusive access to the same set of resources and each thread holds the lock on a different subset of those resources.
If neither thread is willing to give up the resources it has, both threads come to an indefinite halt.
This isn’t quite a hang in the classical sense because the program is still active and behaving normally from the perspective of the OS, but to a user the difference is insignificant.
If Jill has checked out the first book and Jack has checked out the second, and neither is willing to give up the book they have, neither can finish the paper.
Eventually, the deadline expires and they both get an F.
Most of the time, either Jack or Jill will get to the library first and check out both books.
In this case, the one who gets the books first writes a paper and returns the books; then the other one gets the books and writes his or her paper.
Only rarely will they arrive at the same time and each get one of the two books.
Of course, if a multithreaded server is handling hundreds of requests per second, even a problem that occurs only once every million requests can hang the server in short order.
The most important technique for preventing deadlock is to avoid unnecessary synchronization.
If there’s an alternative approach for ensuring thread safety, such as making objects immutable or keeping a local copy of an object, use it.
Synchronization should be a last resort for ensuring thread safety.
If you do need to synchronize, keep the synchronized blocks small and try not to synchronize on more than one object at a time.
This can be tricky, though, because many of the methods from the Java class library that your code may invoke synchronize on objects you aren’t aware of.
Consequently, you may in fact be synchronizing on many more objects than you expect.
The best you can do in the general case is carefully consider whether deadlock is likely to be a problem and design your code around it.
If multiple objects need the same set of shared resources to operate, make sure they request them in the same order.
If neither requests Y unless it already possesses X, deadlock is not a problem.
Thread Scheduling When multiple threads are running at the same time (more properly, when multiple threads are available to be run at the same time), you have to consider issues of thread scheduling.
You need to make sure that all important threads get at least some time to run and that the more important threads get more time.
Furthermore, you want to ensure that the threads execute in a reasonable order.
By that point, the user has likely gone to another page.
The reason this strategy works is that there’s a lot of dead time in servicing a typical web request, time in which the thread is simply waiting for the network to catch up with the CPU—time the VM’s thread scheduler can put to good use by other threads.
However, CPU-bound threads (as opposed to the I/O-bound threads more common in network programs) may never reach a point where they have to wait for more input.
It is possible for such a thread to starve all other threads by taking all the available CPU resources.
In fact, starvation is a considerably easier problem to avoid than either mis-synchronization or deadlock.
When multiple threads are ready to run, the VM will generally run only the highest-priority thread, although that’s not a hard-and-fast rule.
The default priority is 5, and this is the priority that your threads will have unless you deliberately set them otherwise.
This is the exact opposite of the normal Unix way of prioritizing processes, in which the higher the priority number of a process, the less CPU time the process gets.
Sometimes you want to give one thread more time than another.
Threads that interact with the user should get very high priorities so that perceived responsiveness will be very quick.
On the other hand, threads that calculate in the background should get low priorities.
Tasks that take a long time should have low priorities so that they won’t get in the way of other tasks.
Attempting to exceed the maximum priority or set a nonpositive priority throws an IllegalArgumentException.
For instance, in Example 3-11, you might want to give higher priorities to the threads that do the calculating than the main program that spawns the threads.
In general, though, try to avoid using too high a priority for threads, because you run the risk of starving other, lower-priority threads.
Preemption Every virtual machine has a thread scheduler that determines which thread to run at any given time.
There are two main kinds of thread scheduling: preemptive and cooperative.
A preemptive thread scheduler determines when a thread has had its fair share of CPU time, pauses that thread, and then hands off control of the CPU to a different thread.
A cooperative thread scheduler waits for the running thread to pause itself before handing off control of the CPU to a different thread.
A virtual machine that uses cooperative thread scheduling is much more susceptible to thread starvation than a virtual machine that uses preemptive thread scheduling, because one high-priority, uncooperative thread can hog an entire CPU.
All Java virtual machines are guaranteed to use preemptive thread scheduling between priorities.
That is, if a lower-priority thread is running when a higher-priority thread.
The situation when multiple threads of the same priority are ready to run is trickier.
A preemptive thread scheduler will occasionally pause one of the threads to allow the next one in line to get some CPU time.
It will wait for the running thread to explicitly give up control or come to a stopping point.
If the running thread never gives up control and never comes to a stopping point and if no higher-priority threads preempt the running thread, all other threads will starve.
It’s important to make sure all your threads periodically pause themselves so that other threads have an opportunity to run.
A starvation problem can be hard to spot if you’re developing on a VM that uses preemptive thread scheduling.
Just because the problem doesn’t arise on your machine doesn’t mean it won’t arise on your customers’ machines if their VMs use cooperative thread scheduling.
Most current virtual machines use preemptive thread scheduling, but some older virtual machines are cooperatively scheduled, and you may also encounter cooperative scheduling in special-purpose Java virtual machines such as for embedded environments.
There are 10 ways a thread can pause in favor of other threads or indicate that it is ready to pause.
The last two possibilities are deprecated because they have the potential to leave objects in inconsistent states, so let’s look at the other eight ways a thread can be a cooperative citizen of the virtual machine.
Blocking Blocking occurs any time a thread has to stop and wait for a resource it doesn’t have.
The most common way a thread in a network program will voluntarily give up control of the CPU is by blocking on I/O.
Because CPUs are much faster than networks and disks, a network program will often block while waiting for data to arrive from the network or be sent out to the network.
Even though it may block for only a few milliseconds, this is enough time for other threads to do significant work.
Threads can also block when they enter a synchronized method or block.
If the thread does not already possess the lock for the object being synchronized on and some other thread does possess that lock, the thread will pause until the lock is released.
If the lock is never released, the thread is permanently stopped.
Neither blocking on I/O nor blocking on a lock will release any locks the thread already possesses.
For I/O blocks, this is not such a big deal, because eventually the I/O will either unblock and the thread will continue or an IOException will be thrown and the thread will then exit the synchronized block or method and release its locks.
However, a thread blocking on a lock that it doesn’t possess will never give up its own locks.
If one thread is waiting for a lock that a second thread owns and the second thread is waiting for a lock that the first thread owns, deadlock results.
Yielding The second way for a thread to give up control is to explicitly yield.
A thread does this it can run another thread if one is ready to run.
Some virtual machines, particularly on real-time operating systems, may ignore this hint.
Before yielding, a thread should make sure that it or its associated Runnable object is in a consistent state that can be used by other objects.
Therefore, ideally, a thread should not be synchronized on anything when it yields.
If the only other threads waiting to run when a thread yields are blocked because they need the synchronized resources that the yielding thread possesses, then the other threads won’t be able to run.
Instead, control will return to the only thread that can run, the one that just yielded, which pretty much defeats the purpose of yielding.
This gives other threads of the same priority the opportunity to run.
Whereas yielding indicates only that a thread is willing to pause and let other equal-priority threads have a turn, a thread that goes to sleep will pause whether any other thread is ready to run or not.
This gives an opportunity to run not only to other threads of the same priority, but also to threads of lower priorities.
However, a thread that goes to sleep does hold onto all the locks it’s grabbed.
Consequently, other threads that need the same locks will be blocked even if the CPU is available.
Therefore, try to avoid sleeping threads inside a synchronized method or block.
Although most modern computer clocks have at least close-to-millisecond accuracy, nanosecond accuracy is rarer.
There’s no guarantee that you can actually time the sleep to within a nanosecond or even within a millisecond on any particular virtual machine.
If the local hardware can’t support that level of accuracy, the sleep time is simply rounded load a certain page every five minutes and, if it fails, emails the webmaster to alert him of the problem:
The thread is not guaranteed to sleep as long as it wants to.
On occasion, the thread may not wake up until some time after its requested wake-up call, simply because the VM is busy doing other things.
It is also possible that some other thread will do something to.
This is one of those cases where the distinction between the thread and the Thread object is important.
Just because the thread is sleeping doesn’t mean that other threads that are awake can’t work with the corresponding Thread object through its methods and fields.
From that point forward, the thread is awake and executes as normal, at least until it goes to sleep again.
In the previous example, an InterruptedException is used to terminate a thread that would otherwise run forever.
When the InterruptedException is thrown, from a menu or otherwise indicates that he wants the program to quit.
If a thread is blocked on an I/O operation such as a read or write, the effect of interrupting the thread is highly platform dependent.
However, this is unlikely to happen on other platforms, and may not work with all stream classes on Solaris.
If your program architecture requires interruptible I/O, you should seriously consider using the nonblocking I/O discussed in Chapter 11 rather than streams.
Unlike streams, buffers and channels are explicitly designed to support interruption while blocked on a read or write.
Joining threads It’s not uncommon for one thread to need the result of another thread.
For example, a web browser loading an HTML page in one thread might spawn a separate thread to retrieve every image embedded in the page.
If the IMG elements don’t have HEIGHT and WIDTH attributes, the main thread might have to wait for all the images to load before it thread to wait for another thread to finish before continuing.
The first variant waits indefinitely for the joined thread to finish.
The second two variants wait for the specified amount of time, after which they continue even if the joined.
You want to find the minimum, maximum, and median of a random array of doubles.
You spawn a new thread to sort the array, then join to that thread to await its results.
Only when it’s done do you read out the desired values.
Line 6 starts the thread that will sort the array.
Before you can find the minimum, median, and maximum of the array, you need to wait for the sorting thread to finish.
Therefore, line 8 joins the current thread to the sorting thread.
At this point, the thread executing these lines of code stops in its tracks.
Notice that at no point is there a reference to the thread that pauses.
If this is within the normal flow anywhere that points to this thread.
A thread that’s joined to another thread can be interrupted just like a sleeping thread if starting from the catch block that caught the exception.
In the preceding example, if the thread is interrupted, it skips over the calculation of the minimum, median, and maximum because they won’t be available if the sorting thread was interrupted before it could finish.
Avoid a race condition by joining to the thread that has a result you need.
Because Example 3-12 joins to threads in the same order as the threads are started, this fix also has the side effect of printing the output in the same order as the arguments used to construct the threads, rather than in the order the threads finish.
This modification doesn’t make the program any slower, but it may occasionally be an issue if you want to get the output of a thread as soon as it’s done, without waiting for other unrelated threads to finish first.
Waiting on an object A thread can wait on an object it has locked.
While waiting, it releases the lock on the object and pauses until it is notified by some other thread.
Another thread changes the object in some way, notifies the thread waiting on that object, and then continues.
This differs from joining in that neither the waiting nor the notifying thread has to finish before the other thread can continue.
Waiting pauses execution until an object or resource reaches a certain state.
Waiting on an object is one of the lesser-known ways a thread can pause.
That’s because it doesn’t involve any methods in the Thread class.
Instead, to wait on a particular object, the thread that wants to pause must first obtain the lock on the object using.
These methods are not in the Thread class; rather, they are in the java.lang.Object class.
Consequently, they can be invoked on any object of any class.
When one of these methods is invoked, the thread that invoked it releases the lock on the object it’s waiting on (though not any locks it possesses on other objects) and goes to sleep.
When the timeout expires, execution of the thread resumes thread can’t immediately regain the lock on the object it was waiting on, it may still be blocked for some time.
These must be invoked on the object the thread was waiting on, not generally on the Thread itself.
Before notifying an object, a thread must first obtain the lock on the object or less at random from the list of threads waiting on the object and wakes it up.
Once a waiting thread is notified, it attempts to regain the lock of the object it was waiting on.
If it succeeds, execution resumes with the statement immediately following the then execution resumes with the statement immediately following the invocation of.
For example, suppose one thread is reading a JAR archive from a network connection.
The first entry in the archive is the manifest file.
Another thread might be interested in the contents of the manifest file even before the rest of the archive is available.
The interested thread could create a custom ManifestFile object, pass a reference to this object to the thread that would read the JAR archive, and wait on it.
The thread reading the archive would first fill the ManifestFile with entries from the stream, then notify the ManifestFile, then continue reading the rest of the JAR archive.
When the reader thread notified the ManifestFile, the original thread would wake up and do whatever it planned to do with the now fully prepared ManifestFile object.
Waiting and notification are more commonly used when multiple threads want to wait on the same object.
For example, one thread may be reading a web server logfile in which each line contains one entry to be processed.
Each line is placed in a java.util.List as it’s read.
Several threads wait on the List to process entries as they’re added.
When all threads waiting on one object are notified, all will wake up and try to get the lock on the object.
That one continues; the rest are blocked until the first one releases the lock.
If several threads are all waiting on the same object, a significant amount of time may pass before the last one gets its turn at the lock on the object and continues.
It’s entirely possible that the object on which the thread was waiting will once again have been placed in an unacceptable state during this time.
Thus, you’ll generally put the call because the thread was notified, the object is now in the correct state.
Check it explicitly if you can’t guarantee that once the object reaches a correct state it will never again reach an incorrect state.
For example, this is how the client threads waiting on the logfile entries might look:
If interrupted, the last entry has been processed so return; // process this entry...
The code reading the logfile and adding entries to the list might look something like this:
There are no more entries to add to the list so // we interrupt all threads that are still waiting.
Finish The final way a thread can give up control of the CPU in an orderly fashion is by over.
In network applications, this tends to occur with threads that wrap a single blocking operation, such as downloading a file from a server, so that the rest of the application won’t be blocked.
There’s a nontrivial amount of overhead for the virtual machine in setting up and tearing down threads.
If a thread is finishing in a small fraction of a second anyway, chances are it would finish even faster if you used a simple method call rather than a separate thread.
Thread Pools and Executors Adding multiple threads to a program dramatically improves performance, especially for I/O-bound programs such as most network programs.
Starting a thread and cleaning up after a thread that has died takes a noticeable amount of work from the virtual machine, especially if a program spawns hundreds of threads—not an unusual occurrence for even a low- to mediumvolume network server.
Even if the threads finish quickly, this can overload the garbage collector or other parts of the VM and hurt performance, just like allocating thousands of any other kind of object every minute.
Finally, and most importantly, although threads help make more efficient use of a computer’s limited CPU resources, there is still only a finite amount of resources to go around.
Once you’ve spawned enough threads to use all the computer’s available idle time, spawning more threads just wastes MIPS and memory on thread management.
The Executors class in java.util.concurrent makes it quite easy to set up thread pools.
You simply submit each task as a Runnable object to the pool.
You get back a Future object you can use to check on the progress of the task.
Suppose you want to gzip every file in the current directory using a java.util.zip.GZIPOutputStream.
This is a filter stream that compresses all the data it writes.
On the one hand, this is an I/O-heavy operation because all the files have to be read and written.
On the other hand, data compression is a very CPU-intensive operation, so you don’t want too many threads running at once.
This is a good opportunity to use a thread pool.
Each client thread will compress files while the main program will determine which files to compress.
In this example, the main program is likely to significantly outpace the compressing threads because all it has to do is list the files in a directory.
Therefore, it’s not out of the question to fill the pool first, then start the threads that compress the files in the pool.
However, to make this example as general as possible, you’ll allow the main program to run in parallel with the zipping threads.
Notice the use of Java 7’s try-with-resources statement in GZipRunnable.
Both the input and output stream are declared at the beginning of the try block and automatically closed at the end of the try block.
This is very important for performance in I/O-limited applications, and especially important in network programs.
At worst, buffering has no impact on performance, while at best it can give you an order of magnitude speedup or more.
It constructs the pool with a fixed thread count of four, and iterates through all the files and directories listed on the command line.
Each of those files and files in those directories is used to construct a GZipRunnable.
This runnable is submitted to the pool for eventual processing by one of the four threads.
It simply notifies the pool that no further tasks will be added to its internal queue and that it should shut down once it has finished all pending work.
Shutting down like this is mostly atypical of the heavily threaded network programs you’ll write because it does have such a definite ending point: the point at which all files are processed.
Most network servers continue indefinitely until shut down through an to abort currently processing tasks and skip any pending tasks.
Each node or host is identified by at least one unique number called an Internet address or an IP address.
They aren’t numbers, and they aren’t ordered in any predictable or useful sense.
Bytes are separated by periods for the convenience of human eyes.
An IPv6 address is normally written as eight blocks of four hexadecimal digits separated by colons.
For example, at the time of this writing, the address of www.hamiltonweather.tk is 2400:cb00:2048:0001:0000:0000:6ca2:c665
Therefore, the address of www.hamiltonweather.tk can be written as 2400:cb00:2048:1:0:0:6ca2:c665
A double colon, at most one of which may appear in any address, indicates multiple zero blocks.
Miller discovered that most people could remember about seven digits per number; some can remember as many as nine, while others remember as few as five.
This is why phone numbers are broken into three- and four-digit pieces with three-digit area codes.
Obviously, an IP address, which can have as many as 12 decimal digits, is beyond the capacity of most humans to remember.
I can remember about two IP addresses, and then only if I use both daily and the second is on the same subnet as the first.
To avoid the need to carry around Rolodexes full of IP addresses, the Internet’s designers invented the Domain Name System (DNS)
Clients often have a hostname, but often don’t, especially if their IP address is dynamically assigned at startup.
In a book about network programming, it is crucial to be precise about addresses and hostnames.
In this book, an address is always a numeric IP address, never a human-readable hostname.
For instance, www.beand.com and xom.nu are really the same Linux box.
The name www.beand.com really refers to a website rather than a particular machine.
In the past, when this website moved from one machine to another, the name was reassigned to the new machine so it always pointed to the site’s current server.
This way, URLs around the Web don’t need to be updated just because the site has moved to a new host.
Some common names like www and news are often aliases for the machines providing those services.
For example, news.speakeasy.net is an alias for my ISP’s news server.
Because the server may change over time, the alias can move with the service.
It is then the responsibility of the DNS server to randomly choose machines to respond to each request.
This feature is most frequently used for very high-traffic websites, where it splits the load across multiple systems.
Every computer connected to the Internet should have access to a machine called a domain name server, generally a Unix box running special DNS software that knows the mappings between different hostnames and IP addresses.
Most domain name servers only know the addresses of the hosts on their local network, plus the addresses of a few domain name servers at other sites.
If a client asks for the address of a machine outside the local domain, the local domain name server asks a domain name server at the remote location and relays the answer to the requester.
Most of the time, you can use hostnames and let DNS handle the translation to IP addresses.
As long as you can connect to a domain name server, you don’t need to worry about the details of how names and addresses are passed between your machine, the local domain name server, and the rest of the Internet.
However, you will need access to at least one domain name server to use the examples in this chapter and most of the rest of this book.
It is used by most of the other networking classes, including Socket, ServerSocket, URL, DatagramSocket, DatagramPacket, and more.
Usually, it includes both a hostname and an IP address.
Instead, InetAddress has static factory methods that connect to a DNS server to resolve a hostname.
This method does not merely set a private String field in the InetAddress class.
It actually makes a connection to the local DNS server to look up the name and the numeric address.
If you’ve looked up this host previously, the information may be cached locally, in which case a network connection is not required.) If the DNS server can’t find the address, this method throws an UnknownHostException, a subclass of IOException.
Example 4-1 shows a complete program that creates an InetAddress object for www.oreilly.com including all the necessary imports and exception handling.
You can also do a reverse lookup by IP address.
For example, if you want the hostname for the address 208.201.239.100, pass the dotted quad address to InetAddress.getBy.
Example 4-2 prints the address of the machine it’s run on.
Whether you see a fully qualified name like titan.oit.unc.edu or a partial name like titan depends on what the local DNS server returns for hosts in the local domain.
If you’re not connected to the Internet, and the system does not have a fixed IP address or domain name, you’ll probably see localhost as the domain name and 127.0.0.1 as the IP address.
If you know a numeric address, you can create an InetAddress object from that address addresses for hosts that do not exist or cannot be resolved:
Note that it had to cast the two large values to bytes.
Unlike the other factory methods, these two methods make no guarantees that such a host exists or that the hostname is correctly mapped to the IP address.
This could be useful if a domain name server is not available or might have inaccurate information.
For example, none of the computers, printers, or routers in my basement area network are registered with any DNS server.
Because I can never remember which addresses I’ve assigned to which systems, I wrote a simple program that attempts to connect to all 254 possible local addresses in turn to see which ones are active.
This only took me about 10 times as long as writing down all the addresses on a piece of paper.)
Caching Because DNS lookups can be relatively expensive (on the order of several seconds for a request that has to go through several intermediate servers, or one that’s trying to resolve an unreachable host) the InetAddress class caches the results of lookups.
Once it has the address of a given host, it won’t look it up again, even if you create a new InetAddress object for the same host.
As long as IP addresses don’t change while your program is running, this is not a problem.
Negative results (host not found errors) are slightly more problematic.
It’s not uncommon for an initial attempt to resolve a host to fail, but the immediately following one to succeed.
The first attempt timed out while the information was still in transit from the remote DNS server.
Then the address arrived at the local server and was immediately available for the next request.
For this reason, Java only caches unsuccessful DNS queries for 10 seconds.
These times can be controlled by the system properties networkaddress.cache.ttl and networkaddress.cache.negative.ttl.
The first of those, networkad dress.cache.ttl, specifies the number of seconds a successful DNS lookup will remain in Java’s cache.
Attempting to look up the same host again within these limits will only return the same value.
Besides local caching inside the InetAddress class, the local host, the local domain name server, and other DNS servers elsewhere on the Internet also cache the results of various queries.
As a result, it may take several hours for the information about an IP address change to propagate across the Internet.
In the meantime, your program may encounter various exceptions, including UnknownHos tException, NoRouteToHostException, and ConnectException, depending on the changes made to the DNS.
InetAddress object for the requested IP address without checking with DNS.
This means it’s possible to create InetAddress objects for hosts that don’t really exist and that you can’t connect to.
The hostname of an InetAddress object created from a string containing an IP address is initially set to that string.
A DNS lookup for the actual hostname is only performed when the hostname is requested, either explicitly via a finally performed, the host with the specified IP address can’t be found, the hostname remains the original dotted quad string.
Some services have lived at the same hostname for years, but have switched IP addresses several times.
Use an IP address only when a hostname is not available.
Creating a new InetAddress object from a hostname is considered a potentially insecure operation because it requires a DNS lookup.
An untrusted applet under the control of the default security manager will only be allowed to get the IP address of the host it came from (its codebase) and possibly the local host.
Untrusted code is not allowed to create an InetAddress object from any other hostname.
This is true whether the code construct an InetAddress object from the string form of the IP address, though it will not perform DNS lookups for such addresses.
Untrusted code is not allowed to perform arbitrary DNS lookups for third-party hosts because of the prohibition against making network connections to hosts other than the codebase.
Arbitrary DNS lookups would open a covert channel by which a program could talk to third-party hosts.
All it has to do is request DNS information for macfaq.dialup.cloud9.net.is.vulnerable.crackersinc.com.
To resolve that hostname, the applet would contact the local DNS server.
The local DNS server would contact the DNS server at crackersinc.com.
Even though these hosts don’t exist, the cracker can inspect the DNS error log for crackersinc.com to retrieve the message.
This scheme could be considerably more sophisticated with compression, error correction, encryption, custom DNS servers that email the messages to a fourth site, and more, but this version is good enough for a proof of concept.
Arbitrary DNS lookups are prohibited because arbitrary DNS lookups leak information.
In this case, an applet should not be a channel for information the web server doesn’t already have.
Like all security checks, prohibitions against DNS resolutions can be relaxed for trusted code.
The specific SecurityManager method used to test whether a host can be resolved.
When the port argument is –1, this method checks whether DNS may be invoked to resolve the specified host.
If the port argument is greater than –1, this method checks.
Getter Methods The InetAddress class contains four getter methods that return the hostname as a string and the IP address as both a string and a byte array:
If the machine in question doesn’t have a hostname or if the security manager prevents the name from being determined, a dotted quad format of the numeric IP address is returned.
Example 4-4 uses this method to print the IP address of the local machine in the customary format.
Of course, the exact output depends on where the program is run.
If you want to know the IP address of a machine (and you rarely do), then use the order.
The most significant byte (i.e., the first byte in the address’s dotted quad form) is the first byte in the array, or element zero.
To be ready for IPv6 addresses, try not to assume anything about the length of this array.
If you need to know the length of the array, use the array’s length field:
Unlike C, Java doesn’t have an unsigned byte primitive data type.
Bytes with values higher than 127 are treated as negative numbers.
Therefore, if you want to do anything with the bytes returned by.
If it is, 256 is added to signedByte to make it positive.
Address Types Some IP addresses and some patterns of addresses have special meanings.
For instance, I’ve already mentioned that 127.0.0.1 is the local loopback address.
Java includes 10 methods for testing whether an InetAddress object meets any of these criteria:
A wildcard address matches any address of the local system.
This is with multiple Ethernet cards or an Ethernet card and an 802.11 WiFi interface.
The loopback address connects to the same computer directly in the IP layer without using any physical hardware.
Thus, connecting to the loopback address enables tests to bypass potentially buggy or nonexistent Ethernet, PPP, and other drivers, helping to isolate problems.
Connecting to the loopback address is not the same as connecting to the system’s normal IP address from the same system.
Routers do not forward packets addressed to a link-local address beyond the local subnet.
The next eight bytes are filled with a local address, often copied from the Ethernet MAC address assigned by the Ethernet card manufacturer.
Site-local addresses are similar to link-local addresses except that they may be forwarded by routers within a site or campus but should not be forwarded beyond that site.
The next eight bytes are filled with a local address, often copied from the Ethernet MAC address assigned by the Ethernet card manufacturer.
Multicasting broadcasts content to all subscribed computers rather than to one particular computer.
A global multicast address may have subscribers around the world.
In IPv4, all multicast addresses have global scope, at least as far as this method is concerned.
Packets addressed to a link-local address will only be transmitted within their own subnet.
Packets addressed to an interface-local address are not sent beyond the network interface from which they originate, not even to a different network interface on the same node.
The method name is out of sync with current terminology.
Testing Reachability node is reachable from the current host (i.e., whether a network connection can be made)
Connections can be blocked for many reasons, including firewalls, proxy servers, misbehaving routers, and broken cables, or simply because the remote host is not turned on when you try to connect.
These methods attempt to use traceroute (more specifically, ICMP echo requests) to find out if the specified address is reachable.
If the host responds within timeout milliseconds, the methods return true; otherwise, they return false.
An IOException will be thrown if there’s a network error.
The second variant also lets you specify the local network interface the connection is made from and the “time-to-live” (the maximum number of network hops the connection will attempt before being discarded)
Object Methods Like every other class, java.net.InetAddress inherits from java.lang.Object.
Thus, it has access to all the methods of that class.
An object is equal to an InetAddress object only if it is itself an instance of the InetAd dress class and it has the same IP address.
Thus, an InetAddress object for www.ibiblio.org is equal to an InetAddress object for www.cafeaulait.org because both names refer to the same IP address.
Example 4-7 creates InetAddress objects for www.ibiblio.org and helios.ibiblio.org and then tells you whether they’re the same machine.
If two InetAddress objects have the same address, then they have the same hash code, even if their hostnames are different.
If one doesn’t, the dotted quad address is substituted in Java 1.3 and earlier.
In Java 1.4 and later, the hostname is set to the empty string.
In the application layer where Java programs reside, you simply don’t need to know this (and even if you do need to know, it’s quicker to check the size of the have)
Inet4Address overrides several of the methods in InetAddress but doesn’t change their behavior in any public way.
If this is the case, you can pull off the last four dress instead.
This can either be a physical interface such as an additional Ethernet card (common on firewalls and routers) or it can be a virtual interface bound to the same physical hardware as the machine’s other IP addresses.
The NetworkInterface class provides methods to enumerate all the local addresses, regardless of interface, and to create InetAddress objects from them.
These InetAddress objects can then be used to create sockets, server sockets, and so forth.
Factory Methods Because NetworkInterface objects represent physical hardware and virtual addresses, they cannot be constructed arbitrarily.
As with the InetAddress class, there are static factory methods that return the NetworkInterface object associated with a particular network interface.
You can ask for a NetworkInterface by IP address, by name, or by enumeration.
If there’s no interface with that name, it returns null.
If the underlying network stack encounters a problem while locating the relevant network interface, a SocketException is thrown, but this isn’t too likely to happen.
The local loopback address is probably named something like “lo”
For example, this code fragment attempts to find the primary Ethernet interface on a Unix system:
If no network interface is bound to that IP address on the local host, it returns null.
For example, this code fragment finds the network interface for the local loopback address:
Example 4-8 is a simple program to list all network interfaces on the local host:
Here’s the result of running this on the IBiblio login server:
You can see that this host has two separate Ethernet cards plus the local loopback address.
Getter Methods Once you have a NetworkInterface object, you can inquire about its IP address and name.
This is pretty much the only thing you can do with these objects.
A single network interface may be bound to more than one IP address.
This situation a java.util.Enumeration containing an InetAddress object for each IP address the interface is bound to.
For example, this code fragment lists all the IP addresses for the eth0 interface:
Some Useful Programs You now know everything there is to know about the java.net.InetAddress class.
The tools in this class alone let you write some genuinely useful programs.
Here you’ll look at two examples: one that queries your domain name server interactively and another that can improve the performance of your web server by processing logfiles offline.
SpamCheck A number of services monitor spammers, and inform clients whether a host attempting to connect to them is a known spammer or not.
These real-time blackhole lists need to respond to queries extremely quickly, and process a very high load.
Thousands, maybe millions, of hosts query them repeatedly to find out whether an IP address attempting a connection is or is not a known spammer.
The nature of the problem requires that the response be fast, and ideally it should be cacheable.
Furthermore, the load should be distributed across many servers, ideally ones located around the world.
Although this could conceivably be done using a web server, SOAP, UDP, a custom protocol, or some other mechanism, this service is in fact cleverly implemented using DNS and DNS alone.
To find out if a certain IP address is a known spammer, reverse the bytes of the address, add the domain of the blackhole service, and look it up.
Note that despite the numeric component, this is a hostname ASCII string, not a dotted quad IP address.)
If the DNS query succeeds (and, more specifically, if it returns the address 127.0.0.2), then the host is known to be a spammer.
If you use this technique, be careful to stay on top of changes to blackhole list policies and addresses.
For obvious reasons, blackhole servers are frequent targets of DDOS and other attacks, so you want to be careful that if the blackhole server changes its address or simply stops responding to any queries, you don’t begin blocking all traffic.
Further note that different blackhole lists can follow slightly different protocols.
Processing Web Server Logfiles Web server logs track the hosts that access a website.
By default, the log reports the IP addresses of the sites that connect to the server.
However, you can often get more information from the names of those sites than from their IP addresses.
Most web servers have an option to store hostnames instead of IP addresses, but this can hurt performance because the server needs to make a DNS request for each hit.
It is much more efficient to log the IP addresses and convert them to hostnames at a later time, when the server isn’t busy or even on another machine completely.
Example 4-10 is a program called Weblog that reads a web server logfile and prints each line with IP addresses converted to hostnames.
Most web servers have standardized on the common logfile format.
A typical line in the common logfile format looks like this:
The first field is the IP address or, if DNS resolution is turned on, the hostname from which the connection was made.
Therefore, for our purposes, parsing the logfile is easy: everything before the first space is the IP address, and everything after it does not need to be changed.
The dotted quad format IP address is converted into a hostname using the usual methods of java.net.InetAddress.
The name of the file to be processed is passed to Weblog as the first argument on the command line.
A FileInputStream fin is opened from this file and an InputStream Reader is chained to fin.
This InputStreamReader is buffered by chaining it to an instance of the BufferedReader class.
The file is processed line by line in a for loop.
Each pass through the loop places one line in the String variable entry.
The position of the first space is determined by entry.indexOf(" ")
Output can be sent to a new file through the standard means for redirecting output.
Most web browsers generate multiple logfile entries per page served, because there’s an entry in the log not just for the page itself but for each graphic on the page.
And many visitors request multiple pages while visiting a site.
If the same address is requested again, it can be retrieved from the cache much more quickly than from DNS.
In my initial tests, it took more than a second per log entry.
Exact numbers depend on the speed of your network connection, the speed of the local and remote DNS servers, and network congestion when the program is run.) The program spends a huge amount of time sitting and waiting for DNS requests to return.
Of course, this is exactly the problem multithreading is designed to solve.
One main thread can read the logfile and pass off individual entries to other threads for processing.
Over the space of a few days, even lowvolume web servers can generate a logfile with hundreds of thousands of lines.
Trying to process such a logfile by spawning a new thread for each entry would rapidly bring even the strongest virtual machine to its knees, especially because the main thread can read logfile entries much faster than individual threads can resolve domain names and die.
The number of threads is stored in a tunable parameter, numberOfThreads, so that it can be adjusted to fit the VM and network stack.
Launching too many simultaneous DNS requests can also cause problems.)
The first class, LookupTask, shown in Example 4-11, is a Callable that parses a logfile entry, looks up a single address, and replaces that address with the corresponding hostname.
This doesn’t seem like a lot of work and CPU-wise, it isn’t.
Each task is submitted to an executor that can run multiple (though not all) tasks in parallel and in sequence.
A loop reads values out of the queue and prints them.
Using threads like this lets the same logfiles be processed in parallel—a huge time savings.
The tech editor ran the same test on a different system and only saw a factor of four improvement, but either way it’s still a significant gain.
Although the queue of Callable tasks is much more efficient than spawning a thread for each logfile entry, logfiles can be huge and this program can still burn a lot of memory.
To avoid this, you could put the output into a separate thread that shared the queue with the input thread.
Because early entries could be processed and output while the input was still being parsed, the queue would not grow so large.
You’d need a separate signal to tell you when the output was complete because an empty queue is no longer sufficient to prove the job is complete.
The easiest way is simply to count the number of input lines and make sure it matches up to the number of output lines.
In the last chapter, you learned how to address hosts on the Internet via host names and IP addresses.
In this chapter, we increase the granularity by addressing resources, any number of which may reside on any given host.
A URL unambiguously identifies the location of a resource on the Internet.
A URI can identify a resource by its network location, as in a URL, or by its name, number, or other characteristics.
The URL class is the simplest way for a Java program to locate and retrieve data from the network.
You do not need to worry about the details of the protocol being used, or how to communicate with the server; you simply tell Java the URL and it gets the data for you.
URIs A Uniform Resource Identifier (URI) is a string of characters in a particular syntax that identifies a resource.
The resource identified may be a file on a server; but it may also be an email address, a news message, a book, a person’s name, an Internet host, the current stock price of Oracle, or something else.
A resource is a thing that is identified by a URI.
Don’t spend too much time worrying about what a resource is or isn’t, because you’ll never see one anyway.
All you ever receive from a server is a representation of a resource which comes in the form of bytes.
For instance, https://www.un.org/en/documents/ udhr/ identifies the Universal Declaration of Human Rights; but there are representations of the declaration in plain text, XML, PDF, and other formats.
There are also representations of this resource in English, French, Arabic, and many other languages.
For instance, https:// www.un.org/en/documents/udhr/ identifies specifically the English version of the Universal Declaration of Human Rights.
One of the key principles of good web architecture is to be profligate with URIs.
If anyone might want to address something or refer to something, give it a URI (and in practice a URL)
Just because a resource is a part of another resource, or a collection of other resources, or a state of another resource at a particular time, doesn’t mean it can’t have its own URI.
For instance, in an email service, every user, every message received, every message sent, every filtered view of the inbox, every contact, every filter rule, and every single page a user might ever look at should have a unique URI.
Although architecturally URIs are opaque strings, in practice it’s useful to design them with human-readable substructure.
For instance, http://mail.example.com/ might be a particular mail server, http:// JavaMail.nobody%40meetup.com might be a particular message in that mailbox.
The syntax of a URI is composed of a scheme and a scheme-specific part, separated by a colon, like this:
The syntax of the scheme-specific part depends on the scheme being used.
In addition, Java makes heavy use of nonstandard custom schemes such as rmi, jar, jndi, and doc for various purposes.
There is no specific syntax that applies to the scheme-specific parts of all URIs.
The authority part of the URI names the authority responsible for resolving the rest of the URI.
Although most current examples of URIs use an Internet host as an authority, future schemes may not.
However, if the authority is an Internet host, optional usernames and ports may also be provided to make the authority more specific.
In most cases, including the password in the URI is a big security hole unless, as here, you really do want everyone in the universe to know the password.)
The path is a string that the authority can use to determine which resource is identified.
Different authorities may interpret the same path to refer to different resources.
For instance, the path /index.html means one thing when the authority is www.landoverbaptist.org and something very different when the authority is www.churchofsatan.com.
The path may be hierarchical, in which case the individual parts are separated by forward slashes, and the.
These are derived from the pathname syntax on the Unix operating systems where the Web and URLs were invented.
They conveniently map to a filesystem stored on a Unix web server.
However, there is no guarantee that the components of any particular path actually correspond to files or directories on any particular filesystem.
Some URIs aren’t at all hierarchical, at least in the filesystem sense.
Although there’s some hierarchy to the newsgroup names indicated by the period between netscape and devs-java, it’s not encoded as part of the URI.
The scheme part is composed of lowercase letters, digits, and the plus sign, period, and hyphen.
Thus, in a URI it would be encoded as %E6%9C%A8
If you don’t hexadecimally encode non-ASCII characters like this, but just include them directly, then instead of a URI you have an IRI (an Internationalized Resource Identifier)
IRIs are easier to type and much easier to read, but a lot of software and protocols expect and support only ASCII URIs.
Punctuation characters such as / and @ must also be encoded with percent escapes if they are used in any role other than what’s specified for them in the scheme-specific part of a particular URL.
This is not as far-fetched as it might sound to Unix or Windows users.
URLs A URL is a URI that, as well as identifying a resource, provides a specific network location for the resource that a client can use to retrieve a representation of that resource.
By contrast, a generic URI may tell you what a resource is, but not actually tell you where.
In Java, it’s the difference between the java.net.URI class that only identifies resources and the java.net.URL class that can both identify and retrieve resources.
The network location in a URL usually includes the protocol used to access a server (e.g., FTP, HTTP), the hostname or IP address of the server, and the path to the resource on that server.
This specifies that there is a file called javatutorial.html in a directory called javafaq on the server www.ibiblio.org, and that this file can be accessed via the HTTP protocol.
Here the protocol is another word for what was called the scheme of the URI.
Protocol is the word used in the Java documentation.) In a URL, the protocol part can be file, ftp, http, https, magnet, telnet, or various other strings (though not urn)
The host part of a URL is the name of the server that provides the resource you want.
If present, it contains a username and, rarely, a password.
It’s not necessary if the service is running on its default port (port 80 for HTTP servers)
The path points to a particular resource on the specified server.
It often looks like a filesystem path such as /forum/index.php.
However, it may or may not actually map to a filesystem on the server.
If it does map to a filesystem, the path is relative to the document root of the server, not necessarily to the root of the filesystem on the server.
As a rule, servers that are open to the public do not show their entire filesystem to clients.
Rather, they show only the contents of a specified directory.
This directory is called the document root, and all paths and filenames are relative to it.
Thus, on a Unix server, all files that are available to the public might be in /var/public/html, but to somebody connecting from a remote machine, this directory looks like the root of the filesystem.
It’s commonly used only in http URLs, where it contains form data for input to programs running on the server.
Finally, the fragment references a particular part of the remote resource.
If the remote resource is HTML, the fragment identifier names an anchor in the HTML document.
If the remote resource is XML, the fragment identifier is an XPointer.
Some sources refer to the fragment part of the URL as a “section”
Fragment identifier targets are created in an HTML document with an id attribute, like this:
To refer to this point, a URL includes not only the document’s filename but the fragment identifier separated from the rest of the URL by a #:
Technically, a string that contains a fragment identifier is a URL reference, not a URL.
Java, however, does not distinguish between URLs and URL references.
Relative URLs A URL tells a web browser a lot about a document: the protocol used to retrieve the document, the host where the document lives, and the path to the document on that host.
Most of this information is likely to be the same for other URLs that are referenced in the document.
Therefore, rather than requiring each URL to be specified in its entirety, a URL may inherit the protocol, hostname, and path of its parent document (i.e., the document in which it appears)
URLs that aren’t complete but inherit pieces from their parent are called relative URLs.
In contrast, a completely specified URL is called an absolute URL.
In a relative URL, any pieces that are missing are assumed to be the same as the corresponding pieces from the URL of the document in which the URL is found.
For example, suppose that while browsing http://www.ibiblio.org/javafaq/javatutorial.html you click on this hyperlink:
The browser cuts javatutorial.html off the end of http://www.ibiblio.org/javafaq/javatutorial.html to get http://www.ibiblio.org/javafaq/
Then it attaches javafaq.html onto the end of http://www.ibiblio.org/javafaq/ to get http://www.ibiblio.org/javafaq/javafaq.html.
If the relative link begins with a /, then it is relative to the document root instead of relative to the current file.
Thus, if you click on the following link while browsing http:// www.ibiblio.org/javafaq/javatutorial.html:
More importantly, relative URLs allow a single document tree to be served by multiple protocols: for instance, both HTTP and FTP.
Most importantly of all, relative URLs allow entire trees of documents to be moved or copied from one site to another without breaking all the internal links.
The URL Class The java.net.URL class is an abstraction of a Uniform Resource Locator such as http:// www.lolcats.com/ or ftp://ftp.redhat.com/pub/
It extends java.lang.Object, and it is a final class that cannot be subclassed.
Rather than relying on inheritance to configure instances for different kinds of URLs, it uses the strategy design pattern.
Protocol handlers are the strategies, and the URL class itself forms the context through which the different strategies are selected.
Although storing a URL as a string would be trivial, it is helpful to think of URLs as objects with fields that include the scheme (a.k.a.
Indeed, this is almost exactly how the java.net.URL class is organized, though the details vary a little between different versions of Java.
After a URL object has been constructed, its fields do not change.
This has the side effect of making them thread safe.
Creating New URLs Unlike the InetAddress objects in Chapter 4, you can construct instances of java.net.URL.
Which constructor you use depends on the information you have and the form it’s in.
All these constructors throw a MalformedURLException if you try to create a URL for an unsupported protocol or if the URL is syntactically incorrect.
The only protocols that have been available in all virtual machines are http and file, and the latter is notoriously flaky.
Today, Java also supports the https, jar, and ftp protocols.
Some virtual machines support mailto and gopher as well as some custom protocols like doc, netdoc, systemresource, and verbatim used internally by Java.
If the protocol you need isn’t supported by a particular VM, you may be able to install a protocol handler for that scheme to enable the URL class to speak that protocol.
In practice, this is way more trouble than it’s worth.
You’re better off using a library that exposes a custom API just for that protocol.
Other than verifying that it recognizes the URL scheme, Java does not check the correctness of the URLs it constructs.
The programmer is responsible for making sure that URLs created are valid.
For instance, Java does not check that the hostname in an HTTP URL does not contain spaces or that the query string is x-www-form-URL-encoded.
It does not check that a mailto URL actually contains an email address.
You can create URLs for hosts that don’t exist and for hosts that do exist but that you won’t be allowed to connect to.
The simplest URL constructor just takes an absolute URL in string form as its single argument:
Like all constructors, this may only be called after the new operator, and like all URL constructors, it can throw a MalformedURLException.
The following code constructs a URL object from a String, catching the exception that might be thrown:
Example 5-1 is a simple program for determining which protocols a virtual machine supports.
If the constructor succeeds, you know the protocol is supported.
Otherwise, a MalformedURLException is thrown and you know the protocol is not supported.
The results of this program depend on which virtual machine runs it.
The nonsupport of RMI and JDBC is actually a little deceptive; in fact, the JDK does support these protocols.
However, that support is through various parts of the java.rmi and java.sql packages, respectively.
These protocols are not accessible through the URL class like the other supported protocols (although I have no idea why Sun chose to wrap up RMI and JDBC parameters in URL clothing if it wasn’t intending to interface with these via Java’s quite sophisticated mechanism for handling URLs)
VMs that are not derived from the Oracle codebase may vary somewhat in which protocols they support.
For example, Android’s Dalvik VM only supports the required http, https, file, ftp, and jar protocols.
You can also build a URL by specifying the protocol, the hostname, and the file:
This constructor sets the port to -1 so the default port for the protocol will be used.
The file argument should begin with a slash and include a path, a filename, and optionally a fragment identifier.
Forgetting the initial slash is a common mistake, and one that is not easy to spot.
The file specification includes a reference to a named anchor.
The code catches the exception that would be thrown if the virtual machine did not support the HTTP protocol.
For the rare occasions when the default port isn’t correct, the next constructor lets you specify the port explicitly as an int.
This constructor builds an absolute URL from a relative URL and a base URL:
For instance, you may be parsing an HTML document at http://www.ibiblio.org/javafaq/ index.html and encounter a link to a file called mailinglists.html with no further qualifying information.
In this case, you use the URL to the document that contains the link to provide the missing information.
This constructor is particularly useful when you want to loop through a list of files that are all in the same directory.
You can create a URL for the first file and then use this initial URL to create URL objects for the other files by substituting their filenames.
Other sources of URL objects Besides the constructors discussed here, a number of other methods in the Java class.
The exact format of the URL returned by this method is platform dependent.
For example, on Windows it may return something like file:/D:/JAVA/JNP4/05/ ToURLTest.java.
On Linux and other Unixes, you’re likely to see file:/home/elharo/ books/JNP4/05/ToURLTest.java.
In practice, file URLs are heavily platform and program dependent.
Java file URLs often cannot be interchanged with the URLs used by web browsers and other programs, or even with Java programs running on different platforms.
Class loaders are used not only to load classes but also to load resources such as images and audio files.
The static ClassLoader.getSystemResource(String name) method returns a URL from which a single resource can be read.
The ClassLoader.getSystem Resources(String name) method returns an Enumeration containing a list of URLs from which the named resource can be read.
And finally, the instance method getRe source(String name) searches the path used by the referenced class loader for a URL to the named resource.
The URLs returned by these methods may be file URLs, HTTP URLs, or some other scheme.
The full path of the resource is a package qualified Java name with slashes instead of periods such as /com/macfaq/sounds/swale.au or com/ macfaq/images/headshot.jpg.
The Java virtual machine will attempt to find the requested resource in the classpath, potentially inside a JAR archive.
There are a few other methods that return URL objects here and there throughout the class library, but most are simple getter methods that return a URL you probably already know because you used it to construct the object in the first place; for instance, the java.net.URLConnection.
What’s interesting is the data contained in the documents they point to.
The URL class has several methods that retrieve data from a URL:
If you need more control nection which you can configure, and then get an InputStream from it.
We’ll take this may give you a more complete object such as String or an Image.
Then again, it may just give you an InputStream anyway.
The data you get from this InputStream is the raw (i.e., uninterpreted) content the URL references: ASCII if you’re reading an ASCII text file, raw HTML if you’re reading an HTML file, binary image data if you’re reading an image file, and so forth.
It does not include any of the HTTP headers or any other protocol-related information.
You can read from this InputStream as you would read from any other InputStream.
The preceding code fragment catches an IOException, which also catches the Malfor medURLException that the URL constructor can throw, since MalformedURLException subclasses IOException.
As with most network streams, reliably closing the stream takes a bit of effort.
In Java 6 and earlier, we use the dispose pattern: declare the stream variable outside the try block, set it to null, and then close it in the finally block if it’s not null.
Java 7 makes this somewhat cleaner by using a nested try-with-resources statement:
Example 5-2 reads a URL from the command line, opens an InputStream from that URL, chains the resulting InputStream to an InputStreamReader using the default data located at the URL if the URL references an HTML file; the program’s output is raw HTML.
Open the URL for reading // buffer the input to increase performance // chain the InputStream to a Reader int c; // ignore.
And here are the first few lines of output when SourceViewer downloads http:// www.oreilly.com:
There are quite a few more lines in that web page; if you want to see them, you can fire up your web browser.
The shakiest part of this program is that it blithely assumes that the URL points to text, which is not necessarily true.
It could well be pointing to a GIF or JPEG image, an MP3 sound file, or something else entirely.
Even if does resolve to text, the document encoding may not be the same as the default encoding of the client system.
The remote host and local client may not have the same default character set.
As a general rule, for pages that use a character set radically different from ASCII, the HTML will include a META tag in the header specifying the character set in use.
For instance, this META tag specifies the Big-5 encoding for Chinese:
An XML document will likely have an XML declaration instead:
In practice, there’s no easy way to get at this information other than by parsing the file and looking for a header like this one, and even that approach is limited.
Many HTML files handcoded in Latin alphabets don’t have such a META tag.
And as if this isn’t confusing enough, the HTTP header that precedes the actual document is likely to have its own encoding information, which may completely contradict what the document itself says.
You can’t read this header using the URL class, but you Web.
You should use this method when you want to communicate directly with the server.
The URLConnection gives you access to everything sent by the server: in addition to the document itself in its raw form (e.g., HTML, plain text, binary image data), you can access all the metadata specified by the protocol.
For example, if the scheme is HTTP or HTTPS, the URLConnection lets you access the HTTP headers as well as the raw HTML.
The URLConnection class also lets you write data to as well as read from a URL —for instance, in order to send email to a mailto URL or post form data.
The URLCon nection class will be the primary subject of Chapter 7
An overloaded variant of this method specifies the proxy server to pass the connection through:
This overrides any proxy server set with the usual socksProxyHost, socksProxyPort, http.proxyHost, http.proxyPort, http.nonProxyHosts, and similar system properties.
If the protocol handler does not support proxies, the argument is ignored and the connection is made directly if possible.
If the URL refers to some kind of text such as an ASCII or HTML file, the object returned is usually some sort of InputStream.
What unifies these two disparate classes is that they are not the thing itself but a means by which a program can construct the thing:
If the server does not use MIME headers or sends an unfamiliar can be read.
An IOException is thrown if the object can’t be retrieved.
The exact class may vary from one version of Java to the next (in earlier versions, it’s been java.io.PushbackInputStream or sun.net.www.http.KeepAliveStream) but it should be some form of InputStream.
Here’s what you get when you try to load a header image from that page:
The last result is the most unusual because it is as close as the Java core API gets to a class that represents a sound file.
It’s not just an interface through which you can load the sound data.
You could get some kind of InputStream or an ImageProducer or perhaps an AudioClip; it’s easy to check using the instanceof operator.
This information should be enough to let you read a text file or display an image.
A URL’s content handler may provide different views of a resource.
The method attempts to return the URL’s content in the first available format.
For instance, if you prefer an HTML file to be returned as a String, but your second choice is a Reader and your third choice is an InputStream, write:
If the content handler knows how to return a string representation of the resource, then it returns a String.
If it doesn’t know how to return a string representation of the resource, then it returns a Reader.
And if it doesn’t know how to present the resource as a reader, then it returns an InputStream.
You have to test for the type of the returned object using instanceof.
Splitting a URL into Pieces URLs are composed of five pieces:
The authority may further be divided into the user info, the host, and the port.
This has the user info admin, the host www.blackstar.com, and the port 8080
Read-only access to these parts of a URL is provided by nine public methods: get.
For example, if port number because it isn’t specified in the URL:
If no default port is defined for the protocol, then.
If the URL does not have a file part, Java sets the file to the empty string.
This information comes after the scheme and before the host; an @ symbol delimits it.
For instance, in the URL http://elharo@java.oreilly.com/, the user info is elharo.
However, most of the time, including a password in a URL is a security risk.
That’s because the URL specifies the remote recipient of the message rather than the username and host that’s sending the message.
Between the scheme and the path of a URL, you’ll find the authority.
This part of the URI indicates the authority that resolves the resource.
In the most general case, the authority includes the user info, the host, and the port.
For instance, in the URL the URL, with or without the user info and port.
Example 5-4 uses these methods to split URLs entered on the command line into their component parts.
Here’s the result of running this against several of the URL examples in this chapter:
The URL is http://www.oreilly.com The scheme is http The user info is null The host is www.oreilly.com The port is -1 The path is The ref is null The query string is null.
The scheme is http The user info is null The host is www.ibiblio.org The port is -1 The path is /nywc/compositions.phtml The ref is null.
Two URLs are considered equal if and only if both URLs point to the same resource on the same host, port, and path, with the same fragment identifier tries to resolve the host with DNS so that, for example, it can tell that http:// www.ibiblio.org/ and http://ibiblio.org/ are the same.
For example, http://www.oreilly.com/ is not equal to http:// www.oreilly.com/index.html; and http://www.oreilly.com:80 is not equal to http:// www.oreilly.com/
Example 5-5 creates URL objects for http://www.ibiblio.org/ and http://ibiblio.org/ and.
In the meantime, the main thing you need to know is that the URI class provides much more accurate, specification-conformant behavior than the URL class.
For operations like absolutization and encoding, you should prefer the URI class where you have the option.
You should also prefer the URI class if you need blocking.
The URL class should be used primarily when you want to download content from a server.
Most URIs used in practice are URLs, but most specifications and standards such as XML are defined in terms of URIs.
This class differs from the java.net.URL class in three important ways:
The URI class is purely about identification of resources and parsing of URIs.
It provides no methods to retrieve a representation of the resource identified by its URI.
The URI class is more conformant to the relevant specifications than the URL class.
In brief, a URL object is a representation of an application layer protocol for network retrieval, whereas a URI object is purely for string parsing and manipulation.
The URI behave exactly as the relevant specifications say they should.
Normally, you should use the URL class when you want to download the content at a URL and the URI class when you want to use the URL for identification rather than retrieval, for instance, to represent an XML namespace.
When you need to do both, you may convert from a URI to a URL.
You can either pass the entire URI to the constructor in a single string, or the individual pieces:
Unlike the URL class, the URI class does not depend on an underlying protocol handler.
As long as the URI is syntactically correct, Java does not need to understand its protocol in order to create a representative URI object.
Thus, unlike the URL class, the URI class can be used for new and experimental URI schemes.
The first constructor creates a new URI object from any convenient string.
This is a checked exception, so either catch it or declare that the method where the constructor is invoked.
In contradiction to the URI specification, the characters used in the URI are not limited to ASCII.
They can include other Unicode characters, such as ø and é.
Syntactically, there are very few restrictions on URIs, especially once the need to encode non-ASCII characters is removed and relative URIs are allowed.
The second constructor that takes a scheme specific part is mostly used for nonhierarchical URIs.
The scheme is the URI’s protocol, such as http, urn, tel, and so forth.
It must be composed exclusively of ASCII letters and digits and the three punctuation characters +, -, and ..
Passing null for this argument omits the scheme, thus creating a relative URI.
The scheme-specific part depends on the syntax of the URI scheme; it’s one thing for an http URL, another for a mailto URL, and something else again for a tel URI.
Because the URI class encodes illegal characters with percent escapes, there’s effectively no syntax error you can make in this part.
Finally, the third argument contains the fragment identifier, if any.
Again, characters that are forbidden in a fragment identifier are escaped automatically.
Passing null for this argument simply omits the fragment identifier.
The third constructor is used for hierarchical URIs such as http and ftp URLs.
The host and path together (separated by a /) form the scheme-specific part for this URI.
The fourth constructor is basically the same as the third, with the addition of a query string.
As usual, any unescapable syntax errors cause a URISyntaxException to be thrown and null can be passed to omit any of the arguments.
The fifth constructor is the master hierarchical URI constructor that the previous two invoke.
It divides the authority into separate user info, host, and port parts, each of which has its own syntax rules.
However, the resulting URI still has to follow all the usual rules for URIs; and again null can be passed for any argument to omit it from the result.
If you’re sure your URIs are legal and do not violate any of the rules, you can use the a URISyntaxException.
For example, this invocation creates a URI for anonymous FTP access using an email address as password:
If the URI does prove to be malformed, then an IllegalArgumentException is thrown by this method.
This is a runtime exception, so you don’t have to explicitly declare it or catch it.
The Parts of the URI A URI reference has up to three parts: a scheme, a scheme-specific part, and a fragment identifier.
If the scheme is omitted, the URI reference is relative.
If the fragment identifier is omitted, the URI reference is a pure URI.
These methods all return null if the particular URI object does not have the relevant component: for example, a relative URI without a scheme or an http URI without a fragment identifier.
A URI that has a scheme is an absolute URI.
The details of the scheme-specific part vary depending on the type of the scheme.
For example, in a tel URL, the scheme-specific part has the syntax of a telephone number.
However, in many useful URIs, including the very common file and http URLs, the scheme-specific part has a particular hierarchical format divided into an authority, a path, and a query string.
The authority is further divided into user info, host, and port.
If the URI is opaque, all you can get is the scheme, scheme-specific part, and fragment identifier.
However, if the URI is hierarchical, there are getter methods for all the different parts of a hierarchical URI:
Remember the URI class differs from the URI specification in that non-ASCII characters such as é and ü are never percent escaped in the first place, and thus will still be present to construct the URI object were encoded.
For various technical reasons that don’t have a lot of practical impact, Java can’t always initially detect syntax errors in the authority component.
The immediate symptom of this failing is normally an inability to return the individual parts of the authority, port, authority to be reparsed:
The original URI does not change (URI objects are immutable), but the URI returned will have separate authority parts for user info, host, and port.
If the authority cannot be parsed, a URISyntaxException is thrown.
Example 5-6 uses these methods to split URIs entered on the command line into their component parts.
It’s similar to Example 5-4 but works with any syntactically correct URI, not just the ones Java has a protocol handler for.
System.out.println("The scheme specific part is " // Must be a registry based authority.
Here’s the result of running this against three of the URI examples in this section:
The scheme is tel The scheme specific part is +1-800-9988-9938 The fragment ID is null.
Resolving Relative URIs The URI class has three methods for converting back and forth between relative and absolute URIs:
After they’ve executed, resolved contains the absolute URI http://www.example.com/ images/logo.png.
It’s also possible to reverse this procedure; that is, to go from an absolute URI to a relative is relative to the invoking URI.
The URI object relative now contains the relative URI images/logo.png.
Equality and Comparison URIs are tested for equality pretty much as you’d expect.
The scheme and authority parts are compared without considering case.
That is, http and HTTP are the same scheme, and www.example.com is the same authority as www.EXAMPLE.com.
The rest of the URI is case sensitive, except for hexadecimal digits used to escape illegal characters.
The ordering is based on string comparison of the individual parts, in this sequence:
If the schemes are different, the schemes are compared, without considering case.
If both URIs are hierarchical, they’re ordered according to their authority components, which are themselves ordered according to user info, host, and port, in that order.
If the schemes and the authorities are equal, the path is used to distinguish them.
If the paths are also equal, the query strings are compared.
If the query strings are equal, the fragments are compared.
Comparing a URI to anything except another URI causes a ClassCastException.
Therefore, the result of calling this method is not guaranteed to be a syntactically correct URI, though it is in fact a syntactically correct IRI.
This form is sometimes useful for display to human beings, but usually not for retrieval.
This is the string form of the URI you should use most of the time.
These differences can cause problems with URLs: for example, some operating systems allow spaces in filenames; some don’t.
Other special characters, nonalphanumeric characters, and so on, all of which may have a special meaning inside a URL or on another operating system, present similar problems.
Furthermore, Unicode was not yet ubiquitous when the Web was invented, so not all systems could handle characters such as é and 本.
To solve these problems, characters used in URLs must come from a fixed subset of ASCII, specifically:
If these characters occur as part of a path or query string, they and all other characters should be encoded.
Any characters that are not ASCII numerals, letters, or the punctuation marks specified earlier are converted into bytes and each byte is written as a percent sign followed by two hexadecimal digits.
Besides being encoded as %20, they can be encoded as a plus sign encoded when they are used as part of a name, and not as a separator between parts of the URL.
You can construct URL objects that use illegal ASCII and non-ASCII characters and/or percent escapes.
Such characters and escapes are not automatically encoded or decoded when output by methods such characters are properly encoded in the strings used to construct a URL object.
Luckily, Java provides URLEncoder and URLDecoder classes to cipher strings in this format.
URLEncoder To URL encode a string, pass the string and the character set name to the URLEncod.
This method is a little overaggressive; it also converts tildes, single quotes, exclamation points, and parentheses to percent escapes, even though they don’t absolutely have to be.
However, this change isn’t forbidden by the URL specification, so web browsers deal reasonably with these excessively encoded URLs.
Although this method allows you to specify the character set, the only such character set you should ever pick is UTF-8
UTF-8 is compatible with the IRI specification, the URI class, modern web browsers, and more additional software than any other encoding you could choose.
Here is the output (note that the code needs to be saved in something other than ASCII, and the encoding chosen should be passed as an argument to the compiler to account for the non-ASCII characters in the source code):
Notice in particular that this method encodes the forward slash, the ampersand, the equals sign, and the colon.
It does not attempt to determine how these characters are being used in a URL.
Consequently, you have to encode URLs piece by piece rather than encoding an entire URL in one method call.
This is an important point, because the most common use of URLEncoder is preparing query strings for communicating with server-side programs that use GET.
For example, suppose you want to encode this URL for a Google search:
Consequently, URLs need to be encoded a piece at a time like this:
In this case, you could have skipped encoding several of the constant strings such as “Java” because you know from inspection that they don’t contain any characters that need to be encoded.
However, in general, these values will be variables, not constants; and you’ll need to encode each piece to be safe.
Example 5-8 is a QueryString class that uses URLEncoder to encode successive name and value pairs in a Java object, which will be used for sending data to server-side encoded name-value pairs.
Using this class, we can now encode the previous example:
That is, it converts all plus signs to spaces and all percent escapes to their corresponding character:
If you have any doubt about which encoding to use, pick UTF-8
An IllegalArgumentException should be thrown if the string contains a percent sign that isn’t followed by two hexadecimal digits or decodes into an illegal sequence.
Since URLDecoder does not touch non-escaped characters, you can pass an entire URL to it rather than splitting it into pieces first.
Proxies Many systems access the Web and sometimes other non-HTTP parts of the Internet through proxy servers.
A proxy server receives a request for a remote server from a local client.
The proxy server makes the request to the remote server and forwards the result back to the local client.
Sometimes this is done for security reasons, such as to prevent remote hosts from learning private details about the local network configuration.
Other times it’s done to prevent users from accessing forbidden sites by filtering outgoing requests and limiting which sites can be viewed.
For instance, an elementary school might want to block access to http://www.playboy.com.
And still other times it’s done purely for performance, to allow multiple users to retrieve the same popular documents from a local cache rather than making repeated downloads from the remote server.
Java programs based on the URL class can work through most common proxy servers and protocols.
Indeed, this is one reason you might want to choose to use the URL class rather than rolling your own HTTP or other client on top of raw sockets.
System Properties For basic operations, all you have to do is set a few system properties to point to the addresses of your local proxy servers.
If you are using a pure HTTP proxy, set http.proxyHost to the domain name or the IP address of your proxy server and http.proxyPort to the port of the proxy server (the default is 80)
There are several or using the -D options when launching the program.
If you want to exclude a host from being proxied and connect directly instead, set the http.nonProxyHosts system property to its hostname or IP address.
To exclude multiple hosts, separate their names by vertical bars.
For example, this code fragment proxies everything except java.oreilly.com and xml.oreilly.com:
You can also use an asterisk as a wildcard to indicate that all the hosts within a particular domain or subdomain should not be proxied.
For example, to proxy everything except hosts in the oreilly.com domain:
If you are using an FTP proxy server, set the ftp.proxyHost, ftp.proxyPort, and ftp.nonProxyHosts properties in the same way.
Java does not support any other application layer proxies, but if you’re using a transport layer SOCKS proxy for all TCP connections, you can identify it with the socksProxy Host and socksProxyPort system properties.
Java does not provide an option for nonproxying with SOCKS.
The Proxy Class The Proxy class allows more fine-grained control of proxy servers from within a Java program.
Specifically, it allows you to choose different proxy servers for different remote hosts.
The proxies themselves are represented by instances of the java.net.Proxy class.
There are still only three kinds of proxies, HTTP, SOCKS, and direct connections (no proxy at all), represented by three constants in the Proxy.Type enum:
Besides its type, the other important piece of information about a proxy is its address and port, given as a SocketAddress object.
For example, this code fragment creates a Proxy object representing an HTTP proxy server on port 80 of proxy.example.com:
Although there are only three kinds of proxy objects, there can be many proxies of the same type for different proxy servers on different hosts.
The ProxySelector Class Each running virtual machine has a single java.net.ProxySelector object it uses to locate the proxy server for different connections.
The default ProxySelector merely inspects the various system properties and the URL’s protocol to decide how to connect to different hosts.
However, you can install your own subclass of ProxySelector in place of the default selector and use it to choose different proxies based on protocol, host, path, time of day, or other criteria.
Java passes this method a URI object (not a URL object) representing the host to which a connection is needed.
For a connection made with the URL class, this object typically has the form http://www.example.com/ or ftp://ftp.example.com/pub/files/, for example.
For a pure TCP connection made with the Socket class, this URI will have the form socket://host:port:, for instance, socket://www.example.com:80
The ProxySelector object then chooses the right proxies for this type of object and returns them in a List<Proxy>
This is a callback method used to warn a program that the proxy server isn’t actually making the connection.
Example 5-9 demonstrates with a ProxySelector that attempts to use the proxy server at proxy.example.com for all HTTP connections unless the proxy server has previously failed to resolve a connection to a particular URL.
As I said, each virtual machine has exactly one ProxySelector.
From this point forward, all connections opened by that virtual machine will ask the ProxySelector for the right proxy to use.
You normally shouldn’t use this in code running in a shared environment.
For instance, you wouldn’t change the ProxySelector in a servlet because that would change the ProxySelector for all servlets running in the same container.
Communicating with Server-Side Programs Through GET The URL class makes it easy for Java applets and applications to communicate with serverside programs such as CGIs, servlets, PHP pages, and others that use the GET method.
Server-side programs that use the POST method require the URLConnection class and.
Then you can construct a URL with a query string chapter.
There are a number of ways to determine the exact syntax for a query string that talks to a particular program.
If you’ve written the server-side program yourself, you already know the name-value pairs it expects.
If you’ve installed a third-party program on your own server, the documentation for that program should tell you what it expects.
If you’re talking to a documented external network API such as the eBay Shopping API, then the service usually provides fairly detailed documentation to tell you exactly what data to send for which purposes.
If this is the case, it’s straightforward to figure out what input the program expects.
The method the form uses should be the value of the METHOD attribute of the FORM element.
This value should be either GET, in which case you use the process described here, or POST, in which case you use the process described in Chapter 7
The part of the URL that precedes the query string is given by the value of the ACTION attribute of the FORM element.
Note that this may be a relative URL, in which case you’ll need to determine the corresponding absolute URL.
Finally, the names in the name-value pairs are simply the values of the NAME attributes of the INPUT elements.
The values of the pairs are whatever the user types into the form.
For example, consider this HTML form for the local search engine on my Cafe con Leche site.
The program that processes the form is accessed via the URL http://www.google.com/search.
It has four separate name-value pairs, three of which have default values:
For instance, it doesn’t matter if it’s a set of checkboxes, a pop-up list, or a text field.
Only the name of each INPUT field and the value you give it is significant.
The submit input tells the web browser when to send the data but does not give the server any extra information.
Sometimes you find hidden INPUT fields that must have particular required default values.
There are many different form tags in HTML that produce pop-up.
However, although these input widgets appear different to the user, the format of data they send to the server is the same.
Each form element provides a name and an encoded string value.
In some cases, the program you’re talking to may not be able to handle arbitrary text strings for values of particular inputs.
However, since the form is meant to be read and filled in by human beings, it should provide sufficient clues to figure out what input is expected; for instance, that a particular field is supposed to be a two-letter state abbreviation or a phone number.
There may not even be a form, just links to follow.
In this case, you have to do some experimenting, first copying some existing values and then tweaking them to see what values are and aren’t accepted.
You don’t need to do this in a Java program.
You can simply edit the URL in the address or location bar of your web browser window.
The likelihood that other hackers may experiment with your own server-side programs in such a fashion is a good reason to make them extremely robust against unexpected input.
Regardless of how you determine the set of name-value pairs the server expects, communicating with it once you know them is simple.
All you have to do is create a query string that includes the necessary name-value pairs, then form a URL that includes that query string.
Send the query string to the server and read its response using the same methods you use to connect to a server and retrieve a static HTML page.
There’s no special protocol to follow once the URL is constructed.
There is a special protocol to follow for the POST method, however, which is why discussion of that method will have to wait until Chapter 7.)
To demonstrate this procedure, let’s write a very simple command-line program to look up topics in the Open Directory.
This site is shown in Figure 5-1 and it has the advantage of being really simple.
The Open Directory interface is a simple form with one input field named search; input typed in this field is sent to a program at http://search.dmoz.org/cgi-bin/search, which does the actual search.
There are only two input fields in this form: the Submit button and a text field named q.
Thus, to submit a search request to the Open Directory, you just need to append.
Of course, a lot more effort could be expended on parsing and displaying the results.
But notice how simple the code was to talk to this server.
Aside from the funky-looking URL and the slightly greater likelihood that some pieces of it need to be x-www-formurl-encoded, talking to a server-side program that uses GET is no harder than retrieving any other HTML page.
Accessing Password-Protected Sites Many popular sites require a username and password for access.
Some sites, such as the W3C member pages, implement this through HTTP authentication.
Others, such as the New York Times website, implement it through cookies and HTML forms.
Supporting sites that use nonstandard, cookie-based authentication is more challenging, not least because this varies a lot from one site to another.
Implementing cookie authentication is hard short of implementing a complete web browser with full HTML forms and cookie support; we’ll discuss Java’s cookie support in Chapter 7
Accessing sites protected by standard HTTP authentication is much easier.
The Authenticator Class The java.net package includes an Authenticator class you can use to provide a username and password for sites that protect themselves using HTTP authentication:
Since Authenticator is an abstract class, you must subclass it.
For example, a character mode program might just ask the user to type the username and password on System.in.
A GUI program would likely put up a dialog box like the one shown in Figure 5-2
An automated robot might read the username out of an encrypted file.
To make the URL class use the subclass, install it as the default authenticator by passing.
For example, if you’ve written an Authenticator subclass named DialogAuthentica tor, you’d install it like this:
From this point forward, when the URL class needs a username and password, it will ask the DialogAuthenticator using the static Authen.
The address argument is the host for which authentication is required.
The port argument is the port on that host, and the protocol argument is the application layer protocol by which the site is being accessed.
It’s typically the name of the realm for which authentication is required.
Some large web servers such as www.ibiblio.org have multiple realms, each of which requires different usernames and passwords.) The scheme is the authentication scheme being used.
Here the word scheme is not being used as a synonym for protocol.
Untrusted applets are not allowed to ask the user for a name and password.
Trusted applets can do so, but only if they possess the requestPasswordAuthentication Net a SecurityException.
If you don’t want to authenticate this request, return null, and Java will tell the server it doesn’t know how to authenticate the connection.
If you submit an incorrect username chance to provide the right data.
You normally have five tries to get the username and.
Usernames and passwords are cached within the same virtual machine session.
Once you set the correct password for a realm, you shouldn’t be asked for it again unless you’ve explicitly deleted the password by zeroing out the char array that contains it.
You can get more details about the request by invoking any of these methods inherited from the Authenticator superclass:
These methods either return the information as given in the last call to requestPass.
The PasswordAuthentication Class PasswordAuthentication is a very simple final class that supports two read-only properties: username and password.
The password is a char array so that the password can be erased when it’s no longer needed.
A String would have to wait to be garbage collected before it could be erased, and even then it might still exist somewhere in memory on the local system, possibly even on disk if the block of memory that contained it had been swapped out to virtual memory at one point.
The JPasswordField Class One useful tool for asking users for their passwords in a more or less secure fashion is the JPasswordField component from Swing:
This lightweight component behaves almost exactly like a text field.
However, anything the user types into it is echoed as an asterisk.
This way, the password is safe from anyone looking over the user’s shoulder at what’s being typed on the screen.
JPasswordField also stores the passwords as a char array so that when you’re done with to return this:
Otherwise, you mostly use the methods it inherits from the JTextField superclass.
Example 5-11 demonstrates a Swing-based Authenticator subclass that brings up a dialog to ask the user for his username and password.
A JPasswordField collects the password and a simple JTextField retrieves the username.
Flip back to Figure 5-2 to see the rather simple dialog box this produces.
The password is returned as an array of // chars for security reasons.
Example 5-12 is a revised SourceViewer program that asks the user for a name and password using the DialogAuthenticator class.
Open the URL for reading // chain the InputStream to a Reader int c;
Since we used the AWT, we have to explicitly exit.
The Hypertext Transfer Protocol (HTTP) is a standard that defines how a web client talks to a server and how data is transferred from the server back to the client.
Although HTTP is usually thought of as a means of transferring HTML files and the pictures embedded in them, HTTP is data format agnostic.
It can be used to transfer TIFF pictures, Microsoft Word documents, Windows .exe files, or anything else that can be represented in bytes.
To write programs that use HTTP, you’ll need to understand HTTP at a deeper level than the average web page designer.
This chapter goes behind the scenes to show you what actually happens when you type http://www.google.com into the browser’s address bar and press Return.
The Protocol HTTP is the standard protocol for communication between web browsers and web servers.
For each request from client to server, there is a sequence of four steps:
The client opens a TCP connection to the server on port 80, by default; other ports may be specified in the URL.
The client sends a message to the server requesting the resource at a specified path.
The request includes a header, and optionally (depending on the nature of the request) a blank line followed by data for the request.
The response begins with a response code, followed by a header full of metadata, a blank line, and the requested document or an error message.
In HTTP 1.1 and later, multiple requests and responses can be sent in series over a single TCP connection.
Furthermore, in HTTP 1.1, requests and responses can be sent in multiple chunks.
Each request and response has the same basic form: a header line, an HTTP header containing metadata, a blank line, and then a message body.
The first line is called the request line, and includes a method, a path to a resource, and the version of HTTP.
The GET method asks the server to return a representation of a resource.
HTTP/1.1 is the version of the protocol that the client understands.
Although the request line is all that is required, a client request usually includes other information as well in a header.
If a value is too long, you can add a space or tab to the beginning of the next line and continue it.
Lines in the header are terminated by a carriage-return linefeed pair.
The first keyword in this example is User-Agent, which lets the server know what browser is being used and allows it to send files optimized for the particular browser type.
The following line says that the request comes from version 2.4 of the Lynx browser:
All but the oldest first-generation browsers also include a Host field specifying the server’s name, which allows web servers to distinguish between different named hosts served from the same IP address:
The last keyword in this example is Accept, which tells the server the types of data the client can handle (though servers often ignore this)
For example, the following line says that the client can handle four MIME media types, corresponding to HTML documents, plain text, and JPEG and GIF images:
The type shows very generally what kind of data is contained: is it a picture, text, or movie? The subtype identifies the specific type of data: GIF image, JPEG image, TIFF image.
For example, HTML’s content type is text/html; the type is text, and the subtype is html.
The content type for a JPEG image is image/jpeg; the type is image, and the subtype is jpeg.
The most current list of registered MIME types is available from http://www.iana.org/ assignments/media-types/
In addition, nonstandard custom types and subtypes can be freely defined as long as they begin with x-
For example, Flash files are commonly assigned the type application/x-shockwave-flash.
Once the server sees that blank line, it begins sending its response to the client over the same connection.
A Sample HTML file The rest of the document goes here.
The first line indicates the protocol the server is using (HTTP/1.1), followed by a response code.
Table 6-1 lists the standard and experimental response codes you’re most likely to encounter, minus a few used by WebDAV.
Continue The server is prepared to accept the request body and the client should send it; allows clients to ask whether the server will accept a request before they send a large amount of data as part of the request.
The server accepts the client’s request in the Upgrade header field to change the application protocol (e.g., from HTTP to WebSockets.)
POST, the requested data is contained in the response along with the usual headers.
If the request method was HEAD, only the header information is included.
Created The server has created a resource at the URL specified in the body of the response.
This code is only sent in response to POST requests.
Accepted This rather uncommon response indicates that a request (generally from POST) is being processed, but the processing is not yet complete, so no response can be returned.
However, the server should return an HTML page that explains the situation to the user and provide an estimate of when the request is likely to be completed, and, ideally, a link to a status monitor of some kind.
The resource representation was returned from a caching proxy or other local source and is not guaranteed to be up to date.
No Content The server has successfully processed the request but has no information to send back to the client.
This is normally the result of a poorly written form-processing program on the server that accepts data but does not return a response to the user.
Reset Content The server has successfully processed the request but has no information to send back to the client.
Furthermore, the client should clear the form to which the request is sent.
Partial Content The server has returned the part of the resource the client requested using the byte range extension to HTTP, rather than the whole document.
Multiple Choices The server is providing a list of different representations (e.g., PostScript and PDF) for the requested document.
The client should automatically load the resource at this URL and update any bookmarks that point to the old URL.
The resource is at a new URL temporarily, but its location will change again in the foreseeable future; therefore, bookmarks should not be updated.
Sometimes used by proxies that require the user to log in locally before accessing the Web.
See Other Generally used in response to a POST form request, this code indicates that the user should retrieve a resource from a different URL using GET.
Not Modified The If-Modified-Since header indicates that the client wants the document only if it has been recently updated.
This status code is returned if the document has not been updated.
In this case, the client should load the document from its cache.
Use Proxy The Location header field contains the address of a proxy that will serve the response.
Similar to 302 but without allowing the HTTP method to change.
Similar to 301 but without allowing the HTTP method to change.
Bad Request The client request to the server used improper syntax.
This is rather unusual in normal web browsing but more common when debugging custom clients.
Unauthorized Authorization, generally a username and password, is required to access this page.
Either a username and password have not yet been presented or the username and password are invalid.
Payment Required Not used today, but may be used in the future to indicate that some sort of payment is required to access the resource.
Forbidden The server understood the request, but is deliberately refusing to process it.
This is sometimes used when a client has exceeded its quota.
Not Found This most common error response indicates that the server cannot find the requested resource.
It may indicate a bad link, a document that has moved with no forwarding address, a mistyped URL, or something similar.
The request method is not allowed for the specified resource; for instance, you tried to PUT a file on a web server that doesn’t support PUT or tried to POST to a URI that only allows GET.
Not Acceptable The requested resource cannot be provided in a format the client is willing to accept, as indicated by the Accept field of the request HTTP header.
An intermediate proxy server requires authentication from the client, probably in the form of a username and password, before it will retrieve the requested resource.
Request Timeout The client took too long to send the request, perhaps because of network congestion.
Conflict A temporary conflict prevents the request from being fulfilled; for instance, two clients are trying to PUT the same file at the same time.
Gone Like a 404, but makes a stronger assertion about the existence of the resource.
The resource has been deliberately deleted (not moved) and will not be restored.
Length Required The client must but did not send a Content-length field in the client request HTTP header.
A condition for the request that the client specified in the request HTTP header is not satisfied.
The body of the client request is larger than the server is able to process at this time.
The server does not understand or accept the MIME content type of the request body.
The server cannot send the byte range the client requested.
Expectation Failed The server cannot meet the client’s expectation given in an Expectrequest header field.
The content type of the request body is recognized, and the body is syntactically correct, but nonetheless the server can’t process it.
Either the header as a whole is too large, or one particular header field is too large.
Experimental; the server is prohibited by law from servicing the request.
An unexpected condition occurred that the server does not know how to handle.
Not Implemented The server does not have a feature that is needed to fulfill this request.
A server that cannot handle PUT requests might send this response to a client that tried to PUT form data to it.
Bad Gateway This code is applicable only to servers that act as proxies or gateways.
It indicates that the proxy received an invalid response from a server it was connecting to in an effort to fulfill the request.
The server is temporarily unable to handle the request, perhaps due to overloading or maintenance.
Gateway Timeout The proxy server did not receive a response from the upstream server within a reasonable amount of time, so it can’t send the desired response to the client.
The server does not support the version of HTTP the client is using (e.g., the as-yet-nonexistent HTTP 2.0)
Server does not have enough space to store the supplied request entity; typically used for POST or PUT.
The client needs to authenticate to gain network access (e.g., on a hotel wireless network)
Keep-Alive HTTP 1.0 opens a new connection for each request.
In practice, the time taken to open and close all the connections in a typical web session can outweigh the time taken to transmit the data, especially for sessions with many small documents.
In HTTP 1.1 and later, the server doesn’t have to close the socket after it sends its response.
It can leave it open and wait for a new request from the client on the same socket.
Multiple requests and responses can be sent in series over a single TCP connection.
However, the lockstep pattern of a client request followed by a server response remains the same.
A client indicates that it’s willing to reuse a socket by including a Connection field in the HTTP request header with the value Keep-Alive:
The URL class transparently supports HTTP Keep-Alive unless explicitly turned off.
That is, it will reuse a socket if you connect to the same server again before the server has closed the connection.
You can control Java’s use of HTTP Keep-Alive with several system properties:
Set http.maxConnections to the number of sockets you’re willing to hold open at one time.
Set http.keepAlive.remainingData to true to let Java clean up after abandoned connections (Java 6 or later)
Set sun.net.http.errorstream.bufferSize to the number of bytes to use for buffering error streams.
Set sun.net.http.errorstream.timeout to the number of milliseconds before timing out a read from the error stream.
The defaults are reasonable, except that you probably do want to set sun.net.http.er rorstream.enableBuffering to true unless you want to read the error streams from failed requests.
However, these optimizations are usually performed in a translation layer that shields application programmers from the details, so the code you write will still mostly follow the preceding steps 1–4
Java does not yet support HTTP 2.0; but when the capability is added, your programs shouldn’t need to change to take advantage of it, as long as you access HTTP servers via the URL and URLConnection classes.
A start line containing the HTTP method and a path to the resource on which the method should be executed.
A header of name-value fields that provide meta-information such as authentication credentials and preferred formats to be used in the request.
A request body containing a representation of a resource (POST and PUT only)
There are four main HTTP methods, four verbs if you will, that identify the operations that can be performed:
If that seems like too few, especially compared to the infinite number of object-oriented methods you may be accustomed to designing programs around, that’s because HTTP puts most of the emphasis on the nouns: the resources identified by URIs.
The uniform interface provided by these four methods is sufficient for nearly all practical purposes.
Furthermore, its output is often cached, though that can be controlled with the right headers, as you’ll see shortly.
In a properly architected system, GET requests can be bookmarked and prefetched without concern.
By contrast, a well-behaved browser or web spider will not POST to a link without explicit user action.
The PUT method uploads a representation of a resource to the server at a known URL.
That is, it can be repeated without concern if it fails.
Putting the same document in the same place on the same server twice in a row leaves the server in the same state as only putting it once.
The DELETE method removes a resource from a specified URL.
It too uploads a representation of a resource to a server at a known URL, but it does not specify what the server is to do with the newly supplied resource.
For instance, the server does not necessarily have to make that resource available at the target URL, but may instead move it to a different URL.
Or the server might use the data to update the state of one or more completely different resources.
Because GET requests include all necessary information in the URL, they can be bookmarked, linked to, spidered, and so forth.
The other methods, especially POST, are intended for actions that commit to something.
For example, adding an item to a shopping cart should send a GET, because this action doesn’t commit; the user can still abandon the cart.
However, placing the order should send a POST because that action makes a commitment.
This is why browsers ask you if you’re sure when you go back to a page that uses POST (as shown in Figure 6-1)
Reposting data may buy two copies of a book and charge your credit card twice.
In practice, POST is vastly overused on the Web today.
Any safe operation that does not commit the user to anything should use GET rather than POST.
One sometimes mistaken reason for preferring POST over GET is when forms require large amounts of input.
There’s an outdated misconception that browsers can only work with query strings of a few hundred bytes.
If you have more form data to submit than that, you may indeed need to support POST; but safe operations should still prefer GET for nonbrowser clients.
You usually only exceed those limits if you’re uploading data to the server to create a new resource, rather than merely locating an existing resource on the server; and in these cases POST or PUT is usually the right answer anyway.
In addition to these four main HTTP methods, a few others are used in special circumstances.
The most common such method is HEAD, which acts like a GET except it only returns the header for the resource, not the actual data.
This is commonly used to check the modification date of a file, to see whether a copy stored in the local cache is still valid.
The other two that Java supports are OPTIONS, which lets the client ask the server what it can do with a specified resource; and TRACE, which echoes back the client request for debugging purposes, especially when proxy servers are misbehaving.
Different servers recognize other nonstandard methods including COPY and MOVE, but Java does not send these.
The URL class described in the previous chapter uses GET to communicate with HTTP servers.
The URLConnection class (coming up in the Chapter 7) can use all four of these methods.
The Request Body The GET method retrieves a representation of a resource identified by a URL.
The exact location of the resource you want to GET from a server is specified by the various parts of the path and query string.
How different paths and query strings map to different resources is determined by the server.
As long as it knows the URL, it can download from it.
In these cases, the client supplies the representation of the resource, in addition to the path and the query string.
The representation of the resource is sent in the body of the request, after the header.
For example, this POST request sends form data to a server:
In this example, the body contains an application/x-www-form-urlencoded data, but that’s just one possibility.
However, the HTTP header should include two fields that specify the nature of the body:
A Content-length field that specifies how many bytes are in the body (54 in the preceding example)
A Content-type field that specifies the MIME media type of the bytes (application/ x-www-form-urlencoded in the preceeding example)
The application/x-www-form-urlencoded MIME type used in the preceding example is common because it’s how web browsers encode most form submissions.
Thus it’s used by a lot of server-side programs that talk to browsers.
However, it’s hardly the only possible type you can send in the body.
For example, a camera uploading a picture to a photo sharing site can send image/jpeg.
For example, here’s a PUT request that uploads an Atom document:
Cookies Many websites use small strings of text known as cookies to store persistent client-side state between connections.
Cookies are passed from server to client and back again in the HTTP headers of requests and responses.
Cookies can be used by a server to indicate session IDs, shopping cart contents, login credentials, user preferences, and more.
For instance, a cookie set by an online bookstore might have the value However, more likely, the value is a meaningless string such as ATVPDKIKX0DER, which identifies a particular record in a database of some kind where the real information is kept.
Usually the cookie values do not contain the data but merely point to it on the server.
Cookies are limited to nonwhitespace ASCII text, and may not contain commas or semicolons.
To set a cookie in a browser, the server includes a Set-Cookie header line in the HTTP header.
If a browser makes a second request to the same server, it will send the cookie back in a Cookie line in the HTTP request header like so:
As long as the server doesn’t reuse cookies, this enables it to track individual users and sessions across multiple, otherwise stateless, HTTP connections.
For example, a request I just made to Amazon fed my browser five cookies:
For example, by default, a cookie applies to the server it came from.
If a cookie is originally set by www.foo.example.com, the browser will only send the cookie back to www.foo.example.com.
However, a site can also indicate that a cookie applies within an.
For example, this request sets a user cookie for the entire foo.example.com domain:
The browser will echo this cookie back not just to www.foo.example.com, but also to lothar.foo.example.com, eliza.foo.example.com, enoch.foo.example.com, and any other host somewhere in the foo.example.com domain.
However, a server can only set cookies for domains it immediately belongs to.
Websites work around this restriction by embedding an image or other content hosted on one domain in a page hosted at a second domain.
The cookies set by the embedded content, not the page itself, are called third-party cookies.
Many users block all third-party cookies, and some web browsers are starting to block them by default for privacy reasons.
Cookies are also scoped by path, so they’re returned for some directories on the server, but not all.
The default scope is the original URL and any subdirectories.
For instance, if a cookie is set for the URL http://www.cafeconleche.org/XOM/, the cookie also applies in http://www.cafeconleche.org/XOM/apidocs/, but not in http://www.cafeconleche.org/ slides/ or http://www.cafeconleche.org/
However, the default scope can be changed using a Path attribute in the cookie.
When requesting a document in the subtree /restricted from the same server, the client echoes that cookie back.
However, it does not use the cookie in other directories on the site.
A cookie can include both a domain and a path.
For instance, this cookie applies in the /restricted path on any servers within the example.com domain:
The order of the different cookie attributes doesn’t matter, as long as they’re all separated by semicolons and the cookie’s own name and value come first.
However, this isn’t true when the client is sending the cookie back to the server.
In this case, the path must precede the domain, like so:
A cookie can be set to expire at a certain point in time by setting the expires attribute to a date in the form Wdy, DD-Mon-YYYY HH:MM:SS GMT.
The rest are numeric, padded with initial zeros if necessary.
In the pattern language used by java.text.SimpleDateFormat, this is E, dd-MMM-yyyy H:m:s z.
The browser should remove this cookie from its cache after that date has passed.
The Max-Age attribute that sets the cookie to expire after a certain number of seconds have passed instead of at a specific moment.
For instance, this cookie expires one hour (3,600 seconds) after it’s first set:
The browser should delete this cookie after this amount of time has elapsed.
Because cookies can contain sensitive information such as passwords and session keys, some cookie transactions should be secure.
Most of the time this means using HTTPS instead of HTTP; but whatever it means, each cookie can have a secure attribute with no value, like so:
Browsers are supposed to refuse to send such cookies over insecure channels.
For additional security against cookie-stealing attacks like XSRF, cookies can set the HttpOnly attribute.
This tells the browser to only return the cookie via HTTP and HTTPS and specifically not by JavaScript:
Amazon wants my browser to send these cookie with the request for any page in the amazon.com domain, for the next 30–33 years.
Of course, browsers are free to ignore all these requests, and users can delete or block cookies at any time.
CookieManager Java 5 includes an abstract java.net.CookieHandler class that defines an API for storing and retrieving cookies.
However, it does not include an implementation of that abstract class, so it requires a lot of grunt work.
Java 6 fleshes this out by adding a concrete java.net.CookieManager subclass of CookieHandler that you can use.
Before Java will store and return cookies, you need to enable it:
If all you want is to receive cookies from sites and send them back to those sites, you’re done.
After installing a CookieManager with those two lines of code, Java will store any cookies sent by HTTP servers you connect to with the URL class, and will send the stored cookies back to those same servers in subsequent requests.
However, you may wish to be a bit more careful about whose cookies you accept.
For example, this code fragment tells Java to block third-party cookies but accept firstparty cookies:
That is, it will only accept cookies for the server that you’re talking to, not for any server on the Internet.
If you want more fine-grained control, for instance to allow cookies from some known domains but not others, you can implement the CookiePolicy interface yourself and.
Example 6-1 shows a simple CookiePolicy that blocks cookies from .gov domains, but allows others.
A cookie policy that blocks all .gov cookies but allows others.
CookieStore It is sometimes necessary to put and get cookies locally.
For instance, when an application quits, it can save the cookie store to disk and load those cookies again when it next starts up.
You can retrieve the store in which the CookieManager saves its cookies with.
The CookieStore class allows you to add, remove, and list cookies so you can control the cookies that are sent outside the normal flow of HTTP requests and responses:
Each cookie in the store is encapsulated in an HttpCookie object that provides methods for inspecting the attributes of the cookie summarized in Example 6-2
Several of these attributes are not actually used any more.
In particular comment, comment URL, discard, and version are only used by the now obsolete Cookie 2 specification that never caught on.
URLConnection is an abstract class that represents an active connection to a resource specified by a URL.
First, it provides more control over the interaction with a server (especially an HTTP server) than the URL class.
A URLConnection can inspect the header sent by the server and respond accordingly.
It can set the header fields used in the client request.
Finally, a URLConnection can send data back to a web server with POST, PUT, and other HTTP request methods.
We will explore all of these techniques in this chapter.
Second, the URLConnection class is part of Java’s protocol handler mechanism, which also includes the URLStreamHandler class.
The idea behind protocol handlers is simple: they separate the details of processing a protocol from processing particular data types, providing user interfaces, and doing the other work that a monolithic web browser performs.
The base java.net.URLConnection class is abstract; to implement a specific protocol, you write a subclass.
For example, if the browser runs across a URL with a strange scheme, such as compress, rather than throwing up its hands and issuing an error message, it can download a protocol handler for this unknown protocol and use it to communicate with the server.
Only abstract URLConnection classes are present in the java.net package.
The concrete subclasses are hidden inside the sun.net package hierarchy.
Many of the methods and fields as well as the single constructor in the URLConnection class are protected.
In other words, they can only be accessed by instances of the URLConnection class or its subclasses.
It is rare to instantiate URLConnection objects directly in your source code; instead, the runtime environment creates these objects as needed, depending on the protocol in use.
The class (which is unknown at compile time) is then instantiated using.
URLConnection does not have the best-designed API in the Java class library.
One of several problems is that the URLConnection class is too closely tied to the HTTP protocol.
For instance, it assumes that each file transferred is preceded by a MIME header or something very much like one.
However, most classic protocols such as FTP and SMTP don’t use MIME headers.
Opening URLConnections A program that uses the URLConnection class directly follows this basic sequence of steps:
For instance, if the default setup for a particular kind of URL is acceptable, you can skip step 3
If you only want the data from the server and don’t care about any metainformation, or if the protocol doesn’t provide any metainformation, you can skip step 4
If you only want to receive data from the server but not send data to the server, you’ll skip step 6
Consequently, unless you’re subclassing URLConnection to handle a new kind of URL (i.e., writing a protocol handler), you create one of these objects by invoking the open.
You may find it convenient or necessary to override other methods in the a connection to a server and thus depends on the type of service (HTTP, FTP, and so method converts the URL to a filename in the appropriate directory, creates MIME information for the file, and then opens a buffered FileInputStream to the file.
The sun.net.www.http.HttpClient object, which is responsible for connecting to the server:
When a URLConnection is first constructed, it is unconnected; that is, the local and remote host cannot send and receive data.
Reading Data from a Server The following is the minimal set of steps needed to retrieve data from a URL using a URLConnection object:
Read from the input stream using the usual stream API.
Open the URLConnection for reading // chain the InputStream to a Reader int c;
It is no accident that this program is almost the same as Example 5-2
The output is identical as well, so I won’t repeat it here.
The differences between URL and URLConnection aren’t apparent with just a simple input stream as in this example.
URLConnection can configure the request parameters sent to the server.
URLConnection can write data to the server as well as read data from the server.
Reading the Header HTTP servers provide a substantial amount of information in the header that precedes each response.
For example, here’s a typical HTTP header returned by an Apache web server:
In general, an HTTP header may include the content type of the requested document, the length of the document in bytes, the character set in which the content is encoded, the date and time, the date the content expires, and the date the content was last modified.
However, the information depends on the server; some servers send all this information for each request, others send some information, and a few don’t send anything.
The methods of this section allow you to query a URL Connection to find out what metadata the server has provided.
Aside from HTTP, very few protocols use MIME headers (and technically speaking, even the HTTP header isn’t actually a MIME header; it just looks a lot like one)
When writing your own subclass of URLConnection, it is often necessary to override these methods so that they return sensible values.
The most important piece of information you may be lacking is the content type.
URLConnection provides some utility methods that guess the data’s content type based on its filename or the first few bytes of the data itself.
Retrieving Specific Header Fields The first six methods request specific, particularly common fields from the header.
It throws no exceptions and returns null if the content type isn’t available.
Other commonly used types include text/plain, image/gif, application/xml, and image/jpeg.
If the content type is some form of text, this header may also contain a character set part identifying the document’s character encoding.
If a nontext type is encountered, an exception is thrown.
It is used when you need to know exactly how many bytes to read or when you need to create a buffer large enough to hold the data in advance.
As networks get faster and files get bigger, it is actually possible to find resources whose size exceeds the maximum int value (about 2.1 billion bytes)
Although in theory you should be able to use the same method to download a binary file, such as a GIF image or a .class byte code file, in practice this procedure presents a problem.
To download a binary file, it is more reliable to use a URLConnection’s getConten.
Downloading a binary file from a website and saving it to disk.
It puts the type into the variable contentType and the content length into the variable contentLength.
Next, an if statement checks whether the content type either of these is true, an IOException is thrown.
If these checks are both false, you have a binary file of known length: that’s what you want.
Now that you have a genuine binary file on your hands, you prepare to read it into an array of bytes called data.
Ideally, you would like to fill data with a single call to The number of bytes read up to this point is accumulated into the offset variable, which also keeps track of the location in the data array at which to start placing the data contentLength; that is, the array has been filled with the expected number of bytes.
The offset variable now contains the total number of bytes read, which should be equal to the content length.
If they are not equal, an error has occurred, so saveBi files from HTTP connections.
If the content is sent unencoded (as is commonly the case with HTTP servers), this method returns null.
The most commonly used content encoding on the Web is probably x-gzip, which can be straightforwardly decoded using a java.util.zip.GZipInputStream.
The content encoding is not the same as the character encoding.
The character encoding is determined by the Content-type header or information internal to the document, and specifies how characters are encoded in bytes.
Content encoding specifies how the bytes are encoded in other bytes.
This is the time the document was sent as seen from the server; it may not agree with the time on your local machine.
If the HTTP header does not include a Date field,
If the HTTP header does not include an Expiration field, remain in the cache indefinitely.
If the HTTP header does not include a Last-modified field (and many don’t), this method returns 0
Example 7-4 reads URLs from the command line and uses these six methods to print their content type, content length, content encoding, date of last modification, expiration date, and current date.
The content type of the file at http://www.oreilly.com is text/html.
It was last modified on the same day at 5:04 P.M.
Many servers don’t bother to provide a Contentlength header for text files.
However, a Content-length header should always be sent for a binary file.
Here’s the HTTP header you get when you request the GIF image http:// oreilly.com/favicon.ico.
Now the server sends a Content-length header with a value of 2294:
Retrieving Arbitrary Header Fields The last six methods requested specific fields from the header, but there’s no theoretical limit to the number of header fields a message can contain.
The next five methods inspect arbitrary fields in a header.
Indeed, the methods of the preceding section are just thin wrappers over the methods discussed here; you can use these methods to get header fields that Java’s designers did not plan for.
For example, to get the value of the Content-type and Content-encoding header fields of a URLConnec tion object uc, you could write:
To get the Date, Content-length, or Expires headers, you’d do the same:
This method returns the key (i.e., the field name) of the nth header field (e.g., Contentlength or Server)
The request method is header zero and has a null key.
For example, in order to get the sixth key of the header of the URLConnec tion uc, you would write:
This method returns the value of the nth header field.
In HTTP, the starter line containing the request method and path is header field zero and the first actual header is one.
Besides the headers with named getter methods, this server also provides Server, AcceptRanges, Cache-control, Vary, Keep-Alive, and Connection headers.
This method first retrieves the header field specified by the name argument and tries to convert the string to a long that specifies the milliseconds since midnight, January 1, a date (e.g., the Expires, Date, or Last-modified headers)
To convert the string to an date formats, but it can be stumped—for instance, if you ask for a header field that.
You can use the methods of the java.util.Date class to convert the long to a String.
This method retrieves the value of the header field name and tries to convert it to an int.
If it fails, either because it can’t find the requested header field or because that field argument.
This method is often used to retrieve the Content-length field.
For example, to get the content length from a URLConnection uc, you would write:
Caches Web browsers have been caching pages and images for years.
If a logo is repeated on every page of a site, the browser normally loads it from the remote server only once,
Several HTTP headers, including Expires and Cache-control, can control caching.
By default, the assumption is that a page accessed with GET over HTTP can and should be cached.
A page accessed with HTTPS or POST usually shouldn’t be.
An Expires header (primarily for HTTP 1.0) indicates that it’s OK to cache this representation until the specified time.
A server can send multiple Cache-control headers in a single header as long as they don’t conflict.
The Last-modified header is the date when the resource was last changed.
A client can use a HEAD request to check this and only come back for a full GET if its local cached copy is older than the Last-modified date.
The ETag header (HTTP 1.1) is a unique identifier for the resource that changes when the resource does.
A client can use a HEAD request to check this and only come back for a full GET if its local cached copy has a different ETag.
It also says it was last modified on April 20 and has an ETag, so if the local cache already has a copy more recent than that, there’s no need to load the whole document now:
Example 7-6 is a simple Java class for parsing and querying Cache-control headers.
If a representation of the resource is available in the local cache, and its expiry date has not arrived, just use it.
If a representation of the resource is available in the local cache, but the expiry date has arrived, check the server with HEAD to see if the resource has changed before performing a full GET.
To install a system-wide cache of the URL class will use, you need the following:
You install your subclass of ResponseCache that works with your subclass of CacheRe quest and CacheResponse by passing it to the static method ResponseCache.setDe can only support a single shared cache.
Once a cache is installed whenever the system tries to load a new URL, it will first look for it in the cache.
If the cache returns the desired content, the URLConnection won’t need to connect to the remote server.
However, if the requested data is not in the cache, the protocol handler will download it.
After it’s done so, it will put its response into the cache so the content is more quickly available the next time that URL is loaded.
Two abstract methods in the ResponseCache class store and retrieve data from the system’s single cache:
CacheRequest is an abstract class with two methods, as shown in Example 7-7
For instance, if you’re storing the data in a file, you’d return a FileOutput Stream connected to that file.
The protocol handler will copy the data it reads onto this OutputStream.
If a problem arises while copying (e.g., the server unexpectedly closes.
Example 7-8 demonstrates a basic CacheRequest subclass that passes back a a custom method in this subclass just retrieving the data Java wrote onto the Output Stream this class supplied.
An obvious alternative strategy would be to store results in files and use a FileOutputStream instead.
It returns null if the desired URI is not in the cache, in which case the protocol handler loads the URI from the remote server as normal.
Again, this is an abstract class that you have to implement in a subclass.
It has two methods: one to return the data of the request and one to return the headers.
When caching the original response, you need to store both.
The headers should be returned in an unmodifiable map with keys that are the HTTP header field names and values that are lists of values for each named HTTP header.
Example 7-10 shows a simple CacheResponse subclass that is tied to a SimpleCacheRe quest and a CacheControl.
In this example, shared references pass data from the request class to the response class.
If you were storing responses in files, you’d just need to share the filenames instead.
Along with the SimpleCacheRequest object from which it will read the data, you must also pass the original URLConnection object into the constructor.
This is used to read the HTTP header so it can be stored for later retrieval.
The object also keeps track of the expiration date and cache-control (if any) provided by the server for the cached representation of the resource.
Finally, you need a simple ResponseCache subclass that stores and retrieves the cached values as requested while paying attention to the original Cache-control header.
Example 7-11 demonstrates such a simple class that stores a finite number of responses in memory in one big thread-safe HashMap.
This class is suitable for a single-user, private cache (because it ignores the private and public attributes of Cache-control)
These set the single cache used by all programs running within the same Java virtual machine.
For example, this one line of code installs Example 7-11 in an application:
Once a ResponseCache like Example 7-11 is installed, HTTP URLConnections always use it.
Each retrieved resource stays in the HashMap until it expires.
This example waits for an expired document to be requested again before it deletes it from the cache.
A more sophisticated implementation could use a low-priority thread to scan for expired documents and remove them to make way for others.
Instead of or in addition to this, an implementation might cache the representations in a queue and remove the oldest documents or those closest to their expiration date as necessary to make room for new ones.
An even more sophisticated implementation could track how often each document in the store was accessed and expunge only the oldest and least-used documents.
I’ve already mentioned that you could implement a cache on top of the filesystem instead of on top of the Java Collections API.
You could also store the cache in a database, and you could do a lot of less-common things as well.
For instance, you could redirect requests for certain URLs to a local server rather than a remote server halfway around the world, in essence using a local web server as the cache.
This might be useful for a server that processes many different SOAP requests, all of which adhere to a few common schemas that can be stored in the cache.
The abstract ResponseCache class is flexible enough to support all of these and other usage patterns.
Configuring the Connection The URLConnection class has seven protected instance fields that define exactly how the client makes the request to the server.
For instance, if doOutput is true, you’ll be able to write data to the server over this URLConnection as well as read data from it.
If useCaches is false, the connection bypasses any local caching and downloads the file from the server afresh.
Because these fields are all protected, their values are accessed and modified via obviously named setter and getter methods:
You can modify these fields only before the URLConnection is connected (before you try to read content or headers from the connection)
Most of the methods that set fields throw an IllegalStateException if they are called while the connection is open.
In general, you can set the properties of a URLConnection object only before the connection is opened.
There are also some getter and setter methods that define the default behavior for all instances of URLConnection.
Unlike the instance methods, these methods can be invoked at any time.
The new defaults will apply only to URLConnection objects constructed after the new default values are set.
The constructor sets it when the URLConnection is created and it should not change thereafter.
You can tion to http://www.oreilly.com/, gets the URL of that connection, and prints it.
The URL that is printed is the one used to create the URLConnection.
Because the connection has not yet been opened when a new URLConnection object is created, its initial value is false.
This variable can be accessed only by instances of java.net.URLConnection and its subclasses.
There are no methods that directly read or change the value of connected.
However, any method that causes the URLConnection to connect should set this variable to true,
There are no such methods in java.net.URLConnection, but some of its subclasses, such as.
If you subclass URLConnection to write a protocol handler, you are responsible for setting connected to true when you are connected and resetting it to false when the connection closes.
Many methods in java.net.URLConnection read this variable to determine what they can do.
If it’s set incorrectly, your program will have severe bugs that are not easy to diagnose.
For example, a web browser may need to ask for a username and password.
However, many applications cannot assume that a user is present to interact with it.
For instance, a search engine robot is probably running in the background without any user to provide a username and password.
As its name suggests, the allowUserInteraction field specifies whether user interaction is allowed.
The value true indicates that user interaction is allowed; false indicates that there is no user interaction.
The value may be read at any time but may be set only before the URLConnection is connected throws an IllegalStateException.
For example, this code fragment opens a connection that could ask the user for authentication if it’s required:
Java does not include a default GUI for asking the user for a username and password.
If the request is made from an applet, the browser’s usual authentication dialog can be relied on.
Figure 7-1 shows the dialog box that pops up when you try to access a passwordprotected page.
If you cancel this dialog, you’ll get a 401 Authorization Required error and whatever text the server sends to unauthorized users.
However, if you refuse to send authorization at all—which you can do by clicking OK, then answering No when asked.
Because the allowUserInteraction field is static (i.e., a class variable instead of an instance variable), setting it changes the default behavior for all instances of the URLConnection class that are created after setDefaul.
For instance, the following code fragment checks to see whether user interaction is.
The protected boolean field doInput is true if the URLConnection can be used for reading, false if it cannot be.
For example, a program that needs to send data to the server using the POST method could do so by getting an output stream from a URLConnection.
The protected boolean field doOutput is true if the URLConnection can be used for writing, false if it cannot be; it is false.
When you set doOutput to true for an http URL, the request method is changed from GET to POST.
If the user asks for the same document again, it can be retrieved from the cache.
However, it may have changed on the server since it was last retrieved.
The only way to tell is to ask the server.
Clients can include an If-Modified-Since in the client request HTTP header.
If the document has changed since that time, the server should send it.
Typically, this time is the last time the client fetched the document.
If the document has changed since that time, the server will send it as usual.
Otherwise, it replies with a 304 Not Modified message, like this:
Some will send the document whether it’s changed or not.
Initialize a Date object with the current date and time.
System.out.println("Original if modified since: " System.out.println("Will retrieve file if it's modified since "
Next, you see the new time, which you set to 24 hours prior to the current time:
Because this document hasn’t changed in the last 24 hours, it is not reprinted.
The useCaches variable determines whether a cache will be used if it’s available.
The default value is true, meaning that the cache will be used; false means the cache won’t be used.Because.
This code fragment disables caching to ensure that the most recent version of the document is retrieved by setting useCaches to false:
Although nonstatic, these methods do set and get a static field that determines the default behavior for all instances of the URLConnection class created after the change.
The next code fragment disables caching by default; after this code runs, URLConnections that want caching must enable it explicitly using setUseCaches(true):
Timeouts Four methods query and modify the timeout values for connections; that is, how long the underlying socket will wait for a response from the remote end before throwing a SocketTimeoutException.
Both setter methods throw an IllegalArgumentException if the timeout is negative.
Configuring the Client Request HTTP Header An HTTP client (e.g., a browser) sends the server a request line and a header.
A web server can use this information to serve different pages to different clients, to get and set cookies, to authenticate users through passwords, and more.
Placing different fields in the header that the client sends and the server responds with does all of this.
It’s important to understand that this is not the HTTP header that the server sends to the client that is read by the various getHeader This is the HTTP header that the client sends to the server.
Each URLConnection sets a number of different name-value pairs in the header by default.
As you can see, it’s a little simpler than the one Chrome sends, and it has a different user agent and accepts different kinds of files.
However, you can modify these and add new fields before connecting.
This method can be used only before the connection is opened.
It throws an IllegalStateException if the connection is already open.
In this case, the separate values will be separated by commas.
These methods only really have meaning when the URL being connected to is an HTTP URL, because only the HTTP protocol makes use of headers like this.
Though they could possibly have other meanings in other protocols, such as NNTP, this is really just an example of poor API design.
These methods should be part of the more specific HttpURLConnection class, not the generic URLConnection class.
For instance, web servers and clients store some limited persistent information with cookies.
The server sends a cookie to a client using the response HTTP header.
From that point forward, whenever the client requests a URL from that server, it includes a Cookie field in the HTTP request header that looks like this:
This particular Cookie field sends three name-value pairs to the server.
There’s no limit to the number of name-value pairs that can be included in any one cookie.
Given a URLConnection object uc, you could add this cookie to the connection, like this:
You can set the same property to a new value, but this changes the existing property instead:
For instance, the names can’t contain whitespace and the values can’t contain any line breaks.
Java enforces the restrictions on fields containing line breaks, make a URLConnection send malformed headers to the server, so be careful.
Some will ignore the bad header and return the requested document anyway, but some will reply with an HTTP 400, Bad Request error.
If, for some reason, you need to inspect the headers in a URLConnection, there’s a standard getter method:
Java also includes a method to get all the request properties for a connection as a Map:
Writing Data to a Server Sometimes you need to write data to a URLConnection, for example, when you submit method returns an OutputStream on which you can write data for transmission to a server:
A URLConnection doesn’t allow output by default, so you have to call setDoOut put(true) before asking for an output stream.
When you set doOutput to true for an http URL, the request method is changed from GET to POST.
In Chapter 5, you saw how to send data to server-side programs with GET.
However, GET should be limited to safe operations, such as search requests or page navigation, and not used for unsafe operations that create or modify a resource, such as posting a comment on a web page or ordering a pizza.
Safe operations can be bookmarked, cached, spidered, prefetched, and so on.
Once you have an OutputStream, buffer it by chaining it to a BufferedOutputStream or a BufferedWriter.
You may also chain it to a DataOutputStream, an OutputStream Writer, or some other class that’s more convenient to use than a raw OutputStream.
Sending data with POST is almost as easy as with GET.
Java buffers all the data written onto the output stream until the stream is closed.
This enables it to calculate the value for the Content-length.
The complete transaction, including client request and server response, looks something like this:
For that matter, as long as you control both the client and the server, you can use any other sort of data encoding you like.
For instance, SOAP and XML-RPC both POST data to web servers as XML rather than an x-www-form-url-encoded query string.
It then returns the input stream containing the server’s response.
This resource is a simple form tester that accepts any input using either the POST or GET method and returns an HTML page showing the names and values that were submitted.
The data returned is HTML; this example simply displays the HTML rather than attempting to parse it.
It would be easy to extend this program by adding a user interface that lets you enter the name and email address to be posted—but because doing that triples the size of the program while showing nothing more of network programming, it is left as an exercise for the reader.
Once you understand this example, it should be easy to write Java programs that communicate with other server-side scripts.
The POST line, the Content-type header, // and the Content-length headers are sent by the URLConnection.
It sets the doOutput field of this connection to true because this URL Connection needs to send output and chains the OutputStream for this URL to an ASCII OutputStreamWriter that sends the data, then flushes and closes the stream.
Do not forget to close the stream! If the stream isn’t closed, no data will be sent.
To summarize, posting data to a form requires these steps:
Decide what name-value pairs you’ll send to the server-side program.
Open a URLConnection to the URL of the program that will accept the data.
The data to be stored is written onto the OutputStream HttpURLConnection subclass of URLConnection, so discussion of PUT will have to wait a little while.
Security Considerations for URLConnections URLConnection objects are subject to all the usual security restrictions about making network connections, reading or writing files, and so forth.
For instance, a URLConnec tion can be created by an untrusted applet only if the URLConnection is pointing to the host that the applet came from.
However, the details can be a little tricky because different URL schemes and their corresponding connections can have different security implications.
For example, a jar URL that points into the applet’s own jar file should be fine.
However, a file URL that points to a local hard drive should not be.
Before attempting to connect a URL, you may want to know whether the connection method:
This returns a java.security.Permission object that specifies what permission is needed to connect to the URL.
It returns null if no permission is needed (e.g., there’s no security manager in place)
For instance, if the underlying URL points to host www.gwbush.com with the connect and resolve actions.
Guessing MIME Media Types If this were the best of all possible worlds, every protocol and every server would use standard MIME types to correctly specify the type of file being transferred.
Not only do we have to deal with older protocols such as FTP that predate MIME, but many HTTP servers that should use MIME don’t provide MIME headers at all or lie and provide headers that are incorrect (usually because the server has been misconfigured)
The URLConnection class provides two static methods to help programs figure out the MIME type of some data; you can use these if the content type just isn’t available or if you have reason to believe that the content type you’re given isn’t.
This method tries to guess the content type of an object based upon the extension in the filename portion of the object’s URL.
It returns its best guess about the content type as a String.
This guess is likely to be correct; people follow some fairly regular conventions when thinking up filenames.
The guesses are determined by the content-types.properties file, normally located in the jre/lib directory.
On Unix, Java may also look at the mailcap file to help it guess.
For instance, it omits various XML applications such as RDF (.rdf), XSL (.xsl), and so on that should have the MIME type application/xml.
It also doesn’t provide a MIME type for CSS stylesheets (.css)
This method tries to guess the content type by looking at the first few bytes of data in the stream.
For this method to work, the InputStream must support marking so that you can return to the beginning of the stream after the first bytes have been read.
Java inspects the first 16 bytes of the InputStream, although sometimes fewer bytes are needed to make an identification.
These guesses are often not as reliable as the guesses with a comment rather than an XML declaration would be mislabeled as an HTML file.
This method should be used only as a last resort.
HttpURLConnection The java.net.HttpURLConnection class is an abstract subclass of URLConnection; it provides some additional methods that are helpful when working specifically with http URLs.
In particular, it contains methods to get and set the request method, decide.
Because this class is abstract and its only constructor is protected, you can’t directly create instances of HttpURLConnection.
However, if you construct a URL object using Connection like this:
The Request Method When a web client contacts a web server, the first thing it sends is a request line.
Typically, this line begins with GET and is followed by the path of the resource that the client wants to retrieve and the version of the HTTP protocol that the client understands.
However, web clients can do more than simply GET files from web servers.
They can PUT a file on a web server or DELETE a file from a server.
And they can ask for just the HEAD of a document.
They can ask the web server for a list of the OPTIONS supported at a given URL.
All of these are accomplished by changing the request method from GET to a different keyword.
For example, here’s how a browser asks for just the header of a document using HEAD:
The method argument should be one of these seven case-sensitive strings:
If it’s some other method, then a java.net.ProtocolException, a subclass of IOException, is thrown.
However, it’s generally not enough to simply set the request method.
Depending on what you’re trying to do, you may need to adjust the HTTP header and provide a message body as well.
For instance, POSTing a form requires you to provide a Content-length header.
The HEAD function is possibly the simplest of all the request methods.
However, it tells the server only to return the HTTP header, not to actually send the file.
The most common use of this method is to check whether a file has been modified since the last time it was cached.
Example 7-15 is a simple program that uses the HEAD request method and prints the last time a file on a server was modified.
It wasn’t absolutely necessary to use the HEAD method here.
But if you used GET, the entire file at http://www.ibiblio.org/xml/ would have been sent across the network, whereas all you cared about was one line in the header.
When you can use HEAD, it’s much more efficient to do so.
The DELETE method removes a file at a specified URL from a web server.
Because this request is an obvious security risk, not all servers will be configured to support it, and those that are will generally demand some sort of authentication.
The server is free to refuse this request or ask for authorization.
Even if the server accepts this request, its response is implementation dependent.
Some servers may delete the file; others simply move it to a trash directory.
It allows clients to place documents in the abstract hierarchy of the site without necessarily knowing how the site maps to the actual local filesystem.
This contrasts with FTP, where the user has to know the actual directory structure as opposed to the server’s virtual directory structure.
Here’s a how an editor might PUT a file on a web server:
As with deleting files, some sort of authentication is usually required and the server must be specially configured to support PUT.
Most web servers do not support PUT out of the box.
The OPTIONS request method asks what options are supported for a particular URL.
If the request URL is an asterisk (*), the request applies to the server as a whole rather than to one particular URL on the server.
The server responds to an OPTIONS request by sending an HTTP header with a list of the commands allowed on that URL.
For example, when the previous command was sent, here’s what Apache responded with:
The list of legal commands is found in the Allow field.
However, in practice these are just the commands the server understands, not necessarily the ones it will actually perform on that URL.
The TRACE request method sends the HTTP header that the server received from the client.
The main reason for this information is to see what any proxy servers between the server and client might be changing.
The first five lines are the server’s normal response HTTP header.
The lines from TRACE /xml/ HTTP/1.1 on are the echo of the original client request.
However, if there were a proxy server between the client and server, it might not be.
Disconnecting from the Server HTTP 1.1 supports persistent connections that allow multiple requests and responses to be sent over a single TCP socket.
However, when Keep-Alive is used, the server won’t immediately close a connection simply because it has sent the last byte of data to the client.
Servers will time out and close the connection in as little as 5 seconds of inactivity.
However, it’s still preferred for the client to close the connection as soon as it knows it’s done.
The HttpURLConnection class transparently supports HTTP Keep-Alive unless you explicitly turn it off.
That is, it will reuse sockets if you connect to the same server again before the server has closed the connection.
Closing a stream on a persistent connection does not close the socket and disconnect.
Handling Server Responses The first line of an HTTP server’s response includes a numeric code and a message indicating what sort of response is made.
For instance, the most common response is 200 OK, indicating that the requested document was found.
Another response that you’re undoubtedly all too familiar with is 404 Not Found, indicating that the URL you requested no longer points to a document.
For instance, code 301 indicates that the resource has permanently moved to a new location and the browser should redirect itself to the new location and update any bookmarks that point to the old location.
Often all you need from the response message is the numeric response code.
The text string that follows the response code is called the response message and is.
Although some numbers, notably 404, have become slang almost synonymous with their semantic meaning, most of them are less familiar.
Example 7-16 is a revised source viewer program that now includes the response message.
The only thing this program doesn’t read that the server sends is the version of HTTP the server is using.
In this example, you just fake it as “HTTP/1.x,” like this:
However, uc.getHeaderField(0) does return the entire first HTTP request line, version included:
Error conditions On occasion, the server encounters an error but returns useful information in the message body nonetheless.
However, if that fails for any reason, it then reads from the error stream instead.
Redirects The 300-level response codes all indicate some sort of redirect; that is, the requested resource is no longer available at the expected location but it may be found at some other location.
When encountering such a response, most browsers automatically load the document from its new location.
However, this can be a security risk, because it has the potential to move the user from a trusted site to an untrusted one, perhaps without the user even noticing.
However, the HttpURLConnec tion class has two static methods that let you decide whether to follow redirects:
With an argument of false, it prevents them from following redirects.
Because these are static methods, they change the behavior of all HttpURLConnection objects constructed after the method is invoked.
Java has two methods to configure redirection on an instance-by-instance basis.
HttpURLConnection simply follows the default behavior as set by the class method.
Proxies Many users behind firewalls or using AOL or other high-volume ISPs access the Web HttpURLConnection is going through a proxy server:
It returns true if a proxy is being used, false if not.
In some contexts, the use of a proxy server may have security implications.
Streaming Mode Every request sent to an HTTP server has an HTTP header.
One field in this header is the Content-length (i.e., the number of bytes in the body of the request)
However, to write the header you need to know the length of the body, which you may not have yet.
Normally, the way Java solves this catch-22 is by caching everything you write onto the OutputStream retrieved from the HttpURLCon nection until the stream is closed.
At that point, it knows how many bytes are in the body so it has enough information to write the Content-length header.
This scheme is fine for small requests sent in response to typical web forms.
However, it’s burdensome for responses to very long forms or some SOAP messages.
It’s very wasteful and slow for medium or large documents sent with HTTP PUT.
It’s much more efficient if Java doesn’t have to wait for the last byte of data to be written before sending the first byte of data over the network.
If you don’t know the size of the data in advance, you can use chunked transfer encoding instead.
In chunked transfer encoding, the body of the request is sent in multiple pieces, each with its own separate content length.
To turn on chunked transfer encoding, just pass connect the URL:
Java will then use a slightly different form of HTTP than the examples in this book.
As long as you’re using the URLConnection class instead of raw sockets and as long as the server supports chunked transfer encoding, it should all just work without any further changes to your code.
However, chunked transfer encoding does get in the way of authentication and redirection.
If you’re trying to send chunked files to a redirected URL or one that requires password authentication, an HttpRetryException will be thrown.
You’ll then need to retry the request at the new URL or at the old URL with the appropriate credentials; and this all needs to be done manually without the full support of the HTTP protocol handler you normally have.
Therefore, don’t use chunked transfer encoding unless you really need it.
As with most performance advice, this means you shouldn’t implement this optimization until measurements prove the nonstreaming default is a bottleneck.
If you do happen to know the size of the request data in advance, you can optimize the connection by providing this information to the HttpURLConnection object.
If you do this, Java can start streaming the data over the network immediately.
Otherwise, it has to cache everything you write in order to determine the content length, and only send it over the network after you’ve closed the stream.
Because this number can actually be larger than the maximum size of an int, in Java 7 and later you can use a long instead.
Java will use this number in the Content-length HTTP header field.
However, if you then try to write more or less than the number of bytes given here, Java will throw an IOException.
Of course, that happens later, when you’re writing data, not when you an IllegalArgumentException if you pass in a negative number, or an IllegalSta teException if the connection is connected or has already been set to chunked transfer encoding.
You can’t use both chunked transfer encoding and fixed-length streaming mode on the same request.)”
Servers neither know nor care how the Content-length was set, as long as it’s correct.
However, like chunked transfer encoding, streaming mode does interfere with authentication and redirection.
If either of these is required for a given URL, an HttpRetryException will be thrown; you have to manually retry.
Therefore, don’t use this mode unless you really need it.
Data is transmitted across the Internet in packets of finite size called datagrams.
The header contains the address and port to which the packet is going, the address and port from which the packet came, a checksum to detect data corruption, and various other housekeeping information used to ensure reliable transmission.
However, because datagrams have a finite length, it’s often necessary to split the data across multiple packets and reassemble it at the destination.
It’s also possible that one or more packets may be lost or corrupted in transit and need to be retransmitted or that packets arrive out of order and need to be reordered.
Sockets allow the programmer to treat a network connection as just another stream onto which bytes can be written and from which bytes can be read.
Sockets shield the programmer from low-level details of the network, such as error detection, packet sizes, packet splitting, packet retransmission, network addresses, and more.
Using Sockets A socket is a connection between two hosts.
Listen for incoming data • Accept connections from remote machines on the bound port.
Java’s Socket class, which is used by both clients and servers, has methods that correspond to the first four of these operations.
The last three operations are needed only by servers, which wait for clients to connect to them.
They are implemented by the ServerSocket class, which is discussed in the next chapter.
Java programs normally use client sockets in the following fashion:
Once the connection is established, the local and remote hosts get input and output streams from the socket and use those streams to send data to each other.
What the data means depends on the protocol; different commands are sent to an FTP server than to an HTTP server.
There will normally be some agreed-upon handshaking followed by the transmission of data from one to the other.
When the transmission of data is complete, one or both sides close the connection.
Some protocols, such as HTTP 1.0, require the connection to be closed after each request is serviced.
Others, such as FTP and HTTP 1.1, allow multiple requests to be processed in a single connection.
Investigating Protocols with Telnet In this chapter, you’ll see clients that use sockets to communicate with a number of wellknown Internet services such as time, dict, and more.
The sockets themselves are simple enough; however, the protocols to communicate with different servers make life complex.
To get a feel for how a protocol operates, you can use Telnet to connect to a server, type different commands to it, and watch its responses.
To connect to servers on different ports, specify the port you want to connect to like this:
This requests a connection to port 25, the SMTP port, on the local machine; SMTP is the protocol used to transfer email between servers or between a mail client and a server.
If you know the commands to interact with an SMTP server, you can send email without going through a mail program.
For example, some years ago, the summer students at the National Solar Observatory in Sunspot, New Mexico, made it appear that the party one of the scientists was throwing after the annual volleyball match between the staff and the students was in fact a victory party for the.
Of course, the author of this book had absolutely nothing to do with such despicable behavior.
The interaction with the SMTP server went something like this; input the user types is shown in bold (the names have been changed to protect the gullible):
Beer and Ben-Gay will be provided so the staff may drown their sorrows and assuage their aching muscles after their.
Several members of the staff asked Bart why he, a staff member, was throwing a victory party for the students.
The moral of this story is that you should never trust email, especially patently ridiculous email like this, without independent verification.
In the 20 years since this happened, most SMTP servers have added a little more security than shown here.
They tend to require usernames and passwords, and only accept connections from clients in the local networks and other trusted mail servers.
However, it’s still the case that you can use Telnet to simulate a client, see how the client and the server interact, and thus learn what your Java program needs to do.
Although this session doesn’t demonstrate all the features of the SMTP protocol, it’s sufficient to enable you to deduce how a simple email client talks to a server.
Reading from Servers with Sockets Let’s begin with a simple example.
You’re going to connect to the daytime server at the National Institute for Standards and Technology (NIST) and ask it for the current time.
Reading that, you see that the daytime server listens on port 13, and that the server sends the time in a human-readable format and closes the connection.
You can test the daytime server with Telnet like this:
When you read the Socket’s InputStream, this is what you will get.
The other lines are produced either by the Unix shell or by the Telnet program.
YY-MM-DD is the last two digits of the year, the month, and the current day of month.
HH:MM:SS is the time in hours, minutes, and seconds in Coordinated Universal Time (UTC, essentially Greenwich Mean Time)
Other values count down the number of days until the switchover.
In the preceding code, you can see that it added 888.8 milliseconds to this result, because that’s how long it estimates it’s going to take for the response to return.
The string UTC(NIST) is a constant, and the OTM is almost a constant (an asterisk unless something really weird has happened)
Although they do offer a lot of data, if you have a real programmatic need to sync with a network time server, you’re better off using the NTP protocol defined in RFC 5905 instead.
I’m not sure how long this example is going to work as shown here.
These servers are overloaded, and I did have intermittent problems connecting while writing this chapter.
Now let’s see how to retrieve this same data programmatically using sockets.
If the connection times out or fails because the server isn’t listening on port 13, then the constructor throws an IOException, so you’ll usually wrap this in a try block.
In Java 7, Socket implements Autocloseable so you can use try-with-resources:
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Set a timeout on the connection statement sets the socket to time out after 15 seconds of nonresponsiveness:
Although a socket should throw a ConnectException pretty quickly if the server rejects the connection, or a NoRouteToHostException if the routers can’t figure out how to send your packets to the server, neither of these help you with the case where a misbehaving server accepts the connection and then stops talking to you without actively closing the connection.
Setting a timeout on the socket means that each read from or write to the socket will take at most a certain number of milliseconds.
If a server hangs while you’re connected to it, you will be notified with a SocketTimeoutException.
Exactly how long a timeout to set depends on the needs of your application and how responsive you expect the server to be.
Fifteen seconds is a long time for a local intranet server to respond, but it’s rather short for an overloaded public server like time.nist.gov.
InputStream you can use to read bytes from the socket.
In general, a server can send any bytes at all; but in this specific case, the protocol specifies that those bytes must be ASCII:
You can, of course, use any data structure that fits your problem to hold the data that comes off the network.
Example 8-1 puts this all together in a program that also allows you to choose a different daytime server.
Typical output is much the same as if you connected with Telnet:
As far as network-specific code goes, that’s pretty much it.
In most network programs like this, the real effort is in speaking the protocol and comprehending the data formats.
For instance, rather than simply printing out the text the server sends you, you might want to parse it into a java.util.Date object instead.
For variety, I also wrote this example taking advantage of Java 7’s AutoCloseable and try-with-resources.
Notice, however, this class doesn’t actually do anything with the network that Example 8-1 didn’t do.
It just added a bunch of code to turn strings into dates.
When reading data from the network, it’s important to keep in mind that not all protocols use ASCII or even text.
Rather, it is sent as a 32-bit, unsigned, big-endian binary number.
The RFC never actually comes out and says that this is the format used.
It specifies 32 bits and assumes you know that all network protocols use big-endian numbers.
The fact that the number is unsigned can be determined only by calculating the wraparound date for signed and unsigned integers and comparing it to the date given in the specification (2036)
To make matters worse, the specification gives an example of a negative time that can’t actually be sent by time servers that follow the protocol.
Time is a relatively old protocol, standardized in the early 1980s before the IETF was as careful about such issues as it is today.
Nonetheless, if you find yourself implementing a not particularly well-specified protocol, you may have to do a significant amount of testing against existing implementations to figure out what you need to do.
Because the time protocol doesn’t send back text, you can’t easily use Telnet to test such a service, and your program can’t read the server response with a Reader or any sort of bytes and interpret them appropriately.
In this example, that job is complicated by Java’s lack of a 32-bit unsigned integer type.
When speaking other protocols, you may encounter data formats even more alien to Java.
For instance, a few network protocols use 64-bit fixedpoint numbers.
You simply have to grit your teeth and code the math you need to handle the data in whatever format the server sends.
If you'd rather not use the magic number, uncomment // the following section which calculates it directly.
Here’s the output of this program from a sample run:
Writing to Servers with Sockets Writing to a server is not noticeably harder than reading from one.
You simply ask the socket for an output stream as well as an input stream.
Although it’s possible to send data over the socket using the output stream at the same time you’re reading data over the input stream, most protocols are designed so that the client is either reading or writing over a socket, not both at the same time.
In the most common pattern, the client sends a request.
The client may send another request, and the server responds again.
This continues until one side or the other is done, and closes the connection.
One simple bidirectional TCP protocol is dict, defined in RFC 2229
This tells the server to send a definition of the word gold using its English-to-Latin dictionary.
Different servers have different dictionaries installed.) After the first definition is received, the client can ask for another.
You can see that control response lines begin with a three-digit code.
The actual definition is plain text, terminated with a period on a line by itself.
If the dictionary doesn’t contain the word you asked for, it returns 552 no match.
Of course, you could also find this out, and a lot more, by reading the RFC.
Once again you’ll want to set a timeout in case the server hangs while you’re connected to it:
In the dict protocol, the client speaks first, so ask for the output stream using getOut.
You usually chain this stream to a more convenient class like DataOutputStream or OutputStreamWriter before using it.
For performance reasons, it’s a good idea to buffer it as well.
Because the dict protocol is text based, more specifically UTF-8 based, it’s convenient to wrap this in a Writer:
Finally, flush the output so you’ll be sure the command is sent over the network:
When you see a period on a line by itself, you know the definition is complete.
You can then send the quit over the output stream:
It connects to dict.org, and translates any words the user enters on the command line into Latin.
It reads a line of input from the console, sends it to the server, and waits to read a line of output it gets back.
Instead, they adjust the stream connected to the socket so that it thinks it’s at the end of the stream.
Further reads from the input stream after shutting down input return –1
Further writes to the socket after shutting down output throw an IOException.
Many protocols, such as finger, whois, and HTTP, begin with the client sending a request to the server, then reading the response.
It would be possible to shut down the output after the client has sent the request.
For example, this code fragment sends a request to an HTTP server and then shuts down the output, because it won’t need to write anything else over this socket:
Notice that even though you shut down half or even both halves of a connection, you still need to close the socket when you’re through with it.
They don’t release the resources associated with the socket, such as the port it occupies.
You can use these (rather than from or write to a socket:
Constructing and Connecting Sockets The java.net.Socket class is Java’s fundamental class for performing client-side TCP operations.
Other client-oriented classes that make TCP network connections such as URL, URLConnection, Applet, and JEditorPane all ultimately end up invoking the methods of this class.
This class itself uses native code to communicate with the local TCP stack of the host operating system.
Basic Constructors Each Socket constructor specifies the host and the port to connect to.
Hosts may be specified as an InetAddress or a String.
These constructors connect the socket (i.e., before the constructor returns, an active network connection is established to the remote host)
If the connection can’t be opened for some reason, the constructor throws an IOException or an UnknownHostExcep tion.
In this constructor, the host argument is just a hostname expressed as a String.
If the domain name server cannot resolve the hostname or is not functioning, the constructor throws an UnknownHostException.
If the socket cannot be opened for some other reason, the constructor throws an IOException.
There are many reasons a connection attempt might fail: the host you’re trying to reach may not accept connections on that port, the hotel WiFi service may be blocking you until you log in to its website and pay $14.95, or routing problems may be preventing your packets from reaching their destination.
Because this constructor doesn’t just create a Socket object but also tries to connect the socket to the remote host, you can use the object to determine whether connections to a particular port are allowed, as in Example 8-5
Find out which of the first 1024 ports seem to be hosting TCP servers on a specified host.
Here’s the output this program produces on my local host (your results will vary, depending on which ports are occupied):
If you’re curious about what servers are running on these ports, try experimenting with Telnet.
On a Unix system, you may be able to find out which services reside on which ports by looking in the file /etc/services.
If LowPortScanner finds any ports that are running servers but are not listed in /etc/services, then that’s interesting.
Although this program looks simple, it’s not without its uses.
The first step to securing a system is understanding it.
This program helps you understand what your system is doing so you can find (and close) possible entrance points for attackers.
These provide more control over exactly how the underlying socket behaves, for instance by choosing a different proxy server or an encryption scheme:
Picking a Local Interface to Connect From Two constructors specify both the host and port to connect to and the interface and port to connect from:
This socket connects to the host and port specified in the first two arguments.
It connects from the local network interface and port specified by the last two arguments.
The network interface may be either physical (e.g., an Ethernet card) or virtual (a multihomed host with more than one IP address)
Selecting a particular network interface from which to send data is uncommon, but a need does come up occasionally.
One situation where you might want to explicitly choose the local address would be on a router/firewall that uses dual Ethernet ports.
Incoming connections would be accepted on one interface, processed, and forwarded to the local network from the other interface.
Suppose you were writing a program to periodically dump error logs to a printer or send them over an internal mail server.
You’d want to make sure you used the inward-facing network interface instead of the outward-facing network interface.
By passing 0 for the local port number, I say that I don’t care which port is used but I do want to use the network interface bound to the local hostname router.
This constructor can throw an IOException or an UnknownHostException for the same reasons as the previous constructors.
In addition, it throws an IOException (probably a BindException, although again that’s just a subclass of IOException and not specifically declared in the throws clause of this method) if the socket is unable to bind to the requested local network interface.
For instance, a program running on a.example.com can’t connect from b.example.org.
You could take deliberate advantage of this to restrict a compiled program to run on only a predetermined host.
It would require customizing distributions for each computer and is certainly overkill for cheap products.
Furthermore, Java programs are so easy to disassemble, decompile, and reverse engineer that this scheme is far from foolproof.
Nonetheless, it might be part of a scheme to enforce a software license.
Constructing Without Connecting All the constructors we’ve talked about so far both create the socket object and open a network connection to a remote host.
If you give no arguments to the Socket constructor, it has nowhere to connect to:
You can pass an int as the second argument to specify the number of milliseconds to wait before the connection times out:
The raison d'être for this constructor is to enable different kinds of sockets.
You also need to use it to set a socket option that can only be changed before the socket connects.
However, the prime benefit I find is that it enables me to clean up the code in try-catch-finally blocks, especially prior to Java 7
The noargs constructor throws no exceptions so it enables you to avoid the annoying null check when closing a socket in a finally block.
That’s not quite as nice as the autoclosing version in Java 7, but it is an improvement.
It is an empty abstract class with no methods aside from a default constructor.
At least theoretically, the SocketAddress class can be used for both TCP and non-TCP sockets.
In practice, only TCP/IP sockets are currently supported and the socket addresses you actually use are all instances of InetSocketAddress.
The primary purpose of the SocketAddress class is to provide a convenient store for transient socket connection information such as the IP address and port that can be reused to create new sockets, even after the original socket is disconnected and garbage collected.
To this end, the Socket class offers two methods that return SocketAddress made):
Both of these methods return null if the socket is not yet connected.
For example, first you might connect to Yahoo! then store its address:
The InetSocketAddress class (which is the only subclass of SocketAddress in the JDK, and the only subclass I’ve ever encountered) is usually created with a host and a port (for clients) or just a port (for servers):
InetSocketAddress has a few getter methods you can use to inspect the object:
Proxy Servers The last constructor creates an unconnected socket that connects through a specified proxy server:
Normally, the proxy server a socket uses is controlled by the socksProxyHost and socksProxyPort system properties, and these properties apply to all sockets in the system.
However, a socket created by this constructor will use the specified proxy server instead.
Most notably, you can pass Proxy.NO_PROXY for the argument to bypass all proxy servers completely and connect directly to the remote host.
Of course, if a firewall prevents direct connections, there’s nothing Java can do about it; and the connection will fail.
To use a particular proxy server, specify it by address.
For example, this code fragment uses the SOCKS proxy server at myproxy.example.com to connect to the host login.ibiblio.org:
There’s also a high-level Proxy.Type.HTTP that works in the application layer rather than the transport layer and a Proxy.Type.DIRECT that represents proxyless connections.
Getting Information About a Socket Socket objects have several properties that are accessible through getter methods:
These properties are set as soon as the socket connects, and are fixed from there on.
Socket is connected to; or, if the connection is now closed, which host and port the from.
This way, many different clients on a system can access the same service at the same time.
The local port is embedded in outbound IP packets along with the local host’s IP address, so the server can send data back to the right port on the client.
Example 8-6 reads a list of hostnames from the command line, attempts to open a socket to each one, and then uses these four methods to print the remote host, the remote port, the local address, and the local port.
I included www.oreilly.com on the command line twice in order to demonstrate that each connection was assigned a different local port, regardless of the remote host; the local port assigned to any connection is unpredictable and depends mostly on what other ports are in use.
The connection to login.ibiblio.org failed because that machine does not run any servers on port 80:
Closed or Connected? uncertain about a socket’s state, you can check it with this method rather than risking an IOException.
If the socket has never been connected in the first.
It does not tell you if the socket is currently connected to a remote host (like if it is unclosed)
Instead, it tells you whether the socket has ever been connected to a remote host.
If the socket was able to connect to the remote host at all, this method returns true, even after that socket has been closed.
To tell if a socket is currently open, you need to.
The Socket class overrides only one of the standard methods from java.lang.Ob.
Don’t rely on this format; it may change in the future.
All parts of this string are accessible directly through other methods (specifically.
Because sockets are transitory objects that typically last only as long as the connection they represent, there’s not much reason to store them in hash tables or compare them to each other.
Therefore, Socket does methods are those of the Object class.
Two Socket objects are equal to each other if and only if they are the same object.
Setting Socket Options Socket options specify how the native sockets on which the Java Socket class relies send and receive data.
The funny-looking names for these options are taken from the named constants in the C header files used in Berkeley Unix where sockets were invented.
Thus, they follow classic Unix C naming conventions rather than the more legible Java naming conventions.
Setting TCP_NODELAY to true ensures that packets are sent as quickly as possible regardless of their size.
Normally, small (one-byte) packets are combined into larger packets before being sent.
Before sending another packet, the local host waits to receive acknowledgment of the previous packet from the remote system.
The problem with Nagle’s algorithm is that if the remote system doesn’t send acknowledgments back to the local system fast enough, applications that depend on the steady transfer of small parcels of information may slow down.
This issue is especially problematic for GUI programs such as games or network computer applications where the server needs to track client-side mouse movement in real time.
On a really slow network, even simple typing can be too slow because of the constant buffering.
Setting TCP_NODELAY to true defeats this buffering scheme, so that all packets are sent as soon as they’re ready.
For example, the following fragment turns off buffering (that is, it turns on TCP_NODELAY) for the socket s if it isn’t already off:
These two methods are each declared to throw a SocketException, which will happen if the underlying socket implementation doesn’t support the TCP_ NODELAY option.
The SO_LINGER option specifies what to do with datagrams that have not yet been the system still tries to send any remaining data.
If the linger time is set to zero, any unsent packets are thrown away when the socket is closed.
If SO_LINGER is turned on specified number of seconds for the data to be sent and the acknowledgments to be received.
When that number of seconds has passed, the socket is closed and any remaining data is not sent, acknowledgment or no.
The maximum linger time is 65,535 seconds, and may be smaller on some platforms.
Times larger than that will be reduced to the maximum linger time.
By setting SO_TIMEOUT, you ensure that the call will not block for more than a fixed number of milliseconds.
When the timeout expires, an InterruptedIOException is thrown, and you should be prepared to catch it.
Zero is interpreted as an infinite timeout; it is the default value.
Larger buffers tend to improve performance for reasonably fast (say, 10Mbps and up) connections whereas slower, dialup connections do better with smaller buffers.
Generally, transfers of large, continuous blocks of data, which are common in file transfer protocols such as FTP and HTTP, benefit from large buffers, whereas the smaller transfers of interactive sessions, such as Telnet and many games, do not.
Relatively old operating systems designed in the age of small files and slow networks, such as BSD 4.2, use two-kilobyte buffers.
For example, on Windows XP suppose the latency between two hosts is half a second (500 ms)
That’s the maximum speed of any socket, regardless of how fast the network is.
That’s plenty fast for a dial-up connection, and not bad for ISDN, but not really adequate for a DSL line or FIOS.
However, latency is a function of the network hardware and other factors outside the control of your application.
On the other hand, you do control the buffer size.
Of course, the network itself has limits on maximum bandwidth.
Set the buffer too high and your program will try to send and receive data faster than the network can handle, leading to congestion, dropped packets, and slower performance.
Thus, when you want maximum bandwidth, you need to match the buffer size to the latency of the connection so it’s a little less than the bandwidth of the network.
You can use ping to check the latency to a particular host manually, or program.
The SO_RCVBUF option controls the suggested send buffer size used for network input.
The SO_SNDBUF option controls the suggested send buffer size used for network output:
Although it looks like you should be able to set the send and receive buffers independently, the buffer is usually set to the smaller of these two.
However, the underlying implementation is free to ignore or adjust this suggestion.
If you attempt to set a larger value, Java will just pin it to the maximum possible buffer size.
On Linux, it’s not unheard of for the underlying implementation to double the requested size.
These methods throw an IllegalArgumentException if the argument is less than or equal to zero.
Although they’re also declared to throw SocketException, they probably won’t in practice, because a SocketException is thrown for the same reason as Ille galArgumentException and the check for the IllegalArgumentException is made first.
By contrast, if you’re dropping packets and experiencing congestion, try decreasing the buffer size.
However, most of the time, unless you’re really taxing the network in one direction or the other, the defaults are fine.
In particular, modern operating systems use TCP window scaling (not controllable from Java) to dynamically adjust buffer sizes to fit the network.
As with almost any performance tuning advice, the rule of thumb is not to do it until you’ve measured a problem.
And even then you may well get more speed by increasing the maximum allowed buffer size at the operating system level than by adjusting the buffer sizes of individual sockets.
If the server fails to respond to this packet, the client keeps trying for a little more than 11 minutes until it receives a response.
These methods turn SO_KEEPALIVE on and off and determine its current state:
This code fragment turns SO_KEEPALIVE off, if it’s turned on:
Furthermore, the receiver is notified when the urgent data is received and may elect to process the urgent data before it processes any other data that has already been received.
This method sends the lowest-order byte of its argument almost immediately.
How the receiving end responds to urgent data is a little confused, and varies from one platform and API to the next.
Some systems receive the urgent data separately from the regular data.
However, the more common, more modern approach is to place the urgent data in the regular received data queue in its proper order, tell the application that urgent data is available, and let it hunt through the queue to find it.
By default, Java ignores urgent data received from a socket.
However, if you want to receive urgent data inline with regular data, you need to set the OOBINLINE option to true using these methods:
This code fragment turns OOBINLINE on, if it’s turned off:
Once OOBINLINE is turned on, any urgent data that arrives will be placed on the socket’s input stream to be read in the usual way.
That makes it less than ideally useful, but if you have a particular byte (e.g., a Ctrl-C) that has special meaning to your program and never shows up in the regular data stream, then this would enable you to send it more quickly.
SO_REUSEADDR When a socket is closed, it may not immediately release the local port, especially if a connection was open when the socket was closed.
It can sometimes wait for a small amount of time to make sure it receives any lingering packets that were addressed to the port that were still crossing the network when the socket was closed.
The system won’t do anything with any of the late packets it receives.
It just wants to make sure they don’t accidentally get fed into a new process that has bound to the same port.
This isn’t a big problem on a random port, but it can be an issue if the socket has bound to a well-known port because it prevents any other socket from using that port in the meantime.
If the SO_REUSEADDR is turned on (it’s turned off by default), another socket is allowed to bind to the port even while data may be outstanding for the previous socket.
In Java this option is controlled by these two methods:
This means the socket must be created in an unconnected state using the noargs constructor; then setReuseAddress(true) is called, and the socket is connected using socket reusing the old address must set SO_REUSEADDR to true for it to take effect.
IP_TOS Class of Service Different types of Internet service have different performance needs.
For instance, video chat needs relatively high bandwidth and low latency for good performance, whereas email can be passed over low-bandwidth connections and even held up for several hours without major harm.
It might be wise to price the different classes of service differentially so that people won’t ask for the highest class of service automatically.
After all, if sending an overnight letter cost the same as sending a package via media mail, we’d all just use FedEx overnight, which would quickly become congested and overwhelmed.
The class of service is stored in an eight-bit field called IP_TOS in the IP header.
Java lets you inspect and set the value a socket places in this field using these two methods:
Because this value is copied to an eight-bit field in the TCP header, only the low order byte of this int is used; and values outside this range cause IllegalArgumentExceptions.
In 21st-century TCP stacks, the high-order six bits of this byte contain a Differentiated Services Code Point (DSCP) value and the low-order two bits contain an Explicit Congestion Notification (ECN) value.
The DSCP thus has room for up to 26 different traffic classes.
However, it’s up to individual networks and routers to specify exactly what the 64 different possible DSCP values mean.
The four values shown in Table 8-1 are fairly common.
Assured Forwarding (AF) multiple Assured delivery up to a specified rate.
For example, the Expedited Forwarding PHB is a good choice for for VOIP.
This code fragment sets a socket to use Expedited Forwarding by setting the traffic class to 10111000:
Remember the low-order two bits of this number are Explicit Congestion Notification, and should be set to zero.
The purpose here is to allow a sender to express relative preferences for which packets to drop when the network is congested.
Within a class, packets with lower priority are dropped before packets with a higher priority.
Between classes, packest from a higher-priority class are given preference, though lower-priority classes are not starved completely.
For example, the following code fragment sets up three sockets with different forwarding characteristics.
In practice, although DSCP values are respected on some networks internally, any time a packet crosses ISPs, this information is almost always ignored.
The JavaDoc for these options is severely out of date, and describes a quality of service scheme based on bit fields for four traffic classes: low cost, high reliability, maximum throughput, and minimum delay.
This scheme was never widely implemented and probably hasn’t been used in this century.
The specific TCP header where these values were stored has been repurposed for the DSCP and EN values described here.
However, in the unlikely event you need it, you can put these values in the high-order three bits of a class selector PHB, followed by zero bits.
The underlying socket implementation is not required to respect any of these requests.
They only provide a hint to the TCP stack about the desired policy.
Android in particular treats the setTraffic service, it may, but is not required to, throw a SocketException.
Exactly how any given VM implements this is implementation dependent.
Socket Exceptions Most methods of the Socket class are declared to throw IOException or its subclass, java.net.SocketException:
However, knowing that a problem occurred is often not sufficient to deal with the problem.
A BindException is thrown if you try to construct a Socket or ServerSocket object on a local port that is in use or that you do not have sufficient privileges to use.
A Connec tException is thrown when a connection is refused at the remote host, which usually happens because the host is busy or no process is listening on that port.
Finally, a NoRouteToHostException indicates that the connection has timed out.
The java.net package also includes ProtocolException, which is a direct subclass of IOException:
This is thrown when data is received from the network that somehow violates the TCP/ IP specification.
None of these exception classes have any special methods you wouldn’t find in any other exception class, but you can take advantage of these subclasses to provide more informative error messages or to decide whether retrying the offending operation is likely to be successful.
HotJava has been discontinued, but there are still numerous network-aware client applications written in Java, including the Eclipse IDE and the Frostwire BitTorrent client.
It is completely possible to write commercial-quality client applications in Java; and it is especially possible to write network-aware applications, both clients and servers.
This section demonstrates a network client, whois, to illustrate this point; and to discuss the special considerations that arise when integrating networking code with Swing applications.
The example stops short of what could be done, but only in the user interface.
Indeed, once again you find out that network code is easy; it’s user interfaces that are hard.
Whois Whois is a simple directory service protocol defined in RFC 954; it was originally designed to keep track of administrators responsible for Internet hosts and domains.
A whois client connects to one of several central servers and requests directory information for a person or persons; it can usually give you a phone number, an email address, and a snail mail address (not necessarily current ones, though)
With the explosive growth of the Internet, flaws have become apparent in the whois protocol, most notably its centralized nature.
Let’s begin with a simple client to connect to a whois server.
The client opens a TCP socket to port 43 on the server.
The client sends a search string terminated by a carriage return/linefeed pair (\r\n)
The search string can be a name, a list of names, or a special command, as discussed shortly.
You can also search for domain names, like www.oreilly.com or netscape.com, which give you information about a network.
The server sends an unspecified amount of human-readable information in response to the command and closes the connection.
The search string the client sends has a fairly simple format.
At its most basic, it’s just the name of the person you’re searching for.
Domain names in the .com and .net domains can now be registered with many different competing registrars.
To single out one record, look it up with "xxx", where xxx is one of the of the records displayed above.
Although the previous input has a pretty clear format, that format is regrettably nonstandard.
Different whois servers can and do send decidedly different output.
For example, here are the first couple of results from the same search at the main French whois server, whois.nic.fr:
Here each complete record is returned rather than just a list of sites.
This protocol is not at all designed for machine processing.
You pretty much have to write new code to handle the output of each different whois server.
Handles are guaranteed to be unique, and are used to get more specific information about a person or a network.
If you search for a handle, you will get at most one match.
If your search only has one match, either because you’re lucky or you’re searching for a handle, the server returns a more detailed record.
Because there is only one oreilly.com in the database, the server returns all the information it has on this domain:
Domain names in the .com and .net domains can now be registered with many different competing registrars.
The whois protocol supports several flags you can use to restrict or expand your search.
Each prefix should be placed before the search string on the command line.
Expand or * Search only for group records and show all individuals in that group.
Partial or suffix Match records that start with the given string.
Summary or $ Show just the summary, even if there’s only one match.
SUBdisplay or % Show the users of the specified host, the hosts on the specified network, etc.
These keywords are all useful, but they’re way too much trouble to remember.
In fact, most people don’t even know that they exist.
A good whois client doesn’t rely on users remembering arcane keywords; rather, it shows them the options.
Supplying this requires a graphical user interface for end users and a better API for client programmers.
A Network Client Library It’s best to think of network protocols like whois in terms of the bits and bytes that move across the network, whether as packets, datagrams, or streams.
No network protocol neatly fits into a GUI (with the arguable exception of the Remote Framebuffer Protocol used by VNC and X11)
It’s usually best to encapsulate the network code into a separate library that the GUI code can invoke as needed.
Two fields define the state of each Whois object: host, an InetAddress object, and port, an int.
Together, these define the server that this particular Whois object connects to.
Five constructors set these fields from various combinations of arguments.
I could have used strings or int constants to specify the kind of record to search for and the database to search enums with a fixed number of members instead.
This solution provides much stricter compile-time type-checking and guarantees the Whois class won’t have to handle an unexpected value.
This interface has a text field to enter the name to be searched for and a checkbox to determine whether the match should be exact or partial.
A group of radio buttons lets users specify which group of records they want to search.
Another group of radio buttons chooses the fields that should be searched.
By default, this client searches all fields of all records for an exact match.
When a user enters a string in the Whois: search box and presses Enter or clicks the Find button, the program makes a connection to the whois server and retrieves records that match that string.
These are placed in the text area in the bottom of the window.
Initially, the server is set to whois.internic.net, but the user is free to change this setting.
You don't want the buttons in the south and north // to fill the entire sections so add Panels there // and use FlowLayouts in the Panel.
Then the with LayoutManager-based interfaces, the setup is fairly involved.
Because you’d probably use a visual designer to build such an application, I won’t describe it in detail here.
This isn’t in the constructor because other programs that use this class may not want to exit the an obscure race condition that can lead to deadlock this needs to be done in the event dispatch thread; hence the FrameShower inner class that implements Runnable and the event dispatch thread.
The first event this program must respond to is the user typing a name in the Whois: search box and either clicking the Find button or hitting Enter.
In this case, the Lookup Names inner class sets the main text to the empty string and executes a SwingWorker to make the network connection.
SwingWorker (introduced in Java 6) is a really important class to learn if you’re going to write GUI applications that access the network, or for that matter perform any I/O at all.
In any Java GUI application there are two rules you must follow in order to avoid deadlock and slowness:
All updates to Swing components happen on the event dispatch thread.
No slow blocking operations, especially I/O, happen on the event dispatch thread.
These two rules are at loggerheads for network- and I/O-heavy code because the part of the code that performs the I/O can’t update the GUI and vice versa.
There are several ways to sidestep this paradox, but prior to Java 6 they’re all quite complex.
In Java 6 and later, however, the solution is easy.
Define a subclass of Swing Worker and override two methods:
It can return any convenient type and throw any exception.
Example 8-8 uses an inner class named Lookup as its SwingWorker.
The second event this program must respond to is the user typing a new host in the server text field.
In this case, an anonymous inner class tries to construct a new Whois object and stores it in the server field.
If it fails (e.g., because the user mistyped the hostname), the old server is restored.
The most glaring omission is that it doesn’t provide a way to save the data and quit the program.
However, it does demonstrate how to safely make network connections from a GUI program without blocking the event dispatch thread.
The previous chapter discussed sockets from the standpoint of clients: programs that open a socket to a server that’s listening for connections.
However, client sockets themselves aren’t enough; clients aren’t much use unless they can talk to a server, and the Socket class discussed in the previous chapter is not sufficient for writing servers.
To create a Socket, you need to know the Internet host to which you want to connect.
When you’re writing a server, you don’t know in advance who will contact you; and even if you did, you wouldn’t know when that host wanted to contact you.
In other words, servers are like receptionists who sit by the phone and wait for incoming calls.
They don’t know who will call or when, only that when the phone rings, they have to pick it up and talk to whoever is there.
You can’t program that behavior with the Socket class alone.
For servers that accept connections, Java provides a ServerSocket class that represents server sockets.
In essence, a server socket’s job is to sit by the phone and wait for incoming calls.
More technically, a server socket runs on the server and listens for incoming TCP connections.
Each server socket listens on a particular port on the server machine.
When a client on a remote host attempts to connect to that port, the server wakes up, negotiates the connection between the client and the server, and returns a regular Socket object representing the socket between the two hosts.
In other words, server sockets wait for connections while client sockets initiate connections.
Once a ServerSocket has set up the connection, the server uses a regular Socket object to send data to the client.
Using ServerSockets The ServerSocket class contains everything needed to write servers in Java.
It has constructors that create new ServerSocket objects, methods that listen for connections on.
In Java, the basic life cycle of a server program is this:
The ServerSocket listens for incoming connection attempts on that port using its server.
The server and the client interact according to an agreed-upon protocol until it is time to close the connection.
The server returns to step 2 and waits for the next connection.
When a client connects, the server sends the time in a human-readable format and closes the connection.
For example, here’s a connection to the daytime server at time-a.nist.gov:
First, create a server socket that listens on port 13:
Note that the connection is returned a java.net.Socket object, the same as you used for clients in the previous chapter.
The daytime protocol requires the server (and only the server) to talk, so get an OutputStream from the socket.
Because the daytime protocol requires text, chain this to an OutputStreamWriter:
Now get the current time and write it onto the stream.
The daytime protocol doesn’t require any particular format other than that it be human readable, so let Java pick for you:
Do note, however, the use of a carriage return/linefeed pair to terminate the line.
This is almost always what you want in a network server.
You should explicitly choose this rather than using the system line separator, whether explicitly with System.getProper.
You won’t always have to close the connection after just one write.
Many protocols, dict and HTTP 1.1 for instance, allow clients to send multiple requests over a single socket and expect the server to send multiple responses.
Some protocols such as FTP can even hold a socket open indefinitely.
If the client closes the connection while the server is still operating, the input and/or output streams that connect the server to the client throw an InterruptedIOExcep tion on the next read or write.
In either case, the server should then get ready to process the next incoming connection.
Of course, you’ll want to do all this repeatedly, so you’ll put this all inside a loop.
Each representing the connection between the remote client and the local server.
Interaction with the client takes place through this Socket object.
There’s one big loop, and in each pass through the loop a single connection is completely processed.
This works well for a very simple protocol with very small requests and responses like daytime, though even with this simple a protocol it’s possible for one slow client to delay other faster clients.
Upcoming examples will address this with multiple threads or asynchronous I/O.
When exception handling is added, the code becomes somewhat more convoluted.
It’s and log an error message, and exceptions that should just close that active connection.
Exceptions within the scope of a particular connection should close that connection, but not affect other connections or shut down the server.
Exceptions outside the scope of an individual request probably should shut down the server.
In Chapter 8, I said that a client shouldn’t rely on the other side of a connection to close the socket; that goes triple for servers.
Clients time out or crash; users cancel transactions; networks go down in hightraffic periods; hackers launch denial-of-service attacks.
The inner try block watches for exceptions thrown while infinite loop to watch for new connections; like many servers, this program never terminates but continues listening until an exception is thrown or you stop it manually.
The command for stopping a program manually depends on your system; under Unix, Windows, and many other systems, Ctrl-C will do the job.
If you are running the server in the background on a Unix system, stop it by finding the server’s process ID and killing it with the kill command (kill pid )
If you run this program on Unix (including Linux and Mac OS X), you need to run it as root in order to connect to port 13
Serving Binary Data Sending binary, nontext data is not significantly harder.
You just use an Output Stream that writes a byte array rather than a Writer that writes a String.
Once again, the current time is found by creating a new Date object.
As with the TimeClient of the previous chapter, most of the effort here goes into working with a data format (32-bit unsigned integers) that Java doesn’t natively support.
Multithreaded Servers Daytime and time are both very quick protocols.
The server sends a few dozen bytes at most and then closes the connection.
It’s plausible here to process each connection fully before moving on to the next one.
Even in that case, though, it is possible that a slow or crashed client might hang the server for a few seconds until it notices the socket is broken.
If the sending of data can take a significant amount of time even when client and server are behaving, you really don’t want each connection to wait for the next.
Old-fashioned Unix servers such as wu-ftpd create a new process to handle each connection so that multiple clients can be serviced at the same time.
Java programs should spawn a thread to interact with the client so that the server can be ready to process the next connection sooner.
A thread places a far smaller load on the server than a complete child process.
In fact, the overhead of forking too many processes is why the typical Unix FTP server can’t handle more than roughly 400 connections without slowing to a.
On the other hand, if the protocol is simple and quick and allows the server to close the connection when it’s through, it will be more efficient for the server to process the client request immediately without spawning a thread.
The operating system stores incoming connection requests addressed to a particular port in a first-in, first-out queue.
By default, Java sets the length of this queue to 50, although it can vary from operating system to operating system.
Some operating systems (not Solaris) have a maximum queue length.
For instance, on FreeBSD, the default maximum queue length is 128
On these systems, the queue length for a Java server socket will be the largest operating-system allowed value less than or equal to 50
After the queue fills to capacity with unprocessed connections, the host refuses additional connections on that port until slots in the queue open up.
Many (though not all) clients will try to make a connection multiple times if their initial attempt is refused.
Several ServerSocket constructors allow you to change the length of the queue if its default length isn’t large enough.
However, you won’t be able to increase the queue beyond the maximum size that the operating system supports.
Whatever the queue size, though, you want to be able to empty it faster than new connections are coming in, even if it takes a while to process each connection.
The solution here is to give each connection its own thread, separate from the thread that accepts incoming connections into the queue.
For instance, Example 9-3 is a daytime server that spawns a new thread to handle each incoming connection.
This prevents one slow client from blocking all the other clients.
However, it deliberately does not use try-with-resources for the client sockets accepted by the server socket.
This is because the client socket escapes from the try block into a separate thread.
If you used try-with-resources, the main thread would close the socket as soon as it got to the end of the while loop, likely before the spawned thread had finished using it.
Because Example 9-3 spawns a new thread for each connection, numerous roughly simultaneous incoming connections can cause it to spawn an indefinite number of threads.
Eventually, the Java virtual machine will run out of memory and crash.
A better approach is to use a fixed thread pool as described in Chapter 3 to limit the potential resource usage.
Example 9-4 shouldn’t crash no matter what load it’s under.
The single difference is that it uses a Callable rather than a Thread subclass, and rather than starting threads it submits these callables to an executor service preconfigured with 50 threads.
Writing to Servers with Sockets In the examples so far, the server has only written to client sockets.
You’ll accept a connection as before, but this time ask for both an InputStream and an Out putStream.
Read from the client using the InputStream and write to it using the Out putStream.
The main trick is understanding the protocol: when to write and when to read.
The echo protocol, defined in RFC 862, is one of the simplest interactive TCP services.
The client opens a socket to port 7 on the echo server and sends data.
The echo protocol is useful for testing the network to make sure that data is not mangled by a misbehaving router or firewall.
This sample is line oriented because that’s how Telnet works.
It reads a line of input from the console, sends it to the server, then waits to read a line of output it gets back.
It doesn’t really care whether those bytes represent characters in some encoding or are divided into lines.
Unlike many protocols, echo does not specify lockstep behavior where the client sends a request but then waits for the full server response before sending any more data.
Unlike daytime and time, in the echo protocol the client is responsible for closing the connection.
This makes it even more important to support asynchronous operation with many threads because a single client can remain connected indefinitely.
Closing Server Sockets If you’re finished with a server socket, you should close it, especially if the program is going to continue to run for some time.
This frees up the port for other programs that may wish to use it.
Closing a ServerSocket should not be confused with closing a Socket.
Closing a ServerSocket frees a port on the local host, allowing another server to bind to the port; it also breaks all currently open sockets that the ServerSocket has accepted.
Server sockets are closed automatically when a program dies, so it’s not absolutely necessary to close them in programs that terminate shortly after the ServerSocket is no longer needed.
Programmers often follow the same closeif-not-null pattern in a try-finally block that you’re already familiar with from streams and client-side sockets:
In Java 7, ServerSocket implements AutoCloseable so you can take advantage of trywith-resources instead:
After a server socket has been closed, it cannot be reconnected, even to the same port.
If you need to test whether a ServerSocket is open, For example:
It’s often important to debug what happened when in a server long after the fact.
For this reason, it’s advisable to store server logs for at least some period of time.
What to Log There are two primary things you want to store in your logs:
Indeed, servers often keep two different logfiles for these two different items.
The audit log usually contains one entry for each connection made to the server.
Servers that perform multiple operations per connection may have one entry per operation instead.
For instance, a dict server might log one entry for each word a client looks up.
The error log contains mostly unexpected exceptions that occurred while the server was running.
For instance, any NullPointerException that happens should be logged here because it indicates a bug in the server you’ll need to fix.
The error log does not contain client errors, such as a client that unexpectedly disconnects or sends a malformed request.
The general rule of thumb for error logs is that every line in the error log should be looked at and resolved.
The ideal number of entries in an error log is zero.
Every entry in this log represents a bug to be investigated and resolved.
If investigation of an error log entry ends with the decision that that exception is not really a problem, and the code is working as intended, remove the log statement.
Error logs that fill up with too many false alarms rapidly become ignored and useless.
For the same reason, do not keep debug logs in production.
Do not log every time you enter a method, every time a condition is met, and so on.
If you need method-level logging for debugging, put it in a separate file, and turn it off in the global properties file when running in production.
More advanced logging systems provide log analysis tools that enable you to do things like show only messages with priority INFO or higher, or only show messages that originated from a certain part of the code.
These tools make it more feasible to keep a single logfile or database, perhaps even share one log among many different binaries or programs.
Nonetheless, the principle still applies that a log record no one will ever look at is worthless at best and more often than not distracting or confusing.
Do not follow the common antipattern of logging everything you can think of just in case someone might need it someday.
In practice, programmers are terrible at guessing in advance which log messages they might need for debugging production problems.
Once a problem occurs, it is sometimes obvious what messages you need; but it is rare to be able to anticipate this in advance.
Although you can load a logger on demand, it’s usually easiest to just create one per class like so:
Loggers are thread safe, so there’s no problem storing them in a shared static field.
Indeed, they almost have to be because even if the Logger object were not shared between threads, the logfile or database would be.
This example outputs to a log named “requests.” Multiple Logger objects can output to the same log, but each logger always logs to exactly one log.
What and where the log is depends on external configuration.
Most commonly it’s a file, which may or may not be named “requests”; but it can be a database, a SOAP service running on a different server, another Java program on the same host, or something else.
Once you have a logger, you can write to it using any of several methods.
Including the exception instead of just a message is optional but customary when logging from a catch block.
There are seven levels defined as named constants in java.util.logging.Level in descending order of seriousness:
I use info for audit logs and warning or severe for error logs.
Lower levels are for debugging only and should not be used in production systems.
Info, severe, and warning all have convenience helper methods that log at that level.
For example, this statement logs a hit including the date and the remote address:
You can use any format that’s convenient for the individual log records.
Generally, each record should contain a timestamp, the client address, and any information specific to the request that was being processed.
If the log message represents an error, include the specific exception that was thrown.
Java fills in the location in the code where the message was logged automatically, so you don’t need to worry about that.
Example 9-6 demonstrates by adding logging to the daytime server.
As well as logging, Example 9-6 has also added catch blocks for RuntimeException that cover most of the code and all of the network connections.
The last thing you want is for your entire server to fall down just because one request went down an unplanned code path and threw an IllegalArgumentExcep tion.
Usually when this happens that request is going to fail, but you can continue processing other requests.
If you’re even more careful, you can send the client the appropriate error response.
In HTTP, this would be a 500 internal server error.
Not every exception automatically turns into an error log entry.
For example, if a client disconnects while you’re writing the time, that’s an IOException.
In some situations, you might want to log it in the audit log, or a third location.
However, remember the golden rule of logging: if no one’s going to look at it, don’t log it.
Unless you really plan to investigate and do something about client disconnects, don’t bother to record them.
By default, the logs are just output to the console.
For example, here’s the output from the preceding server when I connected to it a few times in quick succession:
You’ll want to configure the runtime environment such that logs go to a more permanent destination.
Although you can specify this in code, it’s usually advisable to set this up in a configuration file so log locations can be changed without recompiling.
The java.util.logging.config.file system property points to a file in the normal properties format that controls the logging.
Example 9-7 is a sample logging properties file that specifies:
The requests log should be in /var/logs/daytime/requests.log at level Info.
The errors log should be in /var/logs/daytime/requests.log at level Severe.
Limit the log size to about 10 megabytes, then rotate.
Keep two logs: the current one and the previous one.
Each line of the logfile should be in the form level message timestamp.
Here’s some typical log output (note that it looks like the timestamp is doubled in request messages because the log message also includes the current time; this would not typically be the case for a server whose purpose was anything other than serving the current time):
The one thing I don’t like about the Java Logging API is that it doesn’t give you an easy way to specify by configuration alone that different messages belong in different logs.
For instance, you can’t easily separate your error and your audit log.
It can be done, but it requires you to define a new subclass of FileHandler for each separate log so you can assign it a new file.
Finally, once you’ve configured your servers with logging, don’t forget to look in them, especially the error logs.
There’s no point to a logfile no one ever looks at.
You’ll also want to plan for and implement log rotation and retention policies.
Hard drives get bigger every year, but it’s still possible for a high-volume server to fill up a filesystem with log data if you aren’t paying attention.
Murphy’s law says this is most likely to happen at 4:00 A.M.
These constructors specify the port, the length of the queue used to hold incoming connection requests, and the local network interface to bind to.
They pretty much all do the same thing, though some use default values for the queue length and the address to bind to.
For example, to create a server socket that would be used by an HTTP server on port 80, you would write:
If you try to expand the queue past the operating system’s maximum queue length, the maximum queue length is used instead.
By default, if a host has multiple network interfaces or IP addresses, the server socket listens on the specified port on all the interfaces and IP addresses.
However, you can add a third argument to bind only to one particular local IP address.
That is, the server socket only listens for incoming connections on the specified address; it won’t listen for connections that come in through the host’s other addresses.
For example, login.ibiblio.org is a particular Linux box in North Carolina.
It’s connected to the Internet with the IP address 152.2.210.122
The same box has a second Ethernet card with the local IP address 192.168.210.122 that is not visible from the public Internet, only from the local network.
In all three constructors, you can pass 0 for the port number so the system will select an available port for you.
A port chosen by the system like this is sometimes called an anonymous port because you don’t know its number in advance (though you can find out after the port has been chosen)
This is often useful in multisocket protocols such as FTP.
In passive FTP the client first connects to a server on the well-known port 21, so the server has to specify that port.
However, when a file needs to be transferred, the server starts listening on any available port.
The server then tells the client what other port it should connect to for data using the command connection already open on port 21
Thus, the data port can change from one session to the next and does not need to be known in advance.
Active FTP is similar except the client listens on an ephemeral port for the server to connect to it, rather than the other way around.)
All these constructors throw an IOException, specifically, a BindException, if the socket cannot be created and bound to the requested port.
An IOException when creating a ServerSocket almost always means one of two things.
You can take advantage of this to write a variation on the LowPortScanner program of the previous chapter.
Rather than attempting to connect to a server running on a given port, you instead attempt to open a server on that port.
Example 9-8 checks for ports on the local machine by attempting to create Server Socket objects on them and seeing on which ports that fails.
If you’re using Unix and are not running as root, this program works only for ports 1024 and above.
Here’s the output I got when running LocalPortScanner on my Windows workstation:
Constructing Without Binding The noargs constructor creates a ServerSocket object but does not actually bind it to a port, so it cannot initially accept any connections.
The primary use for this feature is to allow programs to set server socket options before binding to a port.
Some options are fixed after the server socket has been bound.
You can also pass null for the SocketAddress to select an arbitrary port.
This is like passing 0 for the port number in the other constructors.
Getting Information About a Server Socket The ServerSocket class provides two getter methods that tell you the local address and port occupied by the server socket.
These are useful if you’ve opened a server socket on an anonymous port and/or an unspecified network interface.
This would be the case, for one example, in the data connection of an FTP session:
This method returns the address being used by the server (the local host)
If the local host has a single IP address (as most do), this is the address returned by InetAd address returned is one of the host’s IP addresses.
If the ServerSocket has not yet bound to a network interface, this method returns null:
The ServerSocket constructors allow you to listen on an unspecified port by passing 0 for the port number.
This method lets you find out what port you’re listening on.
You might use this in a peer-to-peer multisocket program where you already have a means to inform other peers of your location.
Or a server might spawn several smaller servers to perform particular operations.
At least on this system, the ports aren’t truly random, but they are indeterminate until runtime.
As with most Java objects, you can also just print out a ServerSocket using its to like this:
This will be 0.0.0.0 if it’s bound to all interfaces, as is commonly the case.
The localport is the local port on which the server is listening for connections.
This method is sometimes useful for debugging, but not much more.
Socket Options Socket options specify how the native sockets on which the ServerSocket class relies send and receive data.
It also allows you to set performance preferences for the socket’s packets.
You might need it if you were implementing a complicated and secure protocol that required multiple connections between the client and the server where responses needed to occur within a fixed amount of time.
However, most servers are designed to run for indefinite periods of time and therefore just use the default timeout value, 0 (never time out)
It determines whether a new socket will be allowed to bind to a previously used port while there might still be data traversing the network addressed to the old socket.
As you probably expect, there are two methods to get and set this option:
On the Linux and Mac OS X boxes where I tested this code, server sockets were reusable by default.
Recall from the previous chapter that this option suggests a value for the size of the individual IP packets in the stream.
Faster connections will want to use larger buffers, although most of the time the default value is fine.
You can set this option before or after the server socket is bound, unless you want to set a receive buffer size larger than 64K.
In that case, you must set the option on an unbound ServerSocket before binding it.
Class of Service As you learned in the previous chapter, different types of Internet services have different performance needs.
For instance, live streaming video of sports needs relatively high bandwidth.
On the other hand, a movie might still need high bandwidth but be able to tolerate more delay and latency.
Email can be passed over low-bandwidth connections and even held up for several hours without major harm.
These traffic classes can be requested for a given Socket.
For instance, you can request the minimum delay available at low cost.
These measures are all fuzzy and relative, not guarantees of service.
Not all routers and native TCP stacks support these classes.
Exactly how any given VM implements this is implementation dependent.
The underlying socket implementation is not required to respect any of these requests.
They only provide a hint to the TCP stack about the desired policy.
As you saw in Chapter 5, a full-featured HTTP server must respond to requests for files, convert URLs into filenames on the local system, respond to POST and GET requests, handle requests for files that don’t exist, interpret MIME types, and much, much more.
However, many HTTP servers don’t need all of these features.
Such a site is a candidate for a custom server that does only one thing.
Java’s network class library makes writing simple servers like this almost trivial.
High-traffic sites like Yahoo! are also candidates for custom servers because a server that does only one thing can often be much faster than a general-purpose server such as Apache or Microsoft IIS.
It is easy to optimize a special-purpose server for a particular task; the result is often much more efficient than a general-purpose server that needs to respond to many different kinds of requests.
For instance, icons and images that are used repeatedly across many pages or on high-traffic pages might be better handled by a server that read all the image files into memory on startup and then served them straight out of RAM, rather than having to read them off disk for each request.
Furthermore, this server could avoid wasting time on logging if you didn’t want to track the image requests separately from the requests for the pages in which they were included.
Finally, Java isn’t a bad language for full-featured web servers meant to compete with the likes of Apache or IIS.
Even if you believe CPU-intensive Java programs are slower than CPU-intensive C and C++ programs (something I very much doubt is true in modern VMs), most HTTP servers are limited by network bandwidth and latency, not by CPU speed.
Consequently, Java’s other advantages, such as its half-compiled/halfinterpreted nature, dynamic class loading, garbage collection, and memory protection really get a chance to shine.
In particular, sites that make heavy use of dynamic content through servlets, PHP pages, or other mechanisms can often run much faster when reimplemented on top of a pure or mostly pure Java web server.
Indeed, there are several production web servers written in Java, such as the Eclipse Foundation’s Jetty.
These largely replaced traditional CGIs, ASPs, and server-side includes, mostly because the Java equivalents are faster and less resource intensive.
I’m not going to explore these technologies here because they easily deserve a book of their own.
However, it is important to note that servers in general and web servers in particular are one area where Java really is competitive with C for real-world performance.
A Single-File Server Our investigation of HTTP servers begins with a server that always sends out the same file, no matter what the request.
The filename, local port, and content encoding are read from the command line.
The constructors set up the data to be sent along with an HTTP header that includes information about content length and content encoding.
The header and the body of the response are stored in byte arrays in the desired encoding so that they can be blasted to clients very quickly.
The SingleFileHTTPServer class holds the content to send, the header to send, and the enters an infinite loop that continually accepts connections and processes them.
Each incoming socket is processed by a runnable Handler object that is submitted to a thread pool.
Each Handler gets an InputStream from it which it reads the client request.
It looks at the first line to see whether it contains the string HTTP.
If it sees this string, the server assumes that the client understands HTTP/1.0 or later and therefore sends a MIME header for the file; then it sends the data.
If the client request doesn’t contain the string HTTP, the server omits the header, sending the data by itself.
If no file is specified or the file cannot be opened, an error message is printed and the program exits.
Assuming the file can be read, its contents are read into the byte array data using the Path and Files classes introduced in Java 7
The URLConnection class makes a reasonable guess about the content type of the file, and that guess is stored in the contentType variable.
Next, the port number is read from the second command-line argument.
Then these values are used to construct a SingleFileHTTPServer object and start it.
If you added a setter method to change the content, you could easily use it to provide simple status information about a running server or system.
However, that would raise some additional issues of thread safety that Example 9-10 doesn’t have to address because the data is immutable.
Here’s what you see when you connect to this server via Telnet (the specifics depend on the exact server and file):
A Redirector Redirection is another simple but useful application for a special-purpose HTTP server.
In this section, you develop a server that redirects users from one website to another— for example, from cnet.com to www.cnet.com.
In this example, I chose to use a new thread rather than a thread pool for each connection.
This is perhaps a little simpler to code and understand but somewhat less efficient.
If this is HTTP/1.0 or later send a MIME header // Not all browsers support redirection so we need to // produce HTML that says where the document has moved to.
In order to start the redirector on port 80 and redirect incoming requests to http:// www.cafeconleche.org/, type:
If you connect to this server via Telnet, this is what you’ll see:
If, however, you connect with a web browser, you should be sent to http://www.cafeconleche.org/ with only a slight delay.
It uses this information to Redirector listens on port 80
If the site is omitted, Redirector prints an error message and exits.
Every time a connection is accepted, the resulting Socket object is used to construct a Redi rectThread.
Writer to the Socket’s output stream and a Reader to the Socket’s input stream.
Although the client will probably send a whole MIME header, you can ignore that.
It is possible that the first word will be POST or PUT instead or that there will be no HTTP version.
The second “word” is the file the client wants to retrieve.
Browsers are responsible for converting relative URLs to absolute URLs that begin with a slash; the server does not do this.
The third word is the version of the HTTP protocol the browser understands.
To handle a request like this, Redirector ignores the first word.
The second word is attached to the URL of the target server (stored in the field newSite) to give a full redirected URL.
The third word is used to determine whether to send a MIME header; MIME headers are not used for old browsers that do not understand HTTP/1.0
If there is a version, a MIME header is sent; otherwise, it is omitted.
Because all the data you send is pure ASCII, the exact encoding isn’t too important.
The only trick here is that the end-of-line character for HTTP requests is \r\n–a carriage return followed by a linefeed.
The next lines each send one line of text to the client.
This is an HTTP/1.0 response code that tells the client to expect to be redirected.
The second line is a Date: header that gives the current time at the server.
The third line is the name and version of the server; this line is also optional but is used by spiders that try to keep statistics about the most popular web servers.
The next line is the Location: header, which is required for this response type.
It tells the client where it is being redirected to.
You send the content type text/html to indicate that the client should expect to see HTML.
Finally, a blank line is sent to signify the end of the header data.
Everything after this will be HTML, which is processed by the browser and displayed to the user.
The next several lines print a message for browsers that do not support redirection, so those users can manually jump to the new site.
The document / has moved to Please update your bookmarks<P></BODY></HTML>
This next section develops a full-blown HTTP server, called JHTTP, that can serve an entire document tree, including images, applets, HTML files, text files, and more.
It will be very similar to the SingleFileHTTPServer, except that it pays attention to the GET requests.
This server is still fairly lightweight; after looking at the code, we’ll discuss other features you might want to add.
Because this server may have to read and serve large files from the filesystem over potentially slow network connections, you’ll change its approach.
Rather than processing each request as it arrives in the main thread of execution, you’ll place incoming connections in a pool.
Separate instances of a RequestProcessor class will remove the connections from the pool and process them.
You submit one RequestProcessor thread per incoming connection into the pool.
It gets input and output streams from the socket and chains them to a reader and a writer.
Assuming the method is GET, the file that is requested is converted to a filename on the local filesystem.
If the file requested is a directory (i.e., its name ends with a slash), you add the name of an index file.
You use the canonical path to make sure that the requested file doesn’t come from outside the document root directory.
Otherwise, a sneaky client could walk all over the local filesystem by including ..
This is all you’ll need from the client, although a more advanced web server, especially one that logged hits, would read the rest of the MIME header the client sends.
Next, the requested file is opened and its contents are read into a byte array.
If the HTTP version is 1.0 or later, you write the appropriate MIME headers on the output stream.
ContentTypeFor(fileName) method to map file extensions such as .html onto MIME types such as text/html.
The byte array containing the file’s contents is written onto the output stream and the connection is closed.
If the file cannot be found or opened, you send the client a 404 response instead.
If the client sends a method you don’t support, such as POST, you send back a 501 error.
If an exception occurs, you log it, close the connection, and continue.
Don't let clients outside the document root if (version.startsWith("HTTP/")) { // send a MIME header.
Finally, spend a little time thinking about ways to optimize this server.
If you really want to use JHTTP to run a high-traffic site, there are a couple of things that can speed this server up.
Keep track of the requests you’ve received and store the data from the most frequently requested files in a Map so that they’re kept in memory.
You can also try using nonblocking I/O and channels instead of threads and streams.
And this is just a small sampling of government sponsored eavesdropping we know about.
As an Internet user, you do have defenses against snooping bureaucrats.
To make Internet connections more fundamentally secure, sockets can be encrypted.
Performing it properly requires a detailed understanding not only of the mathematical algorithms used to encrypt data, but also of the protocols used to exchange keys and encrypted data.
Even a small mistake can open a large hole in your armor and reveal your communications to an eavesdropper.
Consequently, writing encryption software is a task best left to experts.
Fortunately, nonexperts with only a layperson’s understanding of the underlying protocols and algorithms can secure their communications with software designed by experts.
Every time you order something from an online store, chances are the transaction is encrypted and authenticated using protocols and algorithms you need to know next to nothing about.
As a programmer who wants to write network client software that talks to online stores, you need to know a little more about the protocols and algorithms involved, but not a lot more, provided you can use a class library written by experts who do understand the details.
If you want to write the server software that runs the online store, you need.
Secure Communications Confidential communication through an open channel such as the public Internet absolutely requires that data be encrypted.
Most encryption schemes that lend themselves to computer implementation are based on the notion of a key, a slightly more general kind of password that’s not limited to text.
The plain-text message is combined with the bits of the key according to a mathematical algorithm to produce the encrypted ciphertext.
Using keys with more bits makes messages exponentially more difficult to decrypt by brute-force guessing of the key.
In traditional secret key (or symmetric) encryption, the same key is used to encrypt and decrypt the data.
Both the sender and the receiver have to know the single key.
She first sends Gus the key they’ll use to exchange the secret.
But the key can’t be encrypted because Gus doesn’t have the key yet, so Angela has to send the key unencrypted.
Now suppose Edgar is eavesdropping on the connection between Angela and Gus.
He will get the key at the same time that Gus does.
From that point forward, he can read anything Angela and Gus say to each other using that key.
In public key (or asymmetric) encryption, different keys are used to encrypt and decrypt the data.
A different key, called the private key, is used to decrypt the data.
This must be kept secret but needs to be possessed by only one of the correspondents.
If Angela wants to send a message to Gus, she asks Gus for his public key.
Angela uses Gus’s public key to encrypt her message and sends it to him.
If Edgar is eavesdropping when Gus sends Angela his key, Edgar also gets Gus’s public key.
However, this doesn’t allow Edgar to decrypt the message Angela sends Gus, because decryption requires Gus’s private key.
The message is safe even if the public key is detected in transit.
Asymmetric encryption can also be used for authentication and message integrity checking.
For this use, Angela would encrypt a message with her private key before sending it.
When Gus received it, he’d decrypt it with Angela’s public key.
If the decryption succeeded, Gus would know that the message came from Angela.
After all, no one else could have produced a message that would decrypt properly with her public.
Gus would also know that the message wasn’t changed en route, either maliciously by Edgar or unintentionally by buggy software or network noise, because any such change would have screwed up the decryption.
With a little more effort, Angela can double-encrypt the message, once with her private key, once with Gus’s public key, thus getting all three benefits of privacy, authentication, and integrity.
In practice, public-key encryption is much more CPU-intensive and much slower than secret-key encryption.
Therefore, instead of encrypting the entire transmission with Gus’s public key, Angela encrypts a traditional secret key and sends it to Gus.
Now Angela and Gus both know the secret key, but Edgar doesn’t.
Therefore, Gus and Angela can now use faster secret-key encryption to communicate privately without Edgar listening in.
Edgar still has one good attack on this protocol, however.
Important: the attack is on the protocol used to send and receive messages, not on the encryption algorithms used.
This attack does not require Edgar to break Gus and Angela’s encryption and is completely independent of key length.) Edgar can not only read Gus’s public key when he sends it to Angela, but he can also replace it with his own public key! Then when Angela thinks she’s encrypting a message with Gus’s public key, she’s really using Edgar’s.
When she sends a message to Gus, Edgar intercepts it, decrypts it using his private key, encrypts it using Gus’s public key, and sends it on to Gus.
Working alone on an insecure channel, Gus and Angela have no easy way to protect against this.
The solution used in practice is for both Gus and Angela to store and verify their public keys with a trusted third-party certification authority.
Rather than sending each other their public keys, Gus and Angela retrieve each other’s public key from the certification authority.
As this example indicates, the theory and practice of encryption and authentication, both algorithms and protocols, is a challenging field that’s fraught with mines and pitfalls to surprise the amateur cryptographer.
It is much easier to design a bad encryption algorithm or protocol than a good one.
And it’s not always obvious which algorithms and protocols are good and which aren’t.
Fortunately, you don’t have to be a cryptography expert to use strong cryptography in Java network programs.
All you have to do is send your data over the same streams and sockets you’re familiar with from previous chapters.
The abstract classes that define Java’s API for secure network communication.
The abstract socket factory classes used instead of constructors to create secure sockets.
The classes for handling the public-key certificates needed for SSL.
The concrete classes that implement the encryption algorithms and protocols in Sun’s reference implementation of the JSSE.
Other implementers may replace this package with one of their own; for instance, one that uses native code to speed up the CPU-intensive key generation and encryption process.
Creating Secure Client Sockets If you don’t care very much about the underlying details, using an encrypted SSL socket to talk to an existing secure server is truly straightforward.
Rather than constructing a java.net.Socket object with a constructor, you get one from a jav ry is an abstract class that follows the abstract factory design pattern.
This either returns an instance of SSLSocketFactory or throws an InstantiationEx ception if no concrete subclass can be found.
The first two methods create and return a socket that’s connected to the specified host and port or throw an IOException if they can’t connect.
The third and fourth methods connect and return a socket that’s connected to the specified host and port from the.
It begins with an existing Socket object that’s connected to a proxy server.
It returns a Socket that tunnels through this proxy server to the specified host and port.
The autoClose argument determines whether the underlying proxy socket should be closed when this socket is closed.
If autoClose is true, the underlying socket will be closed; if false, it won’t be.
The Socket that all these methods return will really be a javax.net.ssl.SSLSocket, a subclass of java.net.Socket.
Once the secure socket has been created, you use it just like any other socket, through its getInput accepts orders is listening on port 7000 of login.ibiblio.org.
Each order is sent as an ASCII string using a single TCP connection.
I’m leaving out a lot of details that would be necessary in a real-world system, such as the server sending a response code telling the client whether the order was accepted.) The orders that clients send look like this:
There’s enough information in this message to let someone snooping packets use John Smith’s credit card number for nefarious purposes.
The simplest way to do that without burdening either the server or the client with a lot of complicated, error-prone encryption code is to use a secure socket.
The following code sends the order over a secure socket:
Only the first three statements in the try block are noticeably different from what you’d do with an insecure socket.
The rest of the code just uses the normal methods of the Socket, OutputStream, and Writer classes.
Example 10-1 is a simple program that connects to a secure HTTP server, sends a simple GET request, and prints out the response.
Here are the first few lines of output from this program when you connect to the U.S.
When I tested this program for the previous edition, it initially refused to connect to www.usps.com because it couldn’t verify the identity of the remote server.
The problem was that the root certificates shipped with the version of the JDK I was using (1.4.2_02-b3) had expired.
Upgrading to the latest minor version (1.4.2_03-b2) fixed the problem.
When you run this program, you may notice that it’s slower to respond than you expect.
There’s a noticeable amount of both CPU and network overhead involved in generating.
Even over a fast network, it can take a few seconds to establish a connection.
Consequently, you may not want to serve all your content over HTTPS, only the content that really needs to be private and isn’t latency sensitive.
Choosing the Cipher Suites Different implementations of the JSSE support different combinations of authentication and encryption algorithms.
The stock JSSE bundled with the JDK actually does have code for stronger 256-bit encryption, but it’s disabled unless you install the JCE Unlimited Strength Jurisdiction Policy Files.
I don’t even want to begin trying to explain the legal briar patch that makes this necessary.
However, not all cipher suites that are understood are necessarily allowed on the connection.
The actual suite used is negotiated between the client and server at connection time.
It’s possible that the client and the server won’t agree on any suite.
It’s also possible that although a suite is enabled on both client and server, one or the other or both won’t have method will throw an SSLException, a subclass of IOException.
The argument to this method should be a list of the suites you want to use.
Each name has an algorithm divided into four parts: protocol, key exchange algorithm, encryption algorithm, and checksum.
If you want nonauthenticated transactions or authenticated but unencrypted transactions, you must enable those suites explicitly with that contain NULL, ANON, or EXPORT in their names unless you want the NSA to read your messages.
TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 is believed to be reasonably secure against all known attacks.
Most others are subject to attacks of varying levels of severity.
Besides key lengths, there’s an important difference between DES/AES and RC4-based ciphers.
If 64 bits aren’t available, the encoder has to pad the input with extra bits.
This isn’t a problem for file transfer applications such as secure HTTP and FTP, where more or less all the data is available at once.
However, it’s problematic for user-centered protocols such as chat and Telnet.
RC4 is a stream cipher that can encrypt one byte at a time and is more appropriate for protocols that may need to send a single byte at a time.
For example, let’s suppose that Edgar has some fairly powerful parallel computers at his disposal and can quickly break any encryption that’s 64 bits or less and that Gus and Angela know this.
Furthermore, they suspect that Edgar can blackmail one of their ISPs or the phone company into letting him tap the line, so they want to avoid anonymous connections that are vulnerable to man-in-the-middle attacks.
To be safe, Gus and Angela decide to use only the strongest suite available, which happens to be TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
This code fragment limits their connection to that one suite:
If the other side of the connection doesn’t support this encryption protocol, the socket will throw an exception when they try to read from or write to it, thus ensuring that no confidential information is accidentally transmitted over a weak channel.
Event Handlers Network communications are slow compared to the speed of most computers.
The necessary key generation and setup for a secure connection can easily take several seconds.
Consequently, you may want to deal with the connection asynchronously.
In order to get notifications of handshake-complete events, simply implement the HandshakeCompletedListener interface:
The HandshakeCompletedEvent class provides four methods for getting information about the event:
Particular HandshakeCompletedListener objects register their interest in handshakecompleted events from a particular SSLSocket via its addHandshakeCompletedListen.
Session Management SSL is commonly used on web servers, and for good reason.
Web connections tend to be transitory; every page requires a separate socket.
For instance, checking out of Amazon.com on its secure server requires seven separate page loads, more if you have to edit an address or choose gift wrapping.
Imagine if every one of those pages took an extra 10 seconds or more to negotiate a secure connection.
Because of the high overhead involved in handshaking between two hosts for secure communications, SSL allows sessions to be established that extend over multiple sockets.
Different sockets within the same session use the same set of public and private keys.
Amazon.com takes seven sockets, all seven will be established within the same session and use the same keys.
Only the first socket within that session will have to endure the overhead of key generation and exchange.
As a programmer using JSSE, you don’t need to do anything extra to take advantage of sessions.
If you open multiple secure sockets to one host on one port within a reasonably short period of time, JSSE will reuse the session’s keys automatically.
However, in highsecurity applications, you may want to disallow session-sharing between sockets or force reauthentication of a session.
In the JSSE, sessions are represented by instances of the SSLSession interface; you can use the methods of this interface to check the times the session was created and last accessed, invalidate the session, and get various information about the session:
It is more secure to renegotiate the key for each and every transaction.
If you’ve got really spectacular hardware and are trying to protect your systems from an equally determined, rich, motivated, and competent adversary, you may want to avoid sessions.
On rare occasions, you may even want to reauthenticate a connection (i.e., throw away all the certificates and keys that have previously been agreed to and start over with a.
Client Mode It’s a rule of thumb that in most secure communications, the server is required to authenticate itself using the appropriate certificate.
That is, when I buy a book from Amazon using its secure server, it has to prove to my browser’s satisfaction that it is indeed Amazon and not Joe Random Hacker.
For the most part, this is as it should be, because purchasing and installing the trusted certificates necessary for authentication is a fairly user-hostile experience that readers shouldn’t have to go through just to buy the latest Nutshell Handbook.
To avoid problems like this, sockets can be required to authenticate themselves.
This strategy wouldn’t work for a service open to the general public.
However, it might be reasonable in certain internal, high-security applications.
However, when true is passed in, it means the socket is in client mode (whether it’s on the client side or not) and will not offer to authenticate itself.
When false is passed, it will try to authenticate itself:
This property can be set only once for any given socket.
Attempting to set it a second time throws an IllegalArgumentException.
This method throws an IllegalArgumentException if the socket is not on the server side.
Creating Secure Server Sockets Secure client sockets are only half of the equation.
Like SSLSocket, all the constructors in this class are protected and instances are created by an abstract factory class, javax.net.SSLServerSocketFactory:
Also like SSLSocketFactory, an instance of SSLServerSocketFactory is returned by a.
If that were all there was to creating secure server sockets, they would be quite straightforward and simple to use.
In Sun’s reference implementation, a com.sun.net.ssl.SSLContext object is responsible for creating fully configured and initialized secure server sockets.
The details vary from JSSE implementation to JSSE implementation, but to create a secure server socket in the reference implementation, you have to:
Create a TrustManagerFactory for the source of certificate material you’ll be using.
Create a KeyManagerFactory for the type of key material you’ll be using.
Fill the KeyStore object with keys and certificates; for instance, by loading them from the filesystem using the passphrase they’re encrypted with.
The last two can be null if you’re willing to accept the defaults.)
Example 10-2 demonstrates this procedure with a complete SecureOrderTaker for accepting orders and printing them on System.out.
Of course, in a real application, you’d do something more interesting with the orders.
For security, every key store is encrypted with a // passphrase that must be provided before we can load // it from disk.
The passphrase is stored as a char[] array // so it can be wiped from memory quickly rather than // waiting for a garbage collector.
Now all the set up is complete and we can focus // on the actual communication.
What this example doesn’t show you is how that file was created.
It was built with the keytool program that’s bundled with the JDK like this:
Enter key password for <ourstore> (RETURN if same as keystore password):
When this is finished, you’ll have a file named jnp4e.keys, which contains your public keys.
However, no one will believe that these are your public keys unless you have them certified by a trusted third party such as GeoTrust or GoDaddy.
If you just want to explore the JSSE before deciding whether to go through the hassle and expense of purchasing a verified certificate, Oracle includes a verified keystore file called testkeys, protected with the password “passphrase,” that has some JSSE samples.
Another approach is to use cipher suites that don’t require authentication.
These are not enabled by default because they’re vulnerable to a man-in-the-middle attack, but at least they allow you to write simple programs without paying money.
Configuring SSLServerSockets Once you’ve successfully created and initialized an SSLServerSocket, there are a lot of applications you can write using nothing more than the methods inherited from java.net.ServerSocket.
However, there are times when you need to adjust its behavior a little.
Like SSLSocket, SSLServerSocket provides methods to choose cipher suites, manage sessions, and establish whether clients are required to authenticate themselves.
Most of these methods are similar to the methods of the same name in SSLSocket.
The difference is that they work on the server side and set the defaults for sockets accepted by an SSLServerSocket.
In some cases, once an SSLSocket has been accepted, you can still use the methods of SSLSocket to configure that one socket rather than all sockets accepted by this SSLServerSocket.
Choosing the Cipher Suites The SSLServerSocket class has the same three methods for determining which cipher suites are supported and enabled as SSLSocket does:
These use the same suite names as the similarly named methods in SSLSocket.
The difference is that these methods apply to all sockets accepted by the SSLServerSocket rather than to just one SSLSocket.
For example, the following code fragment has the effect of enabling anonymous, unauthenticated connections on the SSLServerSocket server.
It relies on the names of these suites containing the string anon.
This is true for Oracle’s reference implementations, though there’s no guarantee that other implementers will follow this convention:
This fragment retrieves the list of both supported and enabled cipher suites using get every supported suite to see whether it contains the substring “anon.” If the suite name does contain this substring, the suite is added to a list of anonymous cipher suites.
Once the list of anonymous cipher suites is built, it’s combined in a new array with the previous list of enabled cipher suites.
The new array is then passed to setEnabledCipher be used.
Session Management Both client and server must agree to establish a session.
If the server disallows session creation, then a client that wants a session will still be able to connect.
It just won’t get a session and will have to handshake again for every socket.
Similarly, if the client refuses sessions but the server allows them, they’ll still be able to talk to each other but without sessions.
Client Mode The SSLServerSocket class has two methods for determining and specifying whether client sockets are required to authenticate themselves to the server.
By passing true to is able to authenticate itself will be accepted.
By passing false, you specify that authentication is not required of clients.
For example, in an FTP session, the client program opens a server socket to receive data from the server, but that doesn’t SSLServerSocket is in client mode, false otherwise:
Furthermore, networking speeds are often referred to in kilo/mega/giga bits per second rather than bytes per second.
Here I’m reporting all numbers in bytes so I can compare hard drive, memory, and network bandwidths.
Compared to CPUs and memory or even disks, networks are slow.
A high-end modern PC is capable of moving data between the CPU and main memory at speeds of around six gigabytes per second.
And the speed across the public Internet is generally at least an order of magnitude smaller than what you see across a LAN.
CPUs, disks, and networks are all speeding up over time.
These numbers are all substantially higher than I reported in the third edition of this book 10 years ago.
Nonetheless, CPUs and disks are likely to remain several orders of magnitude faster than networks for the foreseeable future.
The last thing you want to do in these circumstances is make the blazingly fast CPU wait for the (relatively) molasses-slow network.
The traditional Java solution for allowing the CPU to race ahead of the network is a combination of buffering and multithreading.
Multiple threads can generate data for several different connections at once and store that data in buffers until the network is actually ready to send it; this approach works well for fairly simple servers and clients without extreme performance needs.
However, the overhead of spawning multiple threads and switching between them can be nontrivial.
On a large server that may be processing thousands of requests a second, you may not want to assign a thread to each connection.
It’s faster if one thread can take responsibility for multiple connections, pick one that’s ready to receive data, fill it with as much data as that connection can manage as quickly as possible, then move on to the next ready connection.
To work well, this approach needs to be supported by the underlying operating system.
Fortunately, pretty much every modern operating system you’re likely to be using as a high-volume server supports such nonblocking I/O.
However, it might not be well supported on some client systems of interest, such as tablets, cell phones, and the like.
Indeed, the java.nio package that provides this support is not part of any current or planned Java ME profiles, though it is found in Android.
However, the whole new I/O API is designed for and only really matters on servers, which is why I haven’t done more than allude to it until we began talking about servers.
Client and even peer-to-peer systems rarely need to process so many simultaneous connections that multithreaded, stream-based I/O becomes a noticeable bottleneck.
Furthermore, server memory had grown to the point where 10,000 simultaneous threads could easily fit in memory on commodity hardware; and multicore/multi-CPU systems that required multiple threads for maximum utilization were becoming common.
In 2013, it’s really hard to justify the added complexity of a NIO-based architecture compared to a much simpler thread-per-request or thread-per-connection design.
Are there any situations in which asynchronous I/O does beat classic I/O? Maybe.
The one situation I can still imagine is a server that needs to support a colossal number of long-lived, simultaneous connections, say 10,000+, but where each client doesn’t send very much data very frequently.
For instance, imagine a central server in the home office collecting transactions from each cash register in a nationwide chain of convenience stores.
This scenario is tailor-made for NIO, and can probably be implemented much more efficiently with asynchronous or nonblocking on-demand processing in just a few threads.
For experts only) OK, do it but only after you have clear and unambiguous measurements proving you have a problem, and that will clearly show whether your changes have fixed the problem.
An Example Client Although the new I/O APIs aren’t specifically designed for clients, they do work for them.
I’m going to begin with a client program using the new I/O APIs because it’s a little simpler.
In particular, many clients can be implemented with one connection at a time, so I can introduce channels and buffers before talking about selectors and nonblocking I/O.
A simple client for the character generator protocol defined in RFC 864 will demonstrate the basics.
When a client connects, the server sends a continuous sequence of characters until the client disconnects.
The RFC does not specify which character sequence to send, but recommends that the server use a recognizable pattern.
I picked this protocol for the examples in this chapter because both the protocol for transmitting the data and the algorithm to generate the data are simple enough that they won’t obscure the I/O.
However, chargen can transmit a lot of data over a relatively few connections and quickly saturate a network.
It’s thus a good candidate for the new I/O APIs.
Chargen is not commonly used these days, and may be blocked by local firewalls even if it’s turned on.
It’s vulnerable to a “ping-pong” denialof-service attack, in which spoofed Internet packets cause two hosts to spew an unlimited amount of data at each other.
When implementing a client that takes advantage of the new I/O APIs, begin by invoking nels.SocketChannel object.
The argument to this method is a java.net.SocketAd dress object indicating the host and port to connect to.
For example, this fragment connects the channel to rama.poly.edu on port 19:
The channel is opened in blocking mode, so the next line of code won’t execute until the connection is established.
If the connection can’t be established, an IOException is thrown.
If this were a traditional client, you’d now ask for the socket’s input and/or output streams.
With a channel you write directly to the channel itself.
It returns the number of bytes it successfully read and stored in the buffer:
By default, this will read at least one byte or return –1 to indicate the end of the data, exactly as an InputStream does.
It will often read more bytes if more bytes are available to be read.
Shortly you’ll see how to put this client in nonblocking mode where it will return 0 immediately if no bytes are available, but for the moment this code blocks just like an InputStream.
As you could probably guess, this method can also throw an IOException if anything goes wrong with the read.
There are ways to extract a byte array from a ByteBuffer that can then be written on a traditional OutputStream such as System.out.
However, it’s more informative to stick with a pure, channel-based solution.
Such a solution requires wrapping the OutputStream System.out in a channel using the Channels utility class, specifically,
You can then write the data that was read onto this output channel connected to System.out.
However, before you do that, you have to flip the buffer so that the output channel starts from the beginning of the data that was read rather than the end:
You don’t have to tell the output channel how many bytes to write.
However, in general, the output channel is not guaranteed to write all the bytes in the buffer.
In this specific case, though, it’s a blocking channel and it will either do so or throw an IOException.
You shouldn’t create a new buffer for each read and write.
You’ll need to clear the buffer before reading into it again:
Flipping leaves the data in the buffer intact, but prepares it for writing rather than reading.
The old data is still present; it’s not overwritten, but it will be overwritten with new data read from the source as soon as possible.)
Because chargen is by design an endless protocol, you’ll need to kill the program using Ctrl-C.
So far, this is just an alternate vision of a program that could have easily been written using streams.
The really new feature comes if you want the client to do something besides copying all input to output.
You can run this connection in either blocking or This allows the program to do something else before it attempts to read.
It doesn’t have to wait for a slow network connection.
Put whatever code here you want to run every pass through the loop // whether anything is read or not // This shouldn't happen unless the server is misbehaving.
There’s not a lot of call for this in a one-connection client like this one.
Perhaps you could check to see if the user has done something to cancel input, for example.
However, as you’ll see in the next section, when a program is processing multiple connections, this enables code to run very quickly on the fast connections and more slowly on the slow ones.
Each connection gets to run at its own speed without being held up behind the slowest driver on the one-lane road.
An Example Server Clients are well and good, but channels and buffers are really intended for server systems that need to process many simultaneous connections efficiently.
Handling servers requires a third new piece in addition to the buffers and channels used for the client.
Specifically, you need selectors that allow the server to find all the connections that are ready to receive output or send input.
To demonstrate the basics, this example implements a simple server for the character generator protocol.
When implementing a server that takes advantage of the new I/O to create a new ServerSocketChannel object:
Initially, this channel is not actually listening on any port.
To bind it to a port, retrieve on port 19:
In Java 7 and later, you can bind directly without retrieving the underlying java.net.ServerSocket:
As with regular server sockets, binding to port 19 requires you to be root on Unix (including Linux and Mac OS X)
Nonroot users can only bind to ports 1024 and higher.
The server socket channel is now listening for incoming connections on port 19
On the server side, you’ll definitely want to make the client channel nonblocking to allow the server to process multiple simultaneous connections:
Be sure to check for that or you’ll get a nasty NullPointerException when trying to use the socket.
There are now two open channels: a server channel and a client channel.
Furthermore, processing the server channel will create more open client channels.
In the traditional approach, you assign each connection a thread, and the number of threads climbs rapidly as clients connect.
Instead, in the new I/O API, you create a Selector that enables the program to iterate over all the connections that are ready to be processed.
Next, you need to register each channel with the selector that monitors it using the in using a named constant from the SelectionKey class.
For the client channels, you want to know something a little different—specifically, whether they’re ready to have data written onto them.
This is normally used to hold an object that indicates the current state of the connection.
In this case, you can store the buffer that the channel writes onto the network.
Fill an array with the data that will be copied into each buffer.
Rather than writing to the end of the buffer, and then rewinding to the beginning of the buffer and writing again, it’s easier just to start with two sequential copies of the data so every line is available as a contiguous sequence in the array:
Because this array will only be read from after it’s been initialized, you can reuse it for multiple channels.
However, each channel will get its own buffer filled with the contents of this array.
You’ll stuff the buffer with the first 72 bytes of the rotation array, then add a carriage return/linefeed pair to break the line.
Then you’ll flip the buffer so it’s ready for draining, and attach it to the channel’s key:
For a long-running server, this normally goes in an infinite loop:
In either case, you can loop through this with a java.util.Iterator:
Remove key from set so we don't process it twice // operate on the channel...
Removing the key from the set tells the Selector that you’ve dealt with it, and the channel becomes ready again.
It’s really important to remove the key from the ready set here, though.
If the ready channel is the server channel, the program accepts a new socket channel and adds it to the selector.
If the ready channel is a socket channel, the program writes as much of the buffer as it can onto the channel.
If no channels are ready, the selector waits for one.
In this case, it’s easy to tell whether a client or a server channel has been selected because the server channel will only be ready for accepting and the client channels will only be.
Both of these are I/O operations, and both can throw IOExceptions for a variety of reasons, so you’ll want to wrap this all in a try block:
Otherwise, refill the buffer with the next line of data from the rotation array and write that.
Refill the buffer with the next line // Figure out where the last line started // Increment to the next character.
The algorithm that figures out where to grab the next line of data relies on the characters data from the buffer.
From this number you subtract the space character (32) because that’s the first character in the rotation array.
This tells you which index in the array the buffer currently starts at.
You add 1 to find the start of the next line and refill the buffer.
In the chargen protocol, the server never closes the connection.
Example 11-2 puts this all together in a complete chargen server that processes multiple connections efficiently in a single thread.
Refill the buffer with the next line // Get the old first character // Get ready to change the data in the buffer // Find the new first characters position in rotation // copy the data from rotation into the buffer // Store a line break at the end of the buffer // Prepare the buffer for writing.
There are situations where you might still want to use multiple threads, especially if different operations have different priorities.
For instance, you might want to accept new connections in one high-priority thread and service existing connections in a lower-priority thread.
However, you’re no longer required to have a 1:1 ratio between threads and connections, which improves the scalability of servers written in Java.
It may also be important to use multiple threads for maximum performance.
Multiple threads allow the server to take advantage of multiple CPUs.
Even with a single CPU, it’s often a good idea to separate the accepting thread from the processing threads.
The thread pools discussed in Chapter 3 are still relevant even with the new I/O model.
The thread that accepts the connections can add the connections it’s accepted into the queue for processing by the threads in the pool.
This is still faster than doing the same thing here are tricky, so don’t attempt this until profiling proves there is a bottleneck.
Buffers In Chapter 2, I recommended that you always buffer your streams.
Almost nothing has a greater impact on the performance of network programs than a big enough buffer.
In the new I/O model, you’re no longer given the choice.
Instead of writing data onto output streams and reading data from input streams, you read and write data from buffers.
Buffers may appear to be just an array of bytes as in buffered streams.
However, native implementations can connect them directly to hardware or memory or use other, very efficient implementations.
From a programming perspective, the key difference between streams and channels is that streams are byte-based whereas channels are block-based.
A stream is designed to provide one byte after the other, in order.
However, the basic notion is to pass data one byte at a time.
By contrast, a channel passes blocks of data around in buffers.
Before bytes can be read from or written to a channel, the bytes have to be stored in a buffer, and the data is written or read one buffer at a time.
The second key difference between streams and channels/buffers is that channels and buffers tend to support both reading and writing on the same object.
For instance, a channel that points to a file on a CD-ROM can be read but not written.
A channel connected to a socket that has shutdown input could be written but not read.
If you try to write to a read-only channel or read from a write-only channel, an UnsupportedOperationException will be thrown.
However, more often than not network programs can read from and write to the same channels.
Without worrying too much about the underlying details (which can vary hugely from one implementation to the next, mostly as a result of being tuned very closely to the host operating system and hardware), you can think of a buffer as a fixed-size list of elements of a particular, normally primitive data type, like an array.
The methods in each subclass have appropriately typed return values and argument lists.
For example, the DoubleBuffer class has methods to put and get doubles.
The IntBuffer class has methods to put and get ints.
The common Buffer superclass only provides methods that don’t need to know the type of the data the buffer contains.
The lack of primitive-aware generics really hurts here.) Network programs use Byte Buffer almost exclusively, although occasionally one program might use a view that overlays the ByteBuffer with one of the other types.
Besides its list of data, each buffer tracks four key pieces of information.
All buffers have the same methods to set and get these values, regardless of the buffer’s type: position.
The next location in the buffer that will be read from or written to.
This starts counting at 0 and has a maximum value equal to the size of the buffer.
It can be set or gotten with these two methods:
This is set when the buffer is created and cannot be changed thereafter.
You cannot write or read at or past this point without changing the limit, even if the buffer has more capacity.
If the position is set below an existing mark, the mark is discarded.
Unlike reading from an InputStream, reading from a buffer does not actually change the buffer’s data in any way.
It’s possible to set the position either forward or backward so you can start reading from a particular place in the buffer.
Similarly, a program can adjust the limit to control the end of the data that will be read.
The common Buffer superclass also provides a few other methods that operate by reference to these common properties.
It is called when you want to drain a buffer you’ve just filled.
Finally, there are two methods that return information about the buffer but don’t change of remaining elements is greater than zero:
Creating Buffers The buffer class hierarchy is based on inheritance but not really on polymorphism, at least not at the top level.
You normally need to know whether you’re dealing with an.
IntBuffer or a ByteBuffer or a CharBuffer or something else.
You write code to one of these subclasses, not to the common Buffer superclass.
Each typed buffer class has several factory methods that create implementation-specific subclasses of that type in various ways.
Buffers that are prefilled with data are created by wrap methods.
The allocate methods are often useful for input, and the wrap methods are normally used for output.
For example, these lines create byte and int buffers, each with a size of 100:
The cursor is positioned at the beginning of the buffer (i.e., the position is 0)
A buffer of data into a buffer using a channel and then retrieve the array from the buffer to pass to other methods:
Changes to the backing array are reflected in the buffer and vice versa.
The normal pattern here is to fill the buffer with data, retrieve its backing array, and then operate on the array.
This isn’t a problem as long as you don’t write to the buffer after you’ve started working with the array.
The ByteBuffer class (but not the other buffer classes) has an additional allocateDir Ethernet card, kernel memory, or something else.
It’s not required, but it’s allowed, and this can improve performance for I/O operations.
Direct buffers may be faster on some virtual machines, especially if the buffer is large (roughly a megabyte or more)
However, direct buffers are more expensive to create than indirect buffers, so they should only be allocated when the buffer is expected to be around for a while.
As is generally true for most performance advice, you probably shouldn’t even consider using direct buffers until measurements prove performance is an issue.
Wrapping If you already have an array of data that you want to output, you’ll normally wrap a buffer around it, rather than allocating a new buffer and copying its components into the buffer one at a time.
Here, the buffer contains a reference to the array, which serves as its backing array.
Again, changes to the array are reflected in the buffer and vice versa, so don’t wrap the array until you’re finished with it.
Recall that each buffer has a curent position of elements in the buffer, inclusive.
The buffer’s position is incremented by one when an element is read from or written to the buffer.
For example, suppose you allocate a CharBuffer with capacity 12, and fill it by putting five characters into it:
You can only fill the buffer up to its capacity.
If you tried to fill it past its initially set.
Before you can read the data you wrote in out again, you need to flip the buffer:
Buffer classes also have absolute methods that fill and drain at specific positions within the buffer without updating the position.
These both throw an IndexOutOfBoundsException if you try to access a position at or past the limit of the buffer.
For example, using absolute methods, you can put the same text into a buffer like this:
However, you no longer need to flip before reading it out, because the absolute methods don’t change the position.
Bulk Methods Even with buffers, it’s often faster to work with blocks of data rather than filling and draining one element at a time.
The different buffer classes have bulk methods that fill and drain an array of their element type.
These put methods insert the data from the specified array or subarray, beginning at the current position.
The get methods read the data into the argument array or subarray beginning at the current position.
Both put and get increment the position by the length of the array or subarray.
The put methods throw a BufferOverflowException if the buffer does not have sufficient space for the array or subarray.
The get methods throw a BufferUnderflowException if the buffer does not have enough data remaining to fill the array or subarrray.
Data Conversion All data in Java ultimately resolves to bytes.
Any sequence of bytes of the right length can be interpreted as a primitive datum.
For example, any sequence of four bytes corresponds to an int or a float (actually both, depending on how you want to read it)
A sequence of eight bytes corresponds to a long or a double.
The ByteBuffer class (and only the ByteBuffer class) provides relative and absolute put methods that fill a buffer with the bytes corresponding to an argument of primitive type (except boolean) and relative and absolute get methods that read the appropriate number of bytes to form a new primitive datum:
In the world of new I/O, these methods do the job performed by DataOutputStream and DataInputStream in traditional I/O.
These methods do have an additional ability not present in DataOutputStream and DataInputStream.
You can choose whether to interpret the byte sequences as big-endian or little-endian ints, floats, doubles, and so on.
By default, all values are read and written as big endian (i.e., most significant byte constants in the ByteOrder class.
For example, you can change the buffer to little-endian interpretation like so:
Suppose instead of a chargen protocol, you want to test the network by generating binary data.
This test can highlight problems that aren’t apparent in the ASCII chargen protocol, such as an old gateway configured to strip off the high-order bit of every byte, throw away every 230 byte, or put into diagnostic mode by an unexpected sequence of control characters.
I’ve seen variations on all of these at one time or another.
You could test the network for such problems by sending out every possible int.
This would, after almost 4.3 billion iterations, test every possible four-byte sequence.
On the receiving end, you could easily test whether the data received is expected with a simple numeric comparison.
If any problems are found, it is easy to tell exactly where they occurred.
In other words, this protocol (call it Intgen) behaves like this:
The server will eventually wrap around into the negative numbers.
The server would store the current int in a four-byte-long direct ByteBuffer.
When the channel becomes available for writing, the buffer is drained onto the channel.
Then the buffer is rewound and the content of it flips the buffer so it will be ready to be drained the next time the channel becomes writable.
View Buffers If you know the ByteBuffer read from a SocketChannel contains nothing but elements of one particular primitive data type, it may be worthwhile to create a view buffer.
This is a new Buffer object of appropriate type (e.g., DoubleBuffer, IntBuffer, etc.), that draws its data from an underlying ByteBuffer beginning with the current position.
Changes to the view buffer are reflected in the underlying buffer and vice versa.
However, each buffer has its own independent limit, capacity, mark, and position.
View buffers are created with one of these six methods in ByteBuffer:
This protocol is only going to read ints, so it may be helpful to use an IntBuffer rather than a ByteBuffer.
For variety, this client is synchronous and blocking, but it still uses channels and buffers.
Although you can fill and drain the buffers using the methods of the IntBuffer class exclusively, data must be read from and written to the channel using the original ByteBuffer of which the IntBuffer is a view.
The SocketCh annel class only has methods to read and write ByteBuffers.
It cannot read or write any other kind of buffer.
This also means you need to clear the ByteBuffer on each pass through the loop or the buffer will fill up and the program will halt.
The positions and limits of the two buffers are independent and must be considered separately.
Finally, if you’re working in nonblocking mode, be careful that all the data in the underlying ByteBuffer is drained before reading or writing from the overlaying view buffer.
Nonblocking mode provides no guarantee that the buffer will still be aligned on an int, double, or char.
It’s completely possible for a nonblocking channel to write half the bytes of an int or a double.
When using nonblocking I/O, be sure to check for this problem before putting more data in the view buffer.
If it weren’t for invocation chaining, these six methods could have been replaced by one method in the common Buffer superclass.) Compacting shifts any remaining data in the buffer to the start of the buffer, freeing up more space for elements.
Any data that was in those positions will be overwritten.
The buffer’s position is set to the end of the data so it’s ready for writing more data.
Compacting is an especially useful operation when you’re copying—reading from one channel and writing the data to another using nonblocking I/O.
You can read some data into a buffer, write the buffer out again, then compact the data so all the data that wasn’t written is at the beginning of the buffer, and the position is at the end of the data remaining in the buffer, ready to receive more data.
This allows the reads and writes to be interspersed more or less at random with only one buffer.
Several reads can take place in a row, or several writes follow consecutively.
If the network is ready for immediate output but not input (or vice versa), the program can take advantage of that.
This technique can be used to implement an echo server as shown in Example 11-5
The echo protocol simply responds to the client with whatever data the client sent.
Also like chargen, echo relies on the client to close the connection.
Unlike chargen, however, an echo server must both read and write from the connection.
One thing I noticed while writing and debugging this program: the buffer size makes a big difference, although perhaps not in the way you might think.
If the buffer is large enough to hold complete test cases without being flipped or drained, it’s very easy to not notice that the buffer isn’t being flipped or compacted at the right times because the test cases never actually need to do that.
Before shipping your program, try turning the buffer size down to something significantly lower than the input you’re expecting.
In this case, I tested with a buffer size of 10
This test degrades performance, so you shouldn’t ship with such a ridiculously small buffer, but you absolutely should test your code with small buffers to make sure it behaves properly when the buffer fills up.
Duplicating Buffers It’s often desirable to make a copy of a buffer to deliver the same information to two or.
The duplicated buffers share the same data, including the same backing array if the buffer is indirect.
Changes to the data in one buffer are reflected in the other buffer.
Thus, you should mostly use this method when you’re only going to read from the buffers.
Otherwise, it can be tricky to keep track of where the data is being modified.
The original and duplicated buffers do have independent marks, limits, and positions even though they share the same data.
One buffer can be ahead of or behind the other buffer.
Duplication is useful when you want to transmit the same data over multiple channels, roughly in parallel.
You can make duplicates of the main buffer for each channel and.
For example, recall the single-file HTTP server in Example 9-10
Reimplemented with channels and buffers as shown in Example 11-6, NonblockingSingleFileHTTPServer, the single file to serve is stored in one constant, read-only buffer.
Every time a client connects, the program makes a duplicate of this buffer just for that channel, which is stored as the channel’s attachment.
Without duplicates, one client has to wait until the other finishes so the original buffer can be rewound.
The constructors set up the data to be sent along with an HTTP header that includes information about content length and content encoding.
The header and the body of the response are stored in a single ByteBuffer so that they can be blasted to clients very quickly.
However, although all clients receive the same content, they may not receive it at the same time.
Different parallel clients will be at different locations in the file.
This is why we duplicate the buffer, so each channel has its own buffer.
The overhead is small because all channels do share the same content.
Then it creates the Selec tor and registers it with the ServerSocketChannel.
When a SocketChannel is accepted, the same Selector object is registered with it.
Initially it’s registered for reading because the HTTP protocol requires the client to send a request before the server responds.
The program reads as many bytes of input as it can up to 4K.
Then it resets the interest operations for the channel to writability.
A more complete server would actually attempt to parse the HTTP header request here and choose the file to send based on that information.) Next, the content buffer is duplicated and attached to the channel.
The next time the program passes through the while loop, this channel should be ready to receive data (or if not the next time, the time after that; the asynchronous nature of the connection means we won’t see it until it’s ready)
At this point, you get the buffer out of the attachment, and write as much of the buffer as you can onto the channel.
It’s no big deal if you don’t write it all this time.
You’ll just pick up where you left off the next pass through the loop.
Although many incoming clients might result in the creation of many buffer objects, the real overhead is minimal because they’ll all share the same underlying data.
If no file is specified or the file cannot be opened, an error message is printed and the program exits.
Assuming the file can be read, its contents are read into a ByteBuffer using the convenient Path and Files classes from Java 7
A reasonable guess is made about the content type of the file, and that guess is stored in the contentType variable.
Next, the port number is read from the second command-line argument.
The encoding is read from the third command-line argument if present.
Then these values are used to construct a NonblockingSingleFileHTTPServer object and start it running.
Slicing Buffers Slicing a buffer is a slight variant of duplicating.
Slicing also creates a new buffer that shares data with the old buffer.
However, the slice’s zero position is the current position of the original buffer, and its capacity only goes up to the source buffer’s limit.
That is, the slice is a subsequence of the original buffer that only contains the elements from the current position to the limit.
Rewinding the slice only moves it back to the position of the original buffer when the slice was created.
The slice can’t see anything in the original typed buffer classes:
This is useful when you have a long buffer of data that is easily divided into multiple parts such as a protocol header followed by the data.
You can read out the header, then slice the buffer and pass the new buffer containing only the data to a separate method or class.
Marking and Resetting Like input streams, buffers can be marked and reset if you want to reread some data.
Unlike input streams, this can be done to all buffers, not just some of them.
For a change, the relevant methods are declared once in the Buffer superclass and inherited by all the various subclasses:
The mark is also unset when the position is set to a point before the mark.
They have the same type (e.g., a ByteBuffer is never equal to an IntBuffer but may be equal to another ByteBuffer)
They have the same number of elements remaining in the buffer.
The remaining elements at the same relative positions are equal to each other.
Note that equality does not consider the buffers’ elements that precede the position, the buffers’ capacity, limits, or marks.
For example, this code fragment prints true even though the first buffer is twice the size of the second:
That is, two equal buffers will have equal hash codes and two unequal buffers are very unlikely to have equal hash codes.
However, because the buffer’s hash code changes every time an element is added to or removed from the buffer, buffers do not make good hash table keys.
Comparison is implemented by comparing the remaining elements in each buffer, one by one.
If all the corresponding elements are equal, the buffers are equal.
If one buffer runs out of elements before an unequal element is found and the other buffer still has elements, the shorter buffer is considered to be less than the longer buffer.
The notable exception is CharBuffer, which returns a string containing the remaining chars in the buffer.
Channels Channels move blocks of data into and out of buffers to and from various I/O sources such as files, sockets, datagrams, and so forth.
The channel class hierarchy is rather convoluted, with multiple interfaces and many optional operations.
However, for purposes of network programming there are only three really important channel classes, SocketChannel, ServerSocketChannel, and DatagramChannel; and for the TCP connections we’ve talked about so far you only need the first two.
SocketChannel The SocketChannel class reads from and writes to TCP sockets.
The data must be encoded in ByteBuffer objects for reading and writing.
Each SocketChannel is associated with a peer Socket object that can be used for advanced configuration, but this requirement can be ignored for applications where the default options are fine.
This method blocks (i.e., the method will not return until the connection is made or an exception is thrown)
You might choose this more roundabout approach in order to configure various options on the channel and/or the socket before connecting.
Specifically, use this approach if you want to open the channel without blocking:
The program can do other things while it waits for the.
Finally, if the connection could not be established, for instance because the network is down, this method throws an exception.
If the program wants to check whether the connection is complete, it can call these two methods:
To read from a SocketChannel, first create a ByteBuffer the channel can store data in.
The channel fills the buffer with as much data as it can, then returns the number of bytes it put there.
When it encounters the end of stream, the channel fills the buffer with any this method will read at least one byte or return –1 or throw an exception.
If the channel is nonblocking, however, this method may return 0
Because the data is stored into the buffer at the current position, which is updated method until the buffer is filled.
For example, this loop will read until the buffer is filled or the end of stream is detected:
It is sometimes useful to be able to fill several buffers from one source.
These two methods accept an array of ByteBuffer objects as arguments and fill each one in turn:
The second method fills length buffers, starting with the one at offset.
To fill an array of buffers, just loop while the last buffer in the list has space remaining.
In order to write, simply fill a ByteBuffer, flip it, and pass it to one of the write methods, which drains it while copying the data onto the output—pretty much the reverse of the reading process.
As with reads (and unlike OutputStreams), this method is not guaranteed to write the complete contents of the buffer if the channel is nonblocking.
Again, however, the cursor-based nature of buffers enables you to easily call this method again and again until the buffer is fully drained and the data has been completely written:
It is often useful to be able to write data from several buffers onto one socket.
For example, you might want to store the HTTP header in one buffer and the HTTP body in another buffer.
The implementation might even fill the two buffers simultaneously using two threads or overlapped I/O.
These two methods accept an array of ByteBuffer objects as arguments, and drain each one in turn:
The second method drains length buffers, starting with the one at offset.
Closing Just as with regular sockets, you should close a channel when you’re done with it to free up the port and any other resources it may be using:
Attempting to write data to or read data from a closed channel throws an exception.
Starting in Java 7, SocketChannel implements AutoCloseable, so you can use it in trywith-resources.
ServerSocketChannel The ServerSocketChannel class has one purpose: to accept incoming connections.
You cannot read from, write to, or connect a ServerSocketChannel.
The only operation it supports is accepting a new incoming connection.
The class itself only declares four several methods from its superclasses, mostly related to registering with a Selector for method that shuts down the server socket.
This method does not actually open a new server socket.
Before you can use it, you point, you can configure any server options you like, such as the receive buffer size or the socket timeout, using the various setter methods in ServerSocket.
Then connect this ServerSocket to a SocketAddress for the port you want to bind to.
For example, this code fragment opens a ServerSocketChannel on port 80:
A factory method is used here rather than a constructor so that different virtual machines can provide different implementations of this class, more closely tuned to the method always returns an instance of the same class when running in the same virtual machine.
The thread cannot do anything until a connection is made.
This strategy might be appropriate for simple servers that can respond to each request immediately.
In this case, the ac is more appropriate for servers that need to do a lot of work for each connection and thus may want to process multiple requests in parallel.
Nonblocking mode is normally used in conjunction with a Selector.
There are several subclasses of IOException that indicate more detailed problems, as well as a couple of runtime exceptions: ClosedChannelException.
Another thread interrupted this thread while a blocking ServerSocketChannel was waiting.
The security manager refused to allow this application to bind to the requested port.
The Channels Class Channels is a simple utility class for wrapping channels around traditional I/O-based streams, readers, and writers, and vice versa.
It’s useful when you want to use the new I/O model in one part of a program for performance, but still interoperate with legacy APIs that expect streams.
It has methods that convert from streams to channels and methods that convert from channels to streams, readers, and writers:
The SocketChannel class discussed in this chapter implements both the ReadableByte Channel and WritableByteChannel interfaces seen in these signatures.
ServerSock etChannel implements neither of these because you can’t read from or write to it.
For example, all current XML APIs use streams, files, readers, and other traditional I/O APIs to read the XML document.
If you’re writing an HTTP server designed to process SOAP requests, you may want to read the HTTP request bodies using channels and parse the XML using SAX for performance.
These behave like and have almost the same interface as SocketCh annel and ServerSocketChannel (though they are not subclasses of those classes)
However, unlike SocketChannel and ServerSocketChannel, reads from and writes to asynchronous channels return immediately, even before the I/O is complete.
The data read or written is further processed by a Future or a CompletionHandler.
For example, suppose a program needs to perform a lot of initialization at startup.
Some of that involves network connections that are going to take several seconds each.
You can start several asynchronous operations in parallel, then perform your local initializations, and then request the results of the network operations:
The advantage of this approach is that the network connections run in parallel while the program does other things.
When you’re ready to process the data from the network, same effect with thread pools and callables, but this is perhaps a little simpler, especially if buffers are a natural fit for your application.
This approach fits the situation where you want to get results back in a very particular order.
However, if you don’t care about order, if you can process each network read independently of the others, then you may be better off using a CompletionHandler instead.
For example, imagine you’re writing a search engine web spider that feeds pages.
Because you don’t care about the order of the responses returned, you can spawn a large number of AsynchronousSocketChannel requests and give each one a CompletionHandler that stores the results in the backend.
For example, here’s a simple CompletionHandler that prints whatever it received on System.out:
When you read from the channel you pass a buffer, an attachment, and a Completion.
This is one way to push the data read from the network into the CompletionHandler where it can handle it.
Another common pattern is to make the CompletionHandler an anonymous inner class and the buffer a final local variable so it’s in scope inside the completion handler.
Although you can safely share an AsynchronousSocketChannel or AsynchronousSer verSocketChannel between multiple threads, no more than one thread can read from this channel at a time and no more than one thread can write to the channel at a time.
One thread can read and another thread can write simultaneously, though.) If a thread a ReadPendingException.
Similarly, if a thread attempts to write while another thread.
The options have the same meaning in the underlying TCP stack whether set on a socket or a channel.
However, the interface to these options is a little different.
Rather than individual methods for each supported option, the channel classes each have just three methods to get, set, and list the supported options:
The SocketOption class is a generic class specifying the name and type of each option.
The type parameter <T> determines whether the option is a boolean, Integer, or Net workInterface.
The StandardSocketOptions class provides constants for each of the 11 options Java recognizes:
Example 11-7 is a simple program to list all supported socket options for the different types of network channels.
Here’s the output showing which options are supported by which types of channels, and what the default values are:
Readiness Selection For network programming, the second part of the new I/O APIs is readiness selection, the ability to choose a socket that will not block when read or written.
In order to perform readiness selection, different channels are registered with a Selec tor object.
The program can then ask the Selector object for the set of keys to the channels that are ready to perform the operation you want to perform without blocking.
The next step is to add channels to the selector.
Thus, the channel is registered with a selector by passing the selector to one of the channel’s register methods:
This approach feels backward to me, but it’s not hard to use.
The first argument is the selector the channel is registering with.
The second argument is a named constant from the SelectionKey class identifying the operation the channel is registering for.
The SelectionKey class defines four named bit constants used to select the type of the operation:
Therefore, if a channel needs to register for multiple operations in the same selector (e.g., for both reading and writing on a socket), combine the constants with the bitwise or operator (|) when registering:
The optional third argument is an attachment for the key.
This object is often used to store state for the connection.
For example, if you were implementing a web server, you might attach a FileInputStream or FileChannel connected to the local file the server streams to the client.
After the different channels have been registered with the selector, you can query the selector at any time to find out which channels are ready to be processed.
Channels may be ready for some operations and not others.
For instance, a channel could be ready for reading but not writing.
They differ in how long they returns immediately if no connections are ready to be processed now:
The first method waits until at least one registered channel is ready to be processed before returning.
The second waits no longer than timeout milliseconds for a channel to be ready before returning 0
These methods are useful if your program doesn’t have anything to do when no channels are ready to be processed.
When you know the channels are ready to be processed, retrieve the ready channels.
You iterate through the returned set, processing each SelectionKey in turn.
You’ll also want to remove the key from the iterator to tell the selector that you’ve handled it.
Otherwise, the selector will keep telling you about it on future passes through the loop.
Finally, when you’re ready to shut down the server or when you no longer need the selector, you should close it:
More importantly, it cancels all keys registered with the selector and interrupts up any threads blocked by one of this selector’s select methods.
The SelectionKey Class SelectionKey objects serve as pointers to channels.
They can also hold an object attachment, which is how you normally store the state for the connection on that channel.
When retrieving a SelectionKey from the set of selected keys, you often first test what that key is ready to do.
In some cases, the selector is only testing for one possibility and will only return keys to do that one thing.
But if the selector does test for multiple readiness states, you’ll want to test which one kicked the channel into the ready state before operating on it.
It’s also possible that a channel is ready to do more than one thing.
Once you know what the channel associated with the key is ready to do, retrieve the.
If you’ve stored an object in the SelectionKey to hold state information, you can retrieve.
Finally, when you’re finished with a connection, deregister its SelectionKey object so the selector doesn’t waste any resources querying it for readiness.
However, this step is only necessary if you haven’t closed the channel.
Closing a channel automatically deregisters all keys for that channel in all selectors.
Similarly, closing a selector invalidates all keys in that selector.
Previous chapters discussed network applications that run on top of the TCP transport layer protocol.
If data is lost or damaged in transmission, TCP ensures that the data is resent.
If packets of data arrive out of order, TCP puts them back in the correct order.
If the data is coming too fast for the connection, TCP throttles the speed back so that packets won’t be lost.
A program never needs to worry about receiving data that is out of order or incorrect.
Establishing and tearing down TCP connections can take a fair amount of time, particularly for protocols such as HTTP, which tend to require many short transmissions.
The User Datagram Protocol (UDP) is an alternative transport layer protocol for sending data over IP that is very quick, but not reliable.
When you send UDP data, you have no way of knowing whether it arrived, much less whether different pieces of data arrived in the order in which you sent them.
The UDP Protocol The obvious question to ask is why anyone would ever use an unreliable protocol.
Surely, if you have data worth sending, you care about whether the data arrives correctly? Clearly, UDP isn’t a good match for applications like FTP that require reliable transmission of data over potentially unreliable networks.
However, there are many kinds of applications in which raw speed is more important than getting every bit right.
For example, in real-time audio or video, lost or swapped packets of data simply appear as static.
Static is tolerable, but awkward pauses in the audio stream, when TCP requests a retransmission or waits for a wayward packet to arrive, are unacceptable.
In other applications, reliability tests can be implemented in the application layer.
For example, if a client sends a short UDP request to a server, it may assume that the packet is lost if no response is returned within an established period of time; this is one way the Domain.
The latest version of NFS can use either UDP or TCP.) In these protocols, the application is responsible for reliability; UDP doesn’t take care of it (the application must handle missing or out-of-order packets)
This is a lot of work, but there’s no reason it can’t be done—although if you find yourself writing this code, think carefully about whether you might be better off with TCP.
The difference between TCP and UDP is often explained by analogy with the phone system and the post office.
When you dial a number, the phone is answered and a connection is established between the two parties.
As you talk, you know that the other party hears your words in the order in which you say them.
If the phone is busy or no one answers, you find out right away.
Most of the letters arrive, but some may be lost on the way.
The letters probably arrive in the order in which you sent them, but that’s not guaranteed.
The farther away you are from your recipient, the more likely it is that mail will be lost on the way or arrive out of order.
If this is a problem, you can write sequential numbers on the envelopes, then ask the recipients to arrange them in the correct order and send you mail telling you which letters arrived so that you can resend any that didn’t get there the first time.
However, you and your correspondent need to agree on this protocol in advance.
Both the phone system and the post office have their uses.
Although either one could be used for almost any communication, in some cases one is definitely superior to the other.
The past several chapters have all focused on TCP applications, which are more common than UDP applications.
However, UDP also has its place; in this chapter, we’ll look at what you can do with UDP.
If you want to go further, the next chapter describes multicasting over UDP.
A multicast socket is a fairly simple variation on a standard UDP socket.
Java’s implementation of UDP is split into two classes: DatagramPacket and Datagram Socket.
The DatagramPacket class stuffs bytes of data into UDP packets called datagrams and lets you unstuff datagrams that you receive.
To send data, you put the data in a DatagramPacket and send the packet using a DatagramSocket.
To receive data, you take a DatagramPacket object from a DatagramSocket and then inspect the contents of the packet.
In UDP, everything about a datagram, including the address to which it is directed, is included in the packet itself; the socket only needs to know the local port on which to listen or send.
This division of labor contrasts with the Socket and ServerSocket classes used by TCP.
First, UDP doesn’t have any notion of a unique connection between two hosts.
A single DatagramSocket can send data to and receive data from many independent hosts.
The socket isn’t dedicated to a single connection, as it is in TCP.
In fact, UDP doesn’t have any concept of a connection between two hosts; it only knows about individual datagrams.
Figuring out who sent what data is the application’s responsibility.
Second, TCP sockets treat a network connection as a stream: you send and receive data with input and output streams that you get from the socket.
All the data you stuff into a single datagram is sent as a single packet and is either received or lost as a group.
Given two packets, there is no way to determine which packet was sent first and which was sent second.
Instead of the orderly queue of data that’s necessary for a stream, datagrams try to crowd into the recipient as quickly as possible, like a crowd of people pushing their way onto a bus.
And occasionally, if the bus is crowded enough, a few packets, like people, may not squeeze on and will be left waiting at the bus stop.
Recall that the daytime server listens on port 13, and that the server sends the time in a human-readable format and closes the connection.
Now let’s see how to retrieve this same data programmatically using UDP.
The socket does not know the remote host or address.
By specifying port 0 you ask Java to pick a random available port for you, much as with server sockets.
Set a timeout on the connection statement sets the socket to time out after 10 seconds of nonresponsiveness:
Timeouts are even more important for UDP than TCP because many problems that would cause an IOException in TCP silently fail in UDP.
For example, if the remote host is not listening on the targeted port, you’ll never hear about it.
You’ll need two, one to send and one to receive.
For the daytime protocol it doesn’t matter what data you put in the packet, but you do need to tell it the remote host and remote port to connect to:
The packet that receives the server’s response just contains an empty byte array.
This needs to be large enough to hold the entire response.
If it’s too small, it will be silently truncated—1k should be enough space:
First send the packet over the socket and then receive the response:
Finally, extract the bytes from the response and convert them to a string you can show to the end user:
In Java 7, DatagramSocket implements Autocloseable so you can use try-with-resources:
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Typical output is much the same as if you connected with TCP:
Begin by opening a datagram socket on a well-known port.
As with TCP sockets, on Unix systems (including Linux and Mac OS X) you need to be running as root in order to bind to a port below 1024
You can either use sudo to run the program or simply change the port to something 1024 or higher.
Next, create a packet into which to receive a request.
You need to supply both a byte array in which to store incoming data, the offset into the array, and the number of bytes to store.
This call blocks indefinitely until a UDP packet arrives on port 13
This has four parts: the raw data to send, the number of bytes of the raw data to send, the host to send to, and the port on that host to address.
In this example, the raw data comes from a String form of the current time, and the host and the port are simply the host and port of the incoming packet:
Finally, send the response back over the same socket that received it:
Example 12-2 wraps this sequence up in a while loop, complete with logging and exception handling, so that it can process many incoming requests.
As you can see in this example, UDP servers tend not to be as multithreaded as TCP servers.
They usually don’t do a lot of work for any one client, and they can’t get blocked waiting for the other end to respond because UDP never reports errors.
Unless a lot of time-consuming work is required to prepare the response, an iterative approach works just fine for UDP servers.
The DatagramPacket Class UDP datagrams add very little to the IP datagrams they sit on top of.
The UDP header adds only eight bytes to the IP header.
The UDP header includes source and destination port numbers, the length of everything that follows the IP header, and an optional checksum.
Because port numbers are given as two-byte unsigned integers, 65,536 different possible UDP ports are available per host.
These are distinct from the 65,536 different TCP ports per host.
Because the length is also a two-byte unsigned integer, the number of bytes in a datagram is limited to 65,536 minus the eight bytes for the header.
The exact number depends on the size of the IP header.) The checksum field is optional and not used in or accessible from application layer programs.
If the checksum for the data fails, the native network software silently discards the datagram; neither the sender nor the receiver is notified.
Although the theoretical maximum amount of data in a UDP datagram is 65,507 bytes, in practice there is almost always much less.
And implementations are not required to accept datagrams with more than 576 total bytes, including data and headers.
Consequently, you should be extremely wary of any program that depends on sending or receiving UDP packets with more than 8K of data.
Most of the time, larger packets are simply truncated to 8K of data.
For maximum safety, the data portion of a UDP packet should be kept to 512 bytes or less, although this limit can negatively affect performance compared to larger packet sizes.
This is a problem for TCP datagrams too, but the stream-based API provided by Socket and ServerSocket completely shields programmers from these details.)
In Java, a UDP datagram is represented by an instance of the DatagramPacket class:
This class provides methods to get and set the source or destination address from the IP header, to get and set the source or destination port, to get and set the data, and to get and set the length of the data.
The remaining header fields are inaccessible from pure Java code.
The Constructors DatagramPacket uses different constructors depending on whether the packet will be used to send data or to receive data.
Normally, constructors are overloaded to let you provide different kinds of information when you create an object, not to create objects of the same class that will be used in different contexts.
In this case, all six constructors take as arguments a byte array that holds the datagram’s data and the number of bytes in that array to use for the datagram’s data.
When you want to receive a datagram, these are the only arguments you provide.
When the socket receives a datagram from the network, it stores the datagram’s data in the DatagramPacket object’s buffer array, up to the length you specified.
The second set of DatagramPacket constructors is used to create datagrams you will send over the network.
Like the first, these constructors require a buffer array and a length, but they also require an address and port to which the packet will be sent.
In this case, you pass to the constructor a byte array containing the data you want to send and the destination address and port to which the packet is to be sent.
The DatagramSock et reads the destination address and port from the packet; the address and port aren’t stored within the socket, as they are in TCP.
These two constructors create new DatagramPacket objects for receiving data from the network:
If the first constructor is used, when a socket receives a datagram, it stores the datagram’s data part in buffer beginning at buffer[0] and continuing until the packet is completely stored or until length bytes have been written into the buffer.
For example, this code fragment creates a new DatagramPacket for receiving a datagram of up to 8,192 bytes:
If the second constructor is used, storage begins at buffer[offset] instead.
If you try to construct a DatagramPacket with a length that will overflow the buffer, the constructor throws an IllegalArgumentException.
This is a RuntimeEx ception, so your code is not required to catch it.
It is OK to construct a DatagramPack et with a length less than buffer.length - offset.
In this case, at most the first length bytes of buffer will be filled when the datagram is received.
The constructor doesn’t care how large the buffer is and would happily let you create a DatagramPacket with megabytes of data.
In practice, however, many UDP-based protocols such as DNS and TFTP use packets with 512 bytes of data per datagram or fewer.
The largest data size in common usage is 8,192 bytes for NFS.
Almost all UDP datagrams you’re likely to encounter will have 8K of data or fewer.
In fact, many operating systems don’t support UDP datagrams with more than 8K of data and either truncate, split, or discard larger datagrams.
If a large datagram is too big and as a result the network truncates or drops it, your Java program won’t be notified of the problem.
Consequently, you shouldn’t create Data gramPacket objects with more than 8,192 bytes of data.
These four constructors create new DatagramPacket objects used to send data across the network:
InetAddress destination, int port) InetAddress destination, int port) SocketAddress destination) SocketAddress destination)
Each constructor creates a new DatagramPacket to be sent to another host.
The packet is filled with length bytes of the data array starting at offset or 0 if offset is not used.
If you try to construct a DatagramPacket with a length that is greater than data.length (or greater than data.length - offset), the constructor throws an IllegalArgumen tException.
It’s OK to construct a DatagramPacket object with an offset and a length that will leave extra, unused space at the end of the data array.
In this case, only length bytes of data will be sent over the network.
The InetAddress or SocketAddress object destination points to the host you want the packet delivered to; the int argument port is the port on that host.
Choosing a Datagram Size The correct amount of data to stuff into one packet depends on the situation.
For example, rlogin transmits each character to the remote system almost as soon as the user types it.
Therefore, packets tend to be short: a single byte of data, plus a few bytes of headers.
For example, file transfer is more efficient with large buffers; the only requirement is that you split files into packets no larger than the maximum allowable packet size.
Several factors are involved in choosing the optimal packet size.
If the network is highly unreliable, such as a packet radio network, smaller packets are preferable because they’re less likely to be corrupted in transit.
On the other hand, very fast and reliable LANs should use the largest packet size possible.
It’s customary to convert the data to a byte array and place it in data before creating the DatagramPacket, but it’s not absolutely necessary.
Changing data after the datagram has been constructed and before it has been sent changes the data in the datagram; the data isn’t copied into a private buffer.
For example, you could store data that changes over time in data and send out the current datagram (with the most recent data) every minute.
However, it’s more important to make sure that the data doesn’t change when you don’t want it to.
This is especially true if your program is multithreaded, and different threads may write into the data buffer.
If this is the case, copy the data into a temporary buffer before you construct the DatagramPacket.
The packet is directed at port 7 (the echo port) of www.ibiblio.org:
Most of the time, the hardest part of creating a new DatagramPacket is translating the data into a byte array.
Because this code fragment wants to send a string, it uses the class can also be very useful for preparing data for inclusion in datagrams.
The get Methods DatagramPacket has six methods that retrieve different parts of a datagram: the actual data plus several fields from its header.
These methods are mostly used for datagrams received from the network.
If the datagram was received from the Internet, the address returned.
On the other hand, if the datagram was created locally to be sent to a remote machine, this method returns the address of the host to which the datagram is addressed (the destination address)
This method is most commonly used to determine the address of the host that sent a UDP datagram, so that the recipient can reply.
If the datagram was created locally to be sent to a remote host, this is the port to which the packet is addressed on the remote machine.
On the other hand, if the datagram was created locally to be sent to a remote machine, this method returns the address of the host to which the datagram is addressed (the destination address)
You typically invoke this method to determine the address and port of the host that sent a UDP datagram before you reply.
Also, if you’re using nonblocking I/O, the DatagramChannel class accepts a SocketAd dress but not an InetAddress and port.
One way to do this is to change the byte array into a String.
For example, given a DatagramPacket dp received from the network, you can convert it to a UTF-8 String like this:
If the datagram does not contain text, converting it to Java data is more difficult.
You must specify the offset and the length when constructing the ByteArrayInput it that was not filled with data from the network.
Most modern computers use the same floating-point format as Java, and most network protocols specify two’s complement integers in network byte order, which also matches Java’s formats.)
Example 12-3 uses all the methods covered in this section to print the information in the DatagramPacket.
This example is a little artificial; because the program creates a DatagramPacket, it already knows what’s in it.
More often, you’ll use these methods on a DatagramPacket received from the network, but that will have to wait for the introduction of the DatagramSocket class in the next section.
The setter Methods Most of the time, the six constructors are sufficient for creating datagrams.
However, Java also provides several methods for changing the data, remote address, and remote port after the datagram has been created.
These methods might be important in a situation where the time to create and garbage collect new DatagramPacket objects is a significant performance hit.
In some situations, reusing objects can be significantly faster than constructing new ones: for example, in a networked twitch game that sends a datagram for every bullet fired or every centimeter of movement.
However, you would have to use a very speedy connection for the improvement to be noticeable relative to the slowness of the network itself.
You could repeatedly send the same DatagramPacket object, just changing the data each time.
Instead of sending lots of new arrays, you can put all the data in one array and send it a piece at a time.
For instance, this loop sends a large array in 512-byte chunks:
On the other hand, this strategy requires either a lot of confidence that the data will in fact arrive or, alternatively, a disregard for the consequences of its not arriving.
It’s relatively difficult to attach sequence numbers or other reliability tags to individual packets when you take this approach.
Whether this is a sensible choice depends on the application.
If you’re trying to send to all the stations on a network segment, as in this fragment, you’d probably be better off using the local broadcast address and letting the network do the work.
The local broadcast address is determined by setting all bits of the IP address after the network and subnet IDs to 1
Sending a datagram to 128.238.255.255 copies it to every host on that network (although some routers and firewalls may block it, depending on its origin)
For more widely separated hosts, you’re probably better off using multicasting.
However, it uses different IP addresses and a MulticastSocket instead of a DatagramSocket.
It could be used in a port scanner application that tried to find open ports running particular UDP-based services such as FSP.
Another possibility might be some sort of networked game or conferencing server where the clients that need to receive the same information are all running on different ports as.
You could certainly write the same code using InetAddress objects and ports instead of a SocketAddress.
This method is useful when receiving datagrams, as we’ll explore later in this chapter.
When a datagram is received, its length is set to the length of the incoming data.
This means that if you try to receive another datagram into the same DatagramPacket, it’s limited to no more than the number of bytes in the first.
This method lets you reset the length of the buffer so that subsequent datagrams aren’t truncated.
The DatagramSocket Class To send or receive a DatagramPacket, you must open a datagram socket.
In Java, a datagram socket is created and accessed through the DatagramSocket class:
All datagram sockets bind to a local port, on which they listen for incoming data and which they place in the header of outgoing datagrams.
If you’re writing a client, you don’t care what the local port is, so you call a constructor that lets the system assign an unused port (an anonymous port)
This port number is placed in any outgoing datagrams and will be used by the server to address any response datagrams.
If you’re writing a server, clients need to know on which port the server is listening for incoming datagrams; therefore, when a server constructs a DatagramSocket, it specifies the local port.
However, the sockets used by clients and servers are otherwise identical: they differ only in whether they use an anonymous (system-assigned) or a well-known port.
There’s no distinction between client sockets and server sockets, as there is with TCP.
The Constructors The DatagramSocket constructors are used in different situations, much like the Data gramPacket constructors.
The first constructor opens a datagram socket on an anonymous local port.
The second constructor opens a datagram socket on a well-known local port that listens to all local network interfaces.
The last two constructors open a datagram socket on a well-known local port on a specific network interface.
All constructors deal only with the local address and port.
The remote address and port are stored in the DatagramPacket, not the DatagramSocket.
Indeed, one DatagramSocket can send and receive datagrams from multiple remote hosts and ports.
This constructor creates a socket that is bound to an anonymous port.
Pick this constructor for a client that initiates a conversation with a server.
In this scenario, you don’t care what port the socket is bound to because the server will send its response to the port from which the datagram originated.
Letting the system assign a port means that you don’t have to worry about finding an unused port.
The same socket can receive the datagrams that a server sends back to it.
The constructor throws a SocketException if the socket can’t bind to a port.
It’s unusual for this constructor to throw an exception; it’s hard to imagine situations in which the socket could not be opened, because the system gets to choose an available port.
This constructor creates a socket that listens for incoming datagrams on a particular port, specified by the port argument.
Use this constructor to write a server that listens on a well-known port.
A SocketException is thrown if the socket can’t be created.
There are two common reasons for the constructor to fail: the specified port is already occupied, or you are trying to connect to a port below 1024 and you don’t have sufficient.
Two different programs can use the same port number if one uses UDP and the other uses TCP.
Example 12-4 is a port scanner that looks for UDP ports in use on the local host.
It decides that the port is in use if the DatagramSocket constructor throws an exception.
You can easily extend it to check ports below 1024, however, if you have root access or are running it on Windows.
Here are the results from the Linux workstation on which much of the code in this book was written:
The high-numbered ports in the 30,000 range are Remote Procedure Call (RPC) services.
It’s much harder to scan UDP ports on a remote system than to scan for remote TCP ports.
Whereas there’s always some indication that a listening port, regardless of application layer protocol, has received your TCP packet, UDP provides no such guarantees.
To determine that a UDP server is listening, you have to send it a packet it will recognize and respond to.
This constructor is primarily used on multihomed hosts; it creates a socket that listens for incoming datagrams on a specific port and network interface.
The port argument is the port on which this socket listens for datagrams.
As with TCP sockets, you need to be root on a Unix system to create a DatagramSocket on a port below 1024
The address argument is an InetAddress object matching one of the host’s network addresses.
A SocketException is thrown if the socket can’t be created.
There are three common reasons for this constructor to fail: the specified port is already occupied, you are trying to connect to a port below 1024 and you’re not root on a Unix system, or address is not the address of one of the system’s network interfaces.
This constructor is similar to the previous one except that the network interface address and port are read from a SocketAddress.
For example, this code fragment creates a socket that only listens on the local loopback address:
Unlike sockets created by the other four constructors, this socket is not initially bound to a port.
You can pass null to this method, binding the socket to any available address and port.
Sending and Receiving Datagrams The primary task of the DatagramSocket class is to send and receive UDP datagrams.
Indeed, it can send and receive to and from multiple hosts at the same time.
Once a DatagramPacket is created and a DatagramSocket is constructed, send the packet Socket object and theOutput is a DatagramPacket object, send theOutput using the Socket like this:
If there’s a problem sending the data, this method may throw an IOException.
However, this is less common with DatagramSocket than Socket or ServerSocket, because the unreliable nature of UDP means you won’t get an exception just because the packet.
You may get an IOException if you’re trying to send a larger datagram than the host’s native networking software supports, but then again you may not.
This depends heavily on the native UDP software in the OS and the native code that interfaces between this and Java’s DatagramSocketImpl class.
This method may also throw a SecurityException if the SecurityManager won’t let you communicate with the host to which the packet is addressed.
This is primarily a problem for applets and other remotely loaded code.
It reads lines of user input from Sys tem.in and sends them to a discard server, which simply discards all the data.
Many of the simpler Internet protocols, such as discard and echo, have both TCP and UDP implementations.
It has a single static field, PORT, which is set to the standard port for the discard protocol (port 9), and a single method, that hostname to the InetAddress object called server.
A BufferedReader is chained to System.in to read user input from the keyboard.
After creating the socket, the program enters an infinite is guaranteed to work as advertised.
Because the discard protocol deals only with raw bytes, it can ignore character encoding issues.
Finally, theOutput is sent over theSocket, and the loop continues.
If at any point the user types a period on a line by itself, the program exits.
The DatagramSocket constructor may throw a Sock etException, so that needs to be caught.
Because this is a discard client, you don’t need to worry about data coming back from the server.
This method receives a single UDP datagram from the network and stores it in the et class, this method blocks the calling thread until a datagram arrives.
The datagram’s buffer should be large enough to hold the data received.
If it’s not, that the maximum size of the data portion of a UDP datagram is 65,507 bytes.
Example 12-6 shows a UDP discard server that receives incoming datagrams.
Just for fun, it logs the data in each datagram to System.out so that you can see who’s sending what to your discard server.
If the port is not specified on the command line, it listens on port 9
Then the server enters an infinite loop that receives packets and prints the contents and the originating host on the console.
Indeed, there’s no particular reason these packets have to be text at all.
As each datagram is received, the length of packet is set to the length of the data in that datagram.
Consequently, as the last step of the loop, the length of the packet is reset to the maximum possible value.
Otherwise, the incoming packets would be limited to the minimum size of all previous packets.
You can run the discard client on one machine and connect to the discard server on a second machine to verify that the network is working.
As with streams and TCP sockets, you’ll want to take care to close the datagram socket in a finally block:
In Java 7, DatagramSocket implements AutoCloseable so you can use try-withresources:
It’s never a bad idea to close a DatagramSocket when you’re through with it; it’s particularly important to close an unneeded socket if the program will continue to run for a Example 12-4, UDPPortScanner: if this program did not close the sockets it opened, it would tie up every UDP port on the system for a significant amount of time.
On the other hand, if the program ends as soon as you’re through with the DatagramSocket, you don’t need to close the socket explicitly; the socket is automatically closed upon garbage collection.
However, Java won’t run the garbage collector just because you’ve run out of ports or sockets, unless by lucky happenstance you run out of memory at the same time.
Closing unneeded sockets never hurts and is good programming practice.
Use this method if you created a DatagramSock et with an anonymous port and want to find out what port the socket has been assigned.
Normally, you either already know or simply don’t care which address a socket is listening to.
Managing Connections Unlike TCP sockets, datagram sockets aren’t very picky about whom they’ll talk to.
In fact, by default they’ll talk to anyone; but this is often not what you want.
For instance, applets are only allowed to send datagrams to and receive datagrams from the applet host.
An NFS or FSP client should accept packets only from the server it’s talking to.
A networked game should listen to datagrams only from the people playing the game.
The next five methods let you choose which host you can send datagrams to and receive datagrams from, while rejecting all others’ packets.
Attempts to send packets to a different host or port will throw an IllegalArgumentException.
Packets received from a different host or a different port will be discarded without an exception or other notification.
If not, a SecurityExcep on that DatagramSocket no longer make the security checks they’d normally make.
SO_TIMEOUT incoming datagram before throwing an InterruptedIOException, which is a subclass.
The default is to never time out, and indeed there are few situations in which you need to set SO_TIMEOUT.
You might need it if you were implementing a secure protocol that required responses to occur within a fixed amount of time.
You might also decide that the host you’re communicating with is dead (unreachable or not responding) if you don’t receive a response within a certain amount of time.
The timeout argument must be greater than or equal to zero.
It determines the size of the buffer used for network I/O.
Larger buffers tend to improve performance for reasonably fast (say, Ethernet-speed) connections because they can store more incoming datagrams before overflowing.
Sufficiently large receive buffers are even more important for UDP than for TCP, because a UDP datagram that arrives when the buffer is full will be lost, whereas a TCP datagram that arrives at a full buffer will eventually be retransmitted.
Furthermore, SO_RCVBUF sets the maximum size of datagram packets that can be received by the application.
Packets that won’t fit in the receive buffer are silently discarded.
DatagramSocket has methods to set and get the suggested receive buffer size used for network input:
However, the underlying implementation is free to ignore this suggestion.
Consequently, you may wish to check the actual size of the receive buffer returns the number of bytes in the buffer used for input from this socket.
Both methods throw a SocketException if the underlying socket implementation does not recognize the SO_RCVBUF option.
This might happen on a non-POSIX operating tion if its argument is less than or equal to zero.
SO_SNDBUF DatagramSocket has methods to get and set the suggested send buffer size used for network output:
Once again, however, the operating system is free to ignore this size.
Both methods throw a SocketException if the underlying native network software throws an IllegalArgumentException if its argument is less than or equal to zero.
For UDP, SO_REUSEADDR controls whether multiple datagram sockets can bind to the same port and address at the same time.
If multiple sockets are bound to the same port, received packets will be copied to all bound sockets.
This means the socket must be created in an unconnected state using the protected constructor that takes a DatagramImpl as an argument.
In other words, it won’t work with a plain vanilla DatagramSocket.
Reusable ports are most commonly used for multicast sockets, which will be discussed in the next chapter.
Datagram channels also create unconnected datagram sockets that can be configured to reuse ports, as you’ll see later in this chapter.
Routers and gateways do not normally forward broadcast messages, but they can still kick up a lot of traffic on the local network.
This option is turned on by default, but if you like you can disable it thusly:
This option can be changed after the socket has been bound.
On some implementations, sockets bound to a specific address do not receive broadcast packets.
In other words, you should use the Data gramPacket(int port) constructor, not the DatagramPacket(InetAd dress address, int port) constructor to listen to broadcasts.
This is necessary in addition to setting the SO_BROADCAST option to true.
After all, packets are actually routed and prioritized according to IP, which both TCP and UDP sit on top of.
They just have to be repeated here because DatagramSocket and Socket don’t have a common superclass.
These two methods let you inspect and set the class of service for a socket using these two methods:
Because this value is copied to an eight-bit field in the TCP header, only the low-order byte of this int is used; and values outside this range cause IllegalArgumentExceptions.
The JavaDoc for these options is severely out of date, and describes a quality of service scheme based on bit fields for four traffic classes: low cost, high reliability, maximum throughput, and minimum delay.
This scheme was never widely implemented and probably hasn’t been used in this century.
This code fragment sets a socket to use Expedited Forwarding by setting the traffic class to 10111000:
The underlying socket implementation is not required to respect any of these requests.
Android in particular treats the the requested class of service, Java may but is not required to throw a SocketException.
Some Useful Applications In this section, you’ll see several Internet servers and clients that use DatagramPacket and DatagramSocket.
Some of these will be familiar from previous chapters because many Internet protocols have both TCP and UDP implementations.
When an IP packet is received by a host, the host determines whether the packet is a TCP packet or a UDP datagram by inspecting the IP header.
As I said earlier, there’s no connection between UDP and TCP ports; TCP and UDP servers can share the same port number without problems.
By convention, if a service has both TCP and UDP implementations, it uses the same port for both, although there’s no technical reason this has to be the case.
Simple UDP Clients Several Internet services need to know only the client’s address and port; they ignore any data the client sends in its datagrams.
Daytime, quote of the day, time, and chargen are four such protocols.
Each of these responds the same way, regardless of the data contained in the datagram, or indeed regardless of whether there actually is any data in the datagram.
Clients for these protocols simply send a UDP datagram to the server and read the response that comes back.
Therefore, let’s begin with a simple client called UDPPoke , shown in Example 12-7, which sends an empty UDP packet to a specified host and port and reads a response packet from the same host.
The bufferSize field specifies how large a return packet is expected.
An 8,192-byte buffer is large enough for most of the protocols that UDPPoke is useful for, but it can be increased by passing a different value to the constructor.
The timeout field specifies how long to wait for a response.
The host and the port fields specify the remote host to connect to.
If the buffer length is not specified, 8,192 bytes is used.
The host, port, and buffer size are also used to construct the outgoing DatagramPacket.
When the expected datagram appears, its data is copied into the response field.
This method returns null if the response doesn’t come quickly enough or never comes at all.
Most of the simple protocols that this client suits will return ASCII text, so this example attempts to convert the response to an ASCII string and print it.
DatagramPacket incoming // next line blocks until the response is received return response; return null;
For example, this connects to a daytime server over UDP:
Given this class, UDP daytime, time, chargen, and quote of the day clients are almost trivial.
A time client is only slightly harder, and only because you need to convert the four raw bytes returned by the server to a java.util.Date object.
UDPServer Clients aren’t the only programs that benefit from a reusable implementation.
They all wait for UDP datagrams on a specified port and reply to each datagram with another datagram.
The servers differ only in the content of the datagram that they return.
Example 12-9 is a simple iterative UDPServer class that can be subclassed to provide specific servers for different protocols.
The UDPServer class has two fields, the int bufferSize and the DatagramSocket sock et, the latter of which is protected so it can be used by subclasses.
The constructor opens a datagram socket on a specified local port to receive datagrams of no more than bufferSize bytes.
Assuming this class may be used as part of other programs that do more than just run which sets a flag.
The main loop checks this flag each pass to see if it should exit.
This will wake it up once every 10 seconds to check for shutdown whether there’s traffic or not.
Subclasses can send zero, one, or many datagrams in response to each incoming datagram.
If a lot of processing is required to respond to a not to have extended interactions with a client.
Each incoming packet is treated independently of other packets, so the response can usually be handled directly in the.
It isn’t much harder to implement an echo server, as Example 12-11 shows.
Unlike a stream-based TCP echo server, multiple threads are not required to handle multiple clients.
In particular, protocols that require multiple datagrams require a different implementation.
Implementing the echo protocol with TCP is simple; it’s more complex with UDP because you don’t have I/O streams or the concept of a connection to work with.
A TCP-based echo client can send a message and wait for a response on the same connection.
However, a UDP-based echo client has no guarantee that the message it sent was received.
Therefore, it cannot simply wait for the response; it needs to be prepared to send and receive data asynchronously.
This behavior is fairly simple to implement using threads, however.
One thread can process user input and send it to the echo server, while a second thread accepts input from the server and displays it to the user.
The client is divided into three classes: the main UDPEchoClient class, the SenderThread class, and the ReceiverThread class.
It reads a hostname from the command line and converts it to an InetAddress object.
UDPEchoClient uses this object and the default echo port to construct a SenderThread object.
This constructor can throw a SocketException, so the exception must be caught.
The same DatagramSocket that the SenderThread uses is used to construct a ReceiverTh read, which is then started.
It’s important to use the same DatagramSocket for both sending and receiving data because the echo server will send the response back to the port the data was sent from.
The SenderThread class reads input from the console a line at a time and sends it to the echo server.
The input is provided by System.in, but a different client could include an option to read input from a different stream—perhaps opening a FileInputStream to read from a file.
The fields of this class define the server to which it sends data, the port on that server, and the DatagramSocket that does the sending, all set in the single constructor.
The DatagramSocket is connected to the remote server to make sure all datagrams received were in fact sent by the right server.
It’s rather unlikely that some other server on the Internet is going to bombard this particular port with extraneous data, so this is not a big flaw.
However, it’s a good habit to make sure that the packets you receive come from the right place, especially if security is a concern.
A period on a line by itself signals the end of user input and breaks out of the loop.
Otherwise, the bytes of data are stored in the data array using payload part of the DatagramPacket output, along with information about the server, the port, and the data length.
This packet is then sent to its destination by socket.
This thread then yields to give other threads an opportunity to run.
BufferedReader userInput if (stopped) return; if (theLine.equals(".")) break; DatagramPacket output.
The ReceiverThread class shown in Example 12-14 waits for datagrams to arrive from the network.
When a datagram is received, it is converted to a String and printed on System.out for display to the user.
A more advanced echo client could include an option to send the output elsewhere.
The more important is the DatagramSocket, theSocket, which must be the same DatagramSocket used by the SenderThread.
Data arrives on the port used by that DatagramSocket; any other DatagramSocket would not be allowed to connect to the same port.
The second field, stopped, is a boolean used to halt this thread.
When an incoming datagram appears, it is converted into a String with the same length as the incoming data and printed on System.out.
As in the input thread, this thread then yields to give other threads an opportunity to execute.
You can run the echo client on one machine and connect to the echo server on a second machine to verify that the network is functioning properly between them.
DatagramChannel The DatagramChannel class is used for nonblocking UDP applications, in the same way as SocketChannel and ServerSocketChannel are used for nonblocking TCP applications.
Like SocketChannel and ServerSocketChannel, DatagramChannel is a subclass of SelectableChannel that can be registered with a Selector.
This is useful in servers where one thread can manage communications with multiple clients.
However, UDP is by its nature much more asynchronous than TCP so the net effect is smaller.
In UDP, a single datagram socket can process requests from multiple clients for both input and output.
What the DatagramChannel class adds is the ability to do this in a nonblocking fashion, so methods return quickly if the network isn’t immediately ready to receive or send data.
In Java 6 and earlier, you still need to use the DatagramSocket class to bind a channel to a port.
Instead, you read and write byte buffers, just as you do with a SocketChannel.
To bind it, you access the channel’s peer to port 3141:
It returns the address of the host that sent the packet:
If the channel is blocking (the default), this method will not return until a packet has been read.
If the channel is nonblocking, this method will immediately return null if no packet is available to read.
If the datagram packet has more data than the buffer can hold, the extra data is thrown away with no notification of the problem.
You do not receive a BufferOverflowExcep tion or anything similar.
This behavior introduces an additional layer of unreliability into the system.
The data can arrive safely from the network and still be lost inside your own program.
Using this method, you can reimplement the discard server to log the host sending the data as well as the data sent.
It avoids the potential loss of data by using a buffer that’s big enough to hold any UDP packet and clearing it before it’s used again.
The source ByteBuffer can be reused if you want to send the same data to multiple clients.
It is zero if the channel is in nonblocking mode and the data can’t be sent immediately.
Example 12-16 demonstrates with a simple echo server based on channels.
Just as it did than logging the packet on System.out, it returns the same data to the client that sent it.
This is much less of a problem for UDP-based protocols than for TCP protocols.
The unreliable, packet-based, connectionless nature of UDP means that the server at most has to wait for the local buffer to clear.
It does not wait for the client to be ready to receive data.
There’s much less opportunity for one client to get held up behind a slower client.
Connecting Once you’ve opened a datagram channel, you connect it to a particular remote address.
The channel will only send data to or receive data from this host.
Unlike the con packets across the network because UDP is a connectionless protocol.
It merely establishes the host it will send packets to when there’s data ready to be sent.
This tells you whether the DatagramChannel is limited to one host.
Unlike SocketChan nel, a DatagramChannel doesn’t have to be connected to transmit or receive data.
This doesn’t really close anything because nothing was really open in the first place.
It just allows the channel to be connected to a different host in the future.
This makes them more suitable for use with clients that know who they’ll be talking to than for servers that must accept input from multiple hosts at the same time that are normally not known prior to the arrival of the first packet.
Each of these three methods only reads a single datagram packet from the network.
As much data from that datagram as possible is stored in the argument ByteBuffer(s)
Each method returns the number of bytes read or –1 if the channel has been closed.
This method may return 0 for any of several reasons, including:
Buffer(s) can hold, the extra data is thrown away with no notification of the problem.
These methods can only be used on connected channels; otherwise, they don’t know where to send the packet.
Each of these methods sends a single datagram packet over the connection.
None of these methods are guaranteed to write the complete contents of the buffer(s)
Fortunately, the cursor-based nature of buffers enables you to easily call this method again and again until the buffer is fully drained and the data has been completely sent, possibly using multiple datagram packets.
You can use the read and write methods to implement a simple UDP echo client.
On the client side, it’s easy to connect before sending.
Because packets may be lost in transit (always remember UDP is unreliable), you don’t want to tie up the sending while waiting to receive a packet.
Thus, you can take advantage of selectors and nonblocking I/O.
These work for UDP pretty much exactly like they worked for TCP in Chapter 11
You’ll print out the values returned so it will be easy to figure out if any packets are being lost.
There is one major difference between selecting TCP channels and selecting datagram method), you need to notice when the data transfer is complete and shut down.
In this example, you assume the data is finished when all packets have been sent and one minute has passed since the last packet was received.
Any expected packets that have not been received by this point are assumed to be lost in the ether.
Closing Just as with regular datagram sockets, a channel should be closed when you’re done with it to free up the port and any other resources it may be using:
Attempting to write data to or read data from a closed channel throws an exception.
This returns false if the channel is closed, true if it’s open.
Like all channels, in Java 7 DatagramChannel implements AutoCloseable so you can use it in try-with-resources statements.
Prior to Java 7, close it in a finally block if you can.
Integer Size of the buffer used for sending datagram packets.
Integer Size of the buffer used for receiving datagram packets.
The last three are used by multicast sockets, which we’ll take up in Chapter 13
For example, suppose you want to send a broadcast message.
SO_BROADCAST is usually turned off by default, but you can switch it on like so:
Example 12-18 opens a channel just to check the default values of these options.
It’s a bit surprising that my send buffer is so much larger than my receive buffer.
The sockets in the previous chapters are unicast: they provide point-to-point communication.
Unicast sockets create a connection with two well-defined endpoints; there is one sender and one receiver and, although they may switch roles, at any given time it is easy to tell which is which.
However, although point-to-point communications serve many, if not most needs (people have engaged in one-on-one conversations for millennia), many tasks require a different model.
For example, a television station broadcasts data from one location to every point within range of its transmitter.
The signal reaches every television set, whether or not it’s turned on and whether or not it’s tuned to that particular station.
Indeed, the signal even reaches homes with cable boxes instead of antennas and homes that don’t have a television.
It’s indiscriminate and quite wasteful of both the electromagnetic spectrum and power.
Videoconferencing, by contrast, sends an audio-video feed to a select group of people.
Usenet news is posted at one site and distributed around the world to hundreds of thousands of people.
However, the sender relies on the intermediate sites to copy and relay the message to downstream sites.
The sender does not address its message to every host that will eventually receive it.
These are examples of multicasting, although they’re implemented with additional application layer protocols on top of TCP or UDP.
These protocols require fairly detailed configuration and intervention by human beings.
For instance, to join Usenet you have to find a site willing to send news to you and relay your outgoing news to the rest of the world.
To add you to the Usenet feed, the news administrator of the news relay has to specifically add your site to their news config files.
However, recent developments with the network software in most major operating systems as well as Internet routers have opened up a new possibility—true multicasting, in which the routers decide how to efficiently move a message to individual hosts.
In particular, the initial router sends only one copy of the message to a router near the receiving hosts, which then makes multiple copies for different recipients at or closer.
Multicasting in Java uses the DatagramPacket class introduced in Chapter 12, along with a new Multicast Socket class.
Multicasting Multicasting is broader than unicast, point-to-point communication but narrower and more targeted than broadcast communication.
Multicasting sends data from one host to many different hosts, but not to everyone; the data only goes to clients that have expressed an interest by joining a particular multicast group.
People can come and go as they please, leaving when the discussion no longer interests them.
Before they arrive and after they have left, they don’t need to process the information at all: it just doesn’t reach them.
In the best case, the data is duplicated only when it reaches the local network serving the interested clients: the data crosses the Internet only once.
More realistically, several identical copies of the data traverse the Internet; but, by carefully choosing the points at which the streams are duplicated, the load on the network is minimized.
The good news is that programmers and network administrators aren’t responsible for choosing the points where the data is duplicated or even for sending multiple copies; the Internet’s routers handle all that.
Protocols require broadcasts only when there is no alternative; and routers limit broadcasts to the local network or subnet, preventing broadcasts from reaching the Internet at large.
Even a few small global broadcasts could bring the Internet to its knees.
Broadcasting highbandwidth data such as audio, video, or even text and still images is out of the question.
A single email spam that goes to millions of addresses is bad enough.
Imagine what would happen if a real-time video feed were copied to all billion+ Internet users, whether they wanted to watch it or not.
However, there’s a middle ground between point-to-point communications and broadcasts to the whole world.
There’s no reason to send a video feed to hosts that aren’t interested in it; we need a technology that sends data to the hosts that want it, without bothering the rest of the world.
One way to do this is to use many unicast streams.
If 1,000 clients want to watch a BBC live stream, the data is sent a thousand times.
This is inefficient, since it duplicates data needlessly, but it’s orders-of-magnitude more efficient than broadcasting the data to every host on the Internet.
Still, if the number of interested clients is large enough, you will eventually run out of bandwidth or CPU power—probably sooner rather than later.
Another approach to the problem is to create static connection trees.
This is the solution employed by Usenet news and some conferencing systems.
This is more efficient than sending everything to all interested clients via multiple unicasts, but the scheme is kludgy and beginning to show its age.
New sites need to find a place to hook into the tree manually.
The tree does not necessarily reflect the best possible topology at any one time, and servers still need to maintain many point-to-point connections to their clients, sending the same data to each one.
It would be better to allow the routers in the Internet to dynamically determine the best possible routes for transmitting distributed information and to replicate data only when absolutely necessary.
For example, if you’re multicasting video from New York and 20 people attached to one LAN are watching the show in Los Angeles, the feed will be sent to that LAN only once.
If 50 more people are watching in San Francisco, the data stream will be duplicated somewhere (let’s say Fresno) and sent to the two cities.
Multicasting is halfway between the point-topoint communication common to the Internet and the broadcast model of television and it’s more efficient than either.
When a packet is multicast, it is addressed to a multicast group and sent to each host belonging to the group.
It does not go to a single host (as in unicasting), nor does it go to every host (as in broadcasting)
When people talk about multicasting, audio and video are the first applications that come to mind.
Indeed, the BBC has been running a multicast trial covering both TV and radio for several years now, though ISP participation has been regrettably limited.
However, audio and video are only the tip of the iceberg.
Other possibilities include multiplayer games, distributed filesystems, massively parallel computing, multiperson conferencing, database replication, content delivery networks, and more.
Multicasting can be used to implement name services and directory services that don’t require the client to know a server’s address in advance; to look up a name, a host could multicast its request to some well-known address and wait until a response is received from the nearest server.
Zeroconf) and Apache’s River both use IP multicasting to dynamically discover services on the local network.
Multicasting has been designed to fit into the Internet as seamlessly as possible.
Most of the work is done by routers and should be transparent to application programmers.
An application simply sends datagram packets to a multicast address, which isn’t fundamentally different from any other IP address.
The routers make sure the packet is delivered to all the hosts in the multicast group.
The biggest problem is that multicast routers are not yet ubiquitous; therefore, you need to know enough about them to find out whether multicasting is supported on your network.
For instance, although the BBC has been multicasting for several years now, their multicast streams are only accessible to subscribers of about a dozen relatively small British ISPs.
As far as the application itself, you need to pay attention to an additional header field in the datagrams called the Time-To-Live (TTL) value.
The TTL is the maximum number of routers that the datagram is allowed to cross.
Once the packet has crossed that many routers, it is discarded.
Multicasting uses the TTL as an ad hoc way to limit how far a packet can travel.
For example, you don’t want packets for a friendly on-campus game of Dogfight reaching routers on the other side of the world.
Multicast Addresses and Groups A multicast address is the shared address of a group of hosts called a multicast group.
All addresses in this range have the binary digits 1110 as their first four bits.
Like any IP address, a multicast address can have a hostname.
For example, the multicast address 224.0.1.1 (the address of the Network Time Protocol distributed service) is assigned the name ntp.mcast.net.
A multicast group is a set of Internet hosts that share a multicast address.
Any data sent to the multicast address is relayed to all the members of the group.
Membership in a multicast group is open; hosts can enter or leave the group at any time.
Permanent groups have assigned addresses that remain constant, whether or not there are any members in the group.
However, most multicast groups are transient and exist only as long as they have members.
The IANA is responsible for handing out permanent multicast addresses as needed.
For example, all-systems.mcast.net, 224.0.0.1, is a multicast group that includes all systems on the local subnet.
Multicast routers never forward datagrams with destinations in this range.
DHCP-AGENTS.MCAST.NET 224.0.0.12 This multicast group allows a client to locate a Dynamic Host Configuration Protocol (DHCP) server or relay agent on the local subnet.
Other Teredo clients on the same IPv4 subnet respond to this multicast address.
Permanently assigned multicast addresses that extend beyond the local subnet begin with 224.1
A few blocks of addresses ranging in size from a few dozen to a few thousand addresses have also been reserved for particular purposes.
The complete list is available from iana.org, though you should note that it contains many now defunct services, protocols, and companies.
The remaining 248 million multicast addresses can be used on a temporary basis by anyone who needs them.
Multicast routers (mrouters for short) are responsible for making sure that two different systems don’t try to use the same address at the same time.
MLOADD.MCAST.NET 224.0.1.19 MLOADD measures the traffic load through one or more network interfaces over a number of seconds.
Multicasting is used to communicate between the different interfaces being measured.
You can look at this with the X Window utility sdr or the Windows/Unix multikit program.
The idea is to allow the possible group membership to be established in advance without relying on less-than-reliable TTL values.
Clients and Servers When a host wants to send data to a multicast group, it puts that data in multicast datagrams, which are nothing more than UDP datagrams addressed to a multicast group.
Multicast data is sent via UDP, which, though unreliable, can be as much as three times faster than data sent via connection-oriented TCP.
If you think about it, multicast over TCP would be next to impossible.
For example, if you are building a distributed cache system, you might simply decide to leave any files that don’t arrive intact out of the cache.
Earlier, I said that from an application programmer’s standpoint, the primary difference between multicasting and using regular UDP sockets is that you have to worry about the TTL value.
Each time the packet passes through a router, its TTL field is decremented by at least one; some routers may decrement the TTL by two or more.
The TTL field was originally designed to prevent routing loops by guaranteeing that all packets would eventually be discarded.
It prevents misconfigured routers from sending packets back and forth to each other indefinitely.
For example, a TTL value of 16 limits the packet to the local area, generally one organization or perhaps an organization and its immediate upstream and downstream neighbors.
A TTL of 127, however, sends the packet around the world.
However, there is no precise way to map TTLs to geographical distance.
Generally, the farther away a site is, the more routers a packet has to pass through before reaching it.
Packets with small TTL values won’t travel as far as packets with large TTL values.
Table 13-3 provides some rough estimates relating TTL values to geographical reach.
Estimated TTL values for datagrams originating in the continental United States.
High-bandwidth sites in the same country, generally those fairly close to the backbone 32
Once the data has been stuffed into one or more datagrams, the sending host launches the datagrams onto the Internet.
The sending host begins by transmitting a multicast datagram to the local network.
This packet immediately reaches all members of the multicast group in the same subnet.
If the Time-To-Live field of the packet is greater than 1, multicast routers on the local network forward the packet to other networks that have members of the destination group.
When the packet arrives at one of the final destinations, the multicast router on the foreign network transmits the packet to each host it serves that is a member of the multicast group.
If necessary, the multicast router also retransmits the packet to the next routers in the paths between the current router and all its eventual destinations.
When data arrives at a host in a multicast group, the host receives it as it receives any other UDP datagram—even though the packet’s destination address doesn’t match the receiving host.
The host recognizes that the datagram is intended for it because it belongs to the multicast group to which the datagram is addressed, much as most of us accept mail addressed to “Occupant,” even though none of us are named Mr.
The receiving host must be listening on the proper port, ready to process the datagram when it arrives.
Routers and Routing Figure 13-3 shows one of the simplest possible multicast configurations: a single server sending the same data to four clients served by the same router.
A multicast socket sends one stream of data over the Internet to the clients’ router; the router duplicates the stream and sends it to each of the clients.
Without multicast sockets, the server would have to send four separate but identical streams of data to the router, which would route each stream to a client.
Using the same stream to send the same data to multiple clients significantly reduces the bandwidth required on the Internet backbone.
Of course, real-world routes can be much more complex, involving multiple hierarchies of redundant routers.
However, the goal of multicast sockets is simple: no matter how complex the network, the same data should never be sent more than once over any given network segment.
Just create a MulticastSocket, have the socket join a multicast group, and stuff the address of the multicast group in the DatagramPacket you want to send.
The routers and the Multi castSocket class take care of the rest.
The biggest restriction on multicasting is the availability of special multicast routers (mrouters)
Mrouters are reconfigured Internet routers or workstations that support the IP multicast extensions.
Many consumer-oriented ISPs quite deliberately do not enable multicasting in their routers.
In 2013, it is still possible to find hosts between which no multicast route exists (i.e., there is no route between the hosts that travels exclusively over mrouters)
To send and receive multicast data beyond the local subnet, you need a multicast router.
Check with your network administrator to see whether your routers support multicasting.
If any router responds, then your network is hooked up to a multicast router:
This still may not allow you to send to or receive from every multicast-capable host on the Internet.
For your packets to reach any given host, there must be a path of multicastcapable routers between your host and the remote host.
Alternatively, some sites may be connected by special multicast tunnel software that transmits multicast data over unicast UDP that all routers understand.
If you have trouble getting the examples in this chapter to produce the expected results, check with your local network administrator or ISP to see whether multicasting is actually supported by your routers.
In Java, you multicast data using the java.net.MulticastSocket class, a subclass of java.net.DatagramSocket:
As you would expect, MulticastSocket’s behavior is very similar to DatagramSocket’s: you put your data in DatagramPacket objects that you send and receive with the Mul ticastSocket.
Therefore, I won’t repeat the basics; this discussion assumes that you already know how to work with datagrams.
If you’re jumping around in this book rather than reading it cover to cover, now might be a good time to go back and read Chapter 12
To receive data that is being multicast from a remote site, first create a MulticastSock to know the port to listen on.
This code fragment opens a MulticastSocket that listens on port 2300:
This signals the routers in the path between you and the server to start sending data your way and tells the local host that it should pass you IP packets addressed to the multicast group.
Once you’ve joined the multicast group, you receive UDP data just as you would with a DatagramSocket.
You create a DatagramPacket with a byte array that serves as a buffer.
When you no longer want to receive data, leave the multicast group by invoking the inherited from DatagramSocket:
Sending data to a multicast address is similar to sending UDP data to a unicast address.
You do not need to join a multicast group to send data to it.
You create a new Datagram Packet, stuff the data and the address of the multicast group into the packet, and pass.
There is one caveat to all this: multicast sockets are a security hole big enough to drive a small truck through.
Consequently, untrusted code running under the control of a SecurityManager is not allowed to do anything involving multicast sockets.
Remotely loaded code is normally only allowed to send datagrams to or receive datagrams from the host it was downloaded from.
However, multicast sockets don’t allow this sort of restriction to be placed on the packets they send or receive.
Once you send data to a multicast socket, you have very limited and unreliable control over which hosts receive that data.
Consequently, most environments that execute remote code take the conservative approach of disallowing all multicasting.
You can either pick a port to listen on or let Java assign an anonymous port for you:
All three constructors throw a SocketException if the Socket can’t be created.
If you don’t have sufficient privileges to bind to the port or if the port you’re trying to bind to is already in use, then a Socket cannot be created.
Note that because a multicast socket is a datagram socket as far as the operating system is concerned, a MulticastSocket cannot occupy a port already occupied by a DatagramSocket, and vice versa.
For example, this code fragment creates a multicast socket with SO_REUSEADDR disabled (that option is normally enabled by default for multicast sockets):
Communicating with a Multicast Group Once a MulticastSocket has been created, it can perform four key operations:
You can perform these operations in any order, with the exception that you must join a group before you can receive data from it.
You do not need to join a group to send data to it, and you can freely intermix sending and receiving data.
To join a group, pass an InetAddress or a SocketAddress for the multicast group to.
Once you’ve joined a multicast group, you receive datagrams exactly as you receive unicast datagrams, as shown in the previous chapter.
If the address that you try to join is not a multicast address (if it is not between 224.0.0.0
Information about membership in multicast groups is stored in multicast routers, not in the object.
In this case, you’d use the address stored in the incoming datagram to determine which address a packet was intended for.
Multiple multicast sockets on the same machine and even in the same Java program can all join the same group.
If so, each socket receives a complete copy of the data addressed to that group that arrives at the local host.
A second argument allows you to join a multicast group only on a specified local network interface.
If no such interface exists, then it joins on all available network interfaces:
Other than the extra argument specifying the network interface to listen from, this.
It signals the local multicast router, telling it to stop sending you datagrams.
However, no exception occurs if you leave a multicast group you never joined.
Pretty much all the methods in MulticastSocket can throw an IOException, so you’ll usually wrap all this in a try block.
In Java 7, DatagramSocket implements Autocloseable so you can use try-with-resources:
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Sending data with a MulticastSocket is similar to sending data with a DatagramSock inherited from DatagramSocket.
The data is sent to every host that belongs to the multicast group to which the packet is addressed.
By default, multicast sockets uses a TTL of 1 (that is, packets don’t travel outside the local subnet)
For example, this code fragment sets a TTL of 64:
Loopback mode Whether or not a host receives the multicast packets it sends is platform dependent— don’t want to receive the packets you send.
Passing false indicates you do want to receive the packets you send:
Because loopback mode may not be followed on all systems, it’s important to check what the loopback mode is if you’re both sending and receiving packets.
I suspect this method was written by a programmer following the ill-advised convention that defaults should always be true.)
If the system is looping packets back and you don’t want it to, you’ll need to recognize the packets somehow and discard them.
If the system is not looping the packets back and you do want it to, store copies of the packets you send and inject them into your internal data structures manually at the same time you send them.
The setter methods throw a SocketException if the argument is not the address of a network interface on the local machine.
It is unclear why the network interface is immutably set in the constructor for unicast Socket and DatagramSocket objects but is variable and set with a separate method for MulticastSocket objects.
However, it does so based on the local name of a network interface such as “eth0” (as encapsulated in a NetworkInterface object) rather than on the IP address bound to that network interface (as encapsulated in an InetAddress object)
For example, this code fragment prints the network interface used by a socket:
Two Simple Examples Most multicast servers are indiscriminate about who they will talk to.
Therefore, it’s easy to join a group and watch the data that’s being sent to it.
Example 13-1 is a MulticastS niffer class that reads the name of a multicast group from the command line, constructs an InetAddress from that hostname, and creates a MulticastSocket, which attempts to join the multicast group at that hostname.
If the attempt succeeds, MulticastSniff er receives datagrams from the socket and prints their contents on System.out.
This program is useful primarily to verify that you are receiving multicast data at a particular host.
Most multicast data is binary and won’t be intelligible when printed as text.
The program begins by reading the name and port of the multicast group from the first two command-line arguments.
Next, it creates a new MulticastSocket ms on the specified port.
This socket joins the multicast group at the specified InetAddress.
Then it enters a loop in which it waits for packets to arrive.
As each packet arrives, the program reads its data, converts the data to an ISO Latin-1 String, and prints it on Sys tem.out.
Finally, when the user interrupts the program or an exception is thrown, the socket leaves the group and closes itself.
You can use this program to listen to those messages.
If such a device is broadcasting, you should see a message pop through within the first minute or two.
I collected about a megabyte and a half of announcements within the first couple of minutes I had this program running.
It appears that my Google TV is very chatty, sending an announcement about once a second.
Most devices only announce when they’re first connected to the network, or when they’re queried by another device.
Example 13-2 is a MulticastSender class that reads input from the command line and sends it to a multicast group.
Example 13-2 reads the address of a multicast group, a port number, and an optional TTL from the command line.
It then stuffs the string "Here's some multicast data places this array in the DatagramPacket dp.
Next, it constructs the MulticastSocket ms, which joins the group ia.
Once it has joined the group, ms sends the datagram packet dp to the group ia 10 times.
The TTL value is set to one to make sure that this data doesn’t go beyond the local subnet.
Having sent the data, ms leaves the group and closes itself.
Listen to the group allsystems.mcast.net on port 4000, like this:
Next, send data to that group by running MulticastSender on another machine in your local subnet.
You can also run it in a different window on the same machine, although that option is not as exciting.
However, you must start running the MulticastSniff er before you start running the MulticastSender.
Send to the group allsystems.mcast.net on port 4000, like this:
Back on the first machine, you should see this output:
Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data.
For this to work beyond the local subnet, the two subnets must each have multicast routers, and the routers in between them need to have multicast enabled.
We’d like to hear your suggestions for improving our indexes.
About the Author Elliotte Rusty Harold is originally from New Orleans, and he returns there periodically in search of a decent bowl of gumbo.
However, he currently resides in the Prospect Heights neighborhood of Brooklyn with his wife, Beth, and dog, Thor.
He’s a frequent speaker at industry conferences including Software Development, Dr.
His open source projects include the XOM Library for processing XML with Java and the Amateur media player.
These small carnivores are found in all major waterways of the United States and Canada, and in almost every habitat except the tundra and the hot, dry regions of the southwestern United States.
They weigh about 20 pounds and are approximately two and a half feet long, and females tend to be about a third smaller than males.
Their diet consists mainly of aquatic animals like fish and frogs, but since they spend about two-thirds of their time on land, they also eat the occasional bird or rodent.
These animals are sociable and domesticated easily, and in Europe, a related species was once trained to catch fish for people to eat.
Configuring the Connection protected URL url protected boolean connected protected boolean allowUserInteraction protected boolean doInput protected boolean doOutput protected boolean ifModifiedSince protected boolean useCaches Timeouts.
